{
    "active_user_count": 620, 
    "advertiser_category": "Technology", 
    "audience_target": "technology", 
    "avg_comment_num_per_submission": 12, 
    "avg_submission_score": 59, 
    "collection_range_end_unix_timestamp": 1507420800, 
    "collection_range_end_utc": "2017-10-08 00:00:00", 
    "collection_range_start_unix_timestamp": 1506816000, 
    "collection_range_start_utc": "2017-10-01 00:00:00", 
    "description": "**[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n--------\n+[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n--------\n+[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n--------\n+[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n--------\n+[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ANews)\n--------\n\n***[@slashML on Twitter](https://twitter.com/slashML)***\n\n--------\n**AMAs:**\n\n[Google Brain Team (9/17/2017)](https://www.reddit.com/r/MachineLearning/comments/6z51xb/we_are_the_google_brain_team_wed_love_to_answer/)\n\n[Google Brain Team (8/11/2016)]\n(https://www.reddit.com/r/MachineLearning/comments/4w6tsv/ama_we_are_the_google_brain_team_wed_love_to/)\n\n[The MalariaSpot Team (2/6/2016)](https://www.reddit.com/r/MachineLearning/comments/4m7ci1/ama_the_malariaspot_team/)\n\n[OpenAI Research Team (1/9/2016)](http://www.reddit.com/r/MachineLearning/comments/404r9m/ama_the_openai_research_team/)\n\n[Nando de Freitas (12/26/2015)](http://www.reddit.com/r/MachineLearning/comments/3y4zai/ama_nando_de_freitas/)\n\n[Andrew Ng and Adam Coates (4/15/2015)](http://www.reddit.com/r/MachineLearning/comments/32ihpe/ama_andrew_ng_and_adam_coates/)\n\n[J\u00fcrgen Schmidhuber (3/4/2015)](http://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/)\n\n[Geoffrey Hinton (11/10/2014)]\n(http://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton/)\n\n[Michael Jordan (9/10/2014)](http://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/)\n\n[Yann LeCun (5/15/2014)](http://www.reddit.com/r/MachineLearning/comments/25lnbt/ama_yann_lecun/)\n\n[Yoshua Bengio (2/27/2014)](http://www.reddit.com/r/MachineLearning/comments/1ysry1/ama_yoshua_bengio/)\n\n--------\n**Beginners:**\n\nPlease have a look at [our FAQ and Link-Collection](http://www.reddit.com/r/MachineLearning/wiki/index)\n\n[Metacademy](http://www.metacademy.org) is a great resource which compiles lesson plans on popular machine learning topics.\n\nFor Beginner questions please try /r/LearnMachineLearning , /r/MLQuestions or http://stackoverflow.com/\n\n--------\n\n[Advanced Courses](https://www.reddit.com/r/MachineLearning/comments/51qhc8/phdlevel_courses?st=isz2lqdk&sh=56c58cd6)\n\n--------\nRelated Subreddit :\n\n* [LearnMachineLearning](http://www.reddit.com/r/LearnMachineLearning)\n\n* [Statistics](http://www.reddit.com/r/statistics)\n\n* [Computer Vision](http://www.reddit.com/r/computervision)\n\n* [Compressive Sensing](http://www.reddit.com/r/CompressiveSensing/)\n\n* [NLP] (http://www.reddit.com/r/LanguageTechnology)\n\n* [ML Questions] (http://www.reddit.com/r/MLQuestions)\n\n* /r/MLjobs and /r/BigDataJobs\n\n* /r/datacleaning\n\n* /r/DataScience\n\n* /r/scientificresearch\n\n* /r/artificial", 
    "display_name": "machinelearning", 
    "domain_occurrences": {
        "arxiv.org": 3, 
        "ashvin.me": 1, 
        "aws.amazon.com": 1, 
        "bair.berkeley.edu": 1, 
        "baptiste-wicht.com": 1, 
        "bbabenko.github.io": 1, 
        "blog.deepsense.ai": 1, 
        "chainer.org": 1, 
        "cloud.google.com": 1, 
        "deepmind.com": 4, 
        "dropbox.com": 1, 
        "fasttext.cc": 1, 
        "github.com": 9, 
        "i.redd.it": 3, 
        "inference.vc": 1, 
        "kernels.io": 1, 
        "kushalkafle.com": 1, 
        "magenta.tensorflow.org": 1, 
        "medium.com": 5, 
        "mubaris.com": 1, 
        "openaccess.thecvf.com": 1, 
        "research.google.com": 1, 
        "scrimba.com": 1, 
        "self.MachineLearning": 39, 
        "teachablemachine.withgoogle.com": 1, 
        "technologyreview.com": 1, 
        "tooploox.com": 1, 
        "youtu.be": 2, 
        "youtube.com": 3
    }, 
    "id": "2r3gv", 
    "num_external_website_posts": 50, 
    "num_text_posts": 39, 
    "public_description": "", 
    "submissions": [
        {
            "author": "mttd", 
            "created_utc": 1507411008.0, 
            "domain": "baptiste-wicht.com", 
            "id": "74xjp9", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74xjp9/p_deep_learning_library_10_fast_neural_network/", 
            "score": 41, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Deep Learning Library 1.0 - Fast Neural Network Library", 
            "url": "https://baptiste-wicht.com/posts/2017/10/deep-learning-library-10-fast-neural-network-library.html"
        }, 
        {
            "author": "rowanobrian", 
            "created_utc": 1507410926.0, 
            "domain": "self.MachineLearning", 
            "id": "74xjf8", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74xjf8/d_is_changing_the_threshold_enough_to_manage/", 
            "score": 4, 
            "selftext": "I was reading up about class imbalance, and the problem it causes. Changing cost function, oversampling etc were suggested as solutions, as well as for Logistic regression, changing threshold to get a trade off between true positive and false positive was suggested. \nI feel that just changing threshold isnt a good strategy as the initial fit  would be biased. But I am unable to think how to prove this mathematically. \n", 
            "subreddit": "MachineLearning", 
            "title": "[D] Is changing the threshold enough to manage class imbalance in Logistic Regression?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74xjf8/d_is_changing_the_threshold_enough_to_manage/"
        }, 
        {
            "author": "NichG", 
            "created_utc": 1507409472.0, 
            "domain": "self.MachineLearning", 
            "id": "74xefc", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74xefc/d_good_benchmark_datasets_for_nonstationary/", 
            "score": 12, 
            "selftext": "I'm trying to find a couple of good datasets that are statistically non-stationary in a structured way, that would be considered to be good benchmarks by the community. Basically I want to compare various approaches to adapting to non-stationarity (methods with built-in online learning, [deep knn](https://arxiv.org/abs/1702.08833), stuff based on inferring local latent variables, [random walk networks](http://twiecki.github.io/blog/2017/03/14/random-walk-deep-net/), etc )\n\nThe canonical example of this from the business side is things like click prediction, where seasonality effects and year-to-year trends and so on are big issues. I've played with these kinds of data in Kaggle competitions, but the problem is that those datasets generally aren't allowed to be used outside of the context of the competition. This seems like the gold standard of what I'm looking for - fairly predictable when you do it right, but strong non-stationary effects, and a large volume of moderate-dimensional data. I found a [UCI dataset for buzz in social media](https://archive.ics.uci.edu/ml/datasets/Buzz+in+social+media+) and another on [online retail](https://archive.ics.uci.edu/ml/datasets/Online+Retail) that might work for this.\n\nFinancial data seems obvious, but the problem is that even in the best case the performance is going to be very close to chance level, so as a benchmark it doesn't provide much dynamic range for comparing different algorithms.\n\nI think climate and atmospheric emissions data might be a good candidate, although period of monitoring could be an issue. There are a number of large gas sensor timeseries datasets on UCI, but they're generally in artificial controlled settings. \n\nThis [household electricity usage dataset](https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption) seems like it might be good if somewhat low-dimensional.\n\nSomething involving video frame prediction might be really good for this, if heavy, since data is abundant and varied. \n\nWhat do you think? Is there an MNIST equivalent for non-stationary models?", 
            "subreddit": "MachineLearning", 
            "title": "[D] Good benchmark datasets for non-stationary problems?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74xefc/d_good_benchmark_datasets_for_nonstationary/"
        }, 
        {
            "author": "kidOnStreet", 
            "created_utc": 1507398505.0, 
            "domain": "self.MachineLearning", 
            "id": "74wb5o", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74wb5o/p_automatic_scoring_system_academic/", 
            "score": 0, 
            "selftext": "I'm a student at a university in Thailand and I'm trying to create a system that learns lecture scoring behavior focus on correcting boolean algebra problem. My problem is I don't have enough dataset. Please help. Please show all your work by press enter to input the next step. The answer doesn't need to be right, but I need the process how to get to your answer. So the system can learn how to give a partial score. (Sorry for bad English). Thank you \nhttps://docs.google.com/forms/d/e/1FAIpQLSewE2q6wIPXp1QCo9T4PmoKjSuBMOsXOL25g0wsMwzRVKffLQ/viewform", 
            "subreddit": "MachineLearning", 
            "title": "[P] Automatic scoring system (Academic)", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74wb5o/p_automatic_scoring_system_academic/"
        }, 
        {
            "author": "danielcer", 
            "created_utc": 1507389446.0, 
            "domain": "github.com", 
            "id": "74vf5g", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74vf5g/p_sequence_pair_classification_in_tensorflow/", 
            "score": 57, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Sequence Pair Classification in TensorFlow using Sequence-Semantic-Embeddings (SSE)", 
            "url": "https://github.com/eBay/Sequence-Semantic-Embedding"
        }, 
        {
            "author": "lm0n", 
            "created_utc": 1507345259.0, 
            "domain": "medium.com", 
            "id": "74sh3m", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 14, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74sh3m/d_when_you_first_started_learning_did_it_feel/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[D] When you first started learning. Did it feel like anything was holding you back?", 
            "url": "https://medium.com/@cdossman/becoming-a-machine-learning-engineer-step-1-adjusting-your-mind-set-57469a169c31"
        }, 
        {
            "author": "florensacc", 
            "created_utc": 1507336634.0, 
            "domain": "self.MachineLearning", 
            "id": "74rs8a", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "two", 
            "link_flair_text": "News", 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74rs8a/n_nips_2017_workshop_call_for_papers_hierarchical/", 
            "score": 51, 
            "selftext": "We invite all researchers to submit their manuscripts for review.\n\n*******************************************************\nHierarchical Reinforcement Learning Workshop\nNIPS 2017\nSaturday, December 9\nLong Beach, CA, USA\nhttps://sites.google.com/view/hrlnips2017\nPlease address questions to: hrlnips2017@gmail.com\n*******************************************************\n\nReinforcement Learning (RL) has become a powerful tool for tackling complex sequential decision-making problems as demonstrated in high-dimensional robotics or game-playing domains. Nevertheless, modern RL methods have considerable difficulties when facing sparse rewards, long planning horizons, and more generally a scarcity of useful supervision signals.\n\nHierarchical Reinforcement Learning (HRL) is emerging as a key component for finding spatio-temporal abstractions and behavioral patterns that can guide the discovery of useful large-scale control architectures, both for deep-network representations and for analytic and optimal-control methods. HRL has the potential to accelerate planning and exploration by identifying skills that can reliably reach desirable future states. It can abstract away the details of low-level controllers to facilitate long-horizon planning and meta-learning in a high-level feature space. Hierarchical structures are modular and amenable to separation of training efforts, reuse, and transfer. By imitating a core principle of human cognition, hierarchies hold promise for interpretability and explainability.\n\nThere is a growing interest in HRL methods for structure discovery, planning, and learning, as well as HRL systems for shared learning and policy deployment. The goal of this workshop is to improve cohesion and synergy among the research community and increase its impact by promoting better understanding of the challenges and potential of HRL. This workshop further aims to bring together researchers studying both theoretical and practical aspects of HRL, for a joint presentation, discussion, and evaluation of some of the numerous novel approaches to HRL developed in recent years.\n\n*Note: Although the NIPS 2017 conference, tutorials, and workshops are sold out, an additional pool of workshop passes is reserved for authors of accepted workshop papers, both speakers and poster presenters. Authors are requested to specify their registration email addresses on submitted papers.*\n \nIMPORTANT DATES:\n\n* Submission deadline: Wednesday, **November 1**, 2017 (Anywhere on Earth)\n\n* Author notification: Monday, November 13, 2017\n\n* Final paper posted online: Monday, December 4, 2017\n\n* Workshop: Saturday, December 9, 2017 \n\nSUBMISSION DETAILS:\n\n* Research papers are solicited on Hierarchical Reinforcement Learning, its theory and practice, and related fields (optimal control, cognitive science, neuroscience, and others).\n\n* Contributed papers may include novel research, preliminary results, or surveys.\n\n* Papers are limited to 4 pages, excluding references, in the latest camera-ready NIPS style: https://nips.cc/Conferences/2017/PaperInformation/StyleFiles\n\n* Accepted papers will be made publicly available as a non-archival report, allowing future submissions to archival conferences or journals.\n\n* Please submit via CMT3: https://cmt3.research.microsoft.com/HRL2017\n\n* Please check the workshop website for the latest updates: https://sites.google.com/view/hrlnips2017\n\nACCEPTED PAPERS:\n\n* All accepted papers will be presented as spotlights and during two poster sessions.\n\n* Authors of top accepted papers will be invited to give a short contributed talk.\n\n* Lead authors of outstanding papers will be invited to a lunchtime discussion with the workshop\u2019s invited speakers.\n\n* Accepted student authors will be invited to apply for travel and registration support.\n\n* The best paper will win an award.\n\nINVITED SPEAKERS:\n\n* Pieter Abbeel (OpenAI/UC Berkeley)\n\n* Matt Botvinick (DeepMind/UCL)\n\n* Jan Peters (TU Darmstadt)\n\n* Doina Precup (McGill)\n\n* David Silver (DeepMind/UCL)\n\n* Josh Tenenbaum (MIT)\n\nORGANIZERS:\n\n* Andrew Barto (UMass)\n\n* Doina Precup (McGill)\n\n* Shie Mannor (Technion)\n\n* Tom Schaul (DeepMind)\n\n* Roy Fox (UCB)\n\n* Carlos Florensa (UCB)", 
            "subreddit": "MachineLearning", 
            "title": "[N] NIPS 2017 Workshop Call for Papers -- Hierarchical Reinforcement Learning", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74rs8a/n_nips_2017_workshop_call_for_papers_hierarchical/"
        }, 
        {
            "author": "mrborgen86", 
            "created_utc": 1507330181.0, 
            "domain": "scrimba.com", 
            "id": "74r7g7", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74r7g7/p_ive_created_a_tutorial_on_how_to_build_neural/", 
            "score": 29, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] I've created a tutorial on how to build neural networks with Brain.js (screencast + article)", 
            "url": "https://scrimba.com/c/c36zkcb"
        }, 
        {
            "author": "leehomyc", 
            "created_utc": 1507323675.0, 
            "domain": "github.com", 
            "id": "74qjt9", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74qjt9/r_code_for_unsupervised_image_to_image/", 
            "score": 4, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] Code for Unsupervised Image to Image Translation Networks", 
            "url": "https://github.com/leehomyc/Img2Img-Translation-Networks"
        }, 
        {
            "author": "spurious_recollectio", 
            "created_utc": 1507315284.0, 
            "domain": "self.MachineLearning", 
            "id": "74pmzr", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74pmzr/d_theano_user_looking_for_guidance_on/", 
            "score": 0, 
            "selftext": "I'm currently a theano user but I guess I will have to migrate soon to one of the other frameworks.  I really like the symbolic math aspect of theano and prefer to code up my networks \"from scratch\".  I often have my own bespoke architectures so pre-baked \"layers\", optimizers, etc.. generally get in my way (though its nice to have the option of course).  \n\nI checked out the pytorch tutorial (and it seems cool, particularly the dynamic graph part) but they seem to jump straight into using the neuralnetwork part of the library.  Can anyone point me to sample implementation of NN architectures in pytorch, TF, chainer that do _not_ use the high-level NN parts of the library i.e. the equivalent of implementing a GRU or LSTM in theano using scan.  Also if one of these libraries is particularly not suited to this kind of approach it would be helpful to know that.\n\nThanks in advance for any help!\n\np.s. reposted because I forgot the tag!", 
            "subreddit": "MachineLearning", 
            "title": "[D] Theano user looking for guidance on pytorch/TF/chainer", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74pmzr/d_theano_user_looking_for_guidance_on/"
        }, 
        {
            "author": "timburg", 
            "created_utc": 1507312583.0, 
            "domain": "self.MachineLearning", 
            "id": "74pc79", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74pc79/d_do_machine_learning_conference_papers_interfere/", 
            "score": 2, 
            "selftext": "I am a biologist interested in submitting my work to ICLR, which requires an 8-pg paper. Will this interfere with submission of the same work to a traditional biology journal? \n\nThe workshop track asks for a 3-page abstract. I assume this would not interfere? Thanks!", 
            "subreddit": "MachineLearning", 
            "title": "[D] Do machine learning conference papers interfere with journal publication", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74pc79/d_do_machine_learning_conference_papers_interfere/"
        }, 
        {
            "author": "gdny", 
            "created_utc": 1507310514.0, 
            "domain": "bair.berkeley.edu", 
            "id": "74p3tk", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74p3tk/r_learning_diverse_skills_via_maximum_entropy/", 
            "score": 70, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] Learning Diverse Skills via Maximum Entropy Deep Reinforcement Learning", 
            "url": "http://bair.berkeley.edu/blog/2017/10/06/soft-q-learning/"
        }, 
        {
            "author": "twocatsarewhite", 
            "created_utc": 1507309172.0, 
            "domain": "kushalkafle.com", 
            "id": "74oy8l", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74oy8l/r_an_analysis_of_visual_question_answering/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] An analysis of visual question answering algorithms", 
            "url": "http://www.kushalkafle.com/projects/tdiuc.html"
        }, 
        {
            "author": "ydereky", 
            "created_utc": 1507307633.0, 
            "domain": "aws.amazon.com", 
            "id": "74os65", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "two", 
            "link_flair_text": "News", 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74os65/news_introducing_nnvm_compiler_a_new_open/", 
            "score": 52, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[News] Introducing NNVM Compiler: A New Open End-to-End Compiler for AI Frameworks | Amazon Web Services", 
            "url": "https://aws.amazon.com/blogs/ai/introducing-nnvm-compiler-a-new-open-end-to-end-compiler-for-ai-frameworks/"
        }, 
        {
            "author": "manux", 
            "created_utc": 1507296628.0, 
            "domain": "deepmind.com", 
            "id": "74nm22", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "two", 
            "link_flair_text": "News", 
            "media": null, 
            "num_comments": 58, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74nm22/n_strengthening_our_commitment_to_canadian/", 
            "score": 127, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[N] Strengthening our commitment to Canadian research | DeepMind", 
            "url": "https://deepmind.com/blog/strengthening-our-commitment-canadian-research/"
        }, 
        {
            "author": "robintibor", 
            "created_utc": 1507295537.0, 
            "domain": "arxiv.org", 
            "id": "74nijs", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74nijs/r_deep_learning_with_convolutional_neural/", 
            "score": 5, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] Deep learning with convolutional neural networks for decoding and visualization of EEG pathology", 
            "url": "https://arxiv.org/abs/1708.08012"
        }, 
        {
            "author": "shoheihido", 
            "created_utc": 1507279095.0, 
            "domain": "chainer.org", 
            "id": "74md00", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "two", 
            "link_flair_text": "News", 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74md00/n_how_to_use_chainer_for_theano_users/", 
            "score": 5, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[N] How to use Chainer for Theano users", 
            "url": "https://chainer.org/general/2017/10/06/chainer-for-theano-users.html"
        }, 
        {
            "author": "HigherTopoi", 
            "created_utc": 1507278707.0, 
            "domain": "self.MachineLearning", 
            "id": "74mc8g", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74mc8g/d_how_to_make_a_rnn_to_generate_weights_for_each/", 
            "score": 1, 
            "selftext": "This may be late, but I'm trying to implement RNN version of SMASH (hypernet being RNN) with some modifications. Let c be a binary vector describing a CNN architecture. The candidate CNN may have variable layer size, activation function, filter width/height and etc, and the dimension of c is about 2400. Each input vector has dimension about 12 in the way compatible with the encoding rule, and the input \"sentence\" consists of 200 input vectors. Since the output dimension is different from that of the input, encoder-decoder (w/ attention) is needed, and I prefer QRNN or SRU to be used. The issue is the following: since each layer has different size (# of weights), and since each candidate architecture has different depth and n-th layer size, there is no canonical way to map each output vector to weights of the layer. What would be a good way to do it? How do I implement the process of substituting output vectors {o_i} to weights of CNN c, as this kind of task, as far as I know, isn't commonly done? \n\nOne way I can think of is to use a single MLP/CNN to map each output vector to weights of the corresponding layer, and another way is to naively map the elements of the output vector to weights of the corresponding layer and discard the excessive last elements of the vector. However, I'm sure there are better ways, and I have no idea how to make them more concrete. \n\nThe reason why I'm not using memory bank is to make the algorithm more amenable to replacing the network to be searched for from CNN to RNN and other kinds.", 
            "subreddit": "MachineLearning", 
            "title": "[D] How to make a RNN to generate weights for each layer of CNN?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74mc8g/d_how_to_make_a_rnn_to_generate_weights_for_each/"
        }, 
        {
            "author": "stereoa", 
            "created_utc": 1507250949.0, 
            "domain": "self.MachineLearning", 
            "id": "74ka9n", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74ka9n/d_looking_for_papersapplications_of_facebook/", 
            "score": 0, 
            "selftext": "This may exist already, or may not be possible; I am still a lurker to the ML world. Has anyone tried doing classification on video frames and user reaction types to see if they can make a prediction model for how a video makes you feel? Sorry, if this is a poorly worded/conveyed or noob question.", 
            "subreddit": "MachineLearning", 
            "title": "[D] Looking for papers/applications of Facebook video reaction data", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74ka9n/d_looking_for_papersapplications_of_facebook/"
        }, 
        {
            "author": "hardmaru", 
            "created_utc": 1507247653.0, 
            "domain": "magenta.tensorflow.org", 
            "id": "74jzaj", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74jzaj/p_realtime_music_generation_in_the_browser_with/", 
            "score": 11, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Real-time Music Generation in the Browser with Performance RNN", 
            "url": "https://magenta.tensorflow.org/performance-rnn-browser"
        }, 
        {
            "author": "yngvizzle", 
            "created_utc": 1507236509.0, 
            "domain": "self.MachineLearning", 
            "id": "74iupl", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 59, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74iupl/discussionmetaclutter_on_this_subreddit/", 
            "score": 91, 
            "selftext": "Hi fellow machine learning enthusiasts.\n\nI don't think I'm the only one that thinks this subreddit has become cluttered lately. The increase in basic questions and blog posts\u001b about very simple stuff is something I very much think has lessened the quality of this subreddit. Now if you disagree with this, feel free to downvote or ignore this post. However, if you do think this is a bad thing, I hope this can be a good place to discuss possible solutions.\n\nFor the simple questions, the solution should be simple. Create a weekly post where we can post simple questions as comments. I will certainly use that as a resource myself, and I think others will as well. One argument against this is the MLQuestions subreddit, but that subreddit is pretty much useless for anything more complicated than logistic regression... In addition to the simple questions megathread, we can also have a career megathread, that opens for career questions, course questions, etc. Now for blog posts, I don't see any solution though and I would love to hear your ideas here. \n\nSo, what do you guys think? Should we accept the simple questions, have a megathread, ban them altogether, or something completely different that I couldn't think of?", 
            "subreddit": "MachineLearning", 
            "title": "[Discussion][Meta]Clutter on this subreddit", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74iupl/discussionmetaclutter_on_this_subreddit/"
        }, 
        {
            "author": "rantana", 
            "created_utc": 1507228471.0, 
            "domain": "self.MachineLearning", 
            "id": "74hyi9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 23, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74hyi9/r_why_does_batchnorm_have_any_parameters_at_all/", 
            "score": 8, 
            "selftext": "Can't the scaling and offset parameters in batch norm be absorbed in the weight matrices of the pre-activations?\n\nHas anyone found that the scaling and offset parameters extremely important when using batchnorm?", 
            "subreddit": "MachineLearning", 
            "title": "[R] Why does batchnorm have any parameters at all?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74hyi9/r_why_does_batchnorm_have_any_parameters_at_all/"
        }, 
        {
            "author": "LeanderKu", 
            "created_utc": 1507222247.0, 
            "domain": "self.MachineLearning", 
            "id": "74h900", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 15, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74h900/d_are_stochastic_optimizers_linear_transformations/", 
            "score": 0, 
            "selftext": "Stochastic Optimizers in an NN setting (Gradient Descent, Adam etc).\n\nFor example:\nIf my Loss function is L(x) = a(x)+b(x) and i have an optimizer O(z), is this valid O(L(x))=O(a(x)+b(x))=O(a(x))+O(b(x)) (in both theory and practice)?\n", 
            "subreddit": "MachineLearning", 
            "title": "[D] Are stochastic Optimizers linear transformations?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74h900/d_are_stochastic_optimizers_linear_transformations/"
        }, 
        {
            "author": "fixedrl", 
            "created_utc": 1507222191.0, 
            "domain": "self.MachineLearning", 
            "id": "74h8rf", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74h8rf/d_any_impactdifference_to_parameterize_the_policy/", 
            "score": 0, 
            "selftext": "For MLP, tested by CEM in CartPole-v0 (continuous action [-1, 1])\n\n1. Linear controller works: 4 parameters + 1 bias\n\n2. MLP with 2 layers and 50 hidden neurons fails. \n\nI'm a bit confused why MLP fails to work", 
            "subreddit": "MachineLearning", 
            "title": "[D] Any impact/difference to parameterize the policy by MLP or RBF ?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74h8rf/d_any_impactdifference_to_parameterize_the_policy/"
        }, 
        {
            "author": "mingyuliutw", 
            "created_utc": 1507220277.0, 
            "domain": "i.redd.it", 
            "id": "74h0y7", 
            "is_reddit_media_domain": true, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74h0y7/r_unsupervised_imagetoimage_translation_networks/", 
            "score": 106, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] Unsupervised Image-to-Image Translation Networks", 
            "url": "https://i.redd.it/a086gd6wd1qz.png"
        }, 
        {
            "author": "finallyifoundvalidUN", 
            "created_utc": 1507218671.0, 
            "domain": "youtu.be", 
            "id": "74gual", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "two", 
            "link_flair_text": "News", 
            "media": {
                "oembed": {
                    "author_name": "3Blue1Brown", 
                    "author_url": "https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/aircAruvnKk?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/aircAruvnKk/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "But what *is* a Neural Network? | Deep learning, Part 1", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 51, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74gual/n_its_here_but_what_is_a_neural_network_deep/", 
            "score": 423, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[N] It's here! \"But what *is* a Neural Network? | Deep learning, Part 1", 
            "url": "https://youtu.be/aircAruvnKk"
        }, 
        {
            "author": "fhuszar", 
            "created_utc": 1507213018.0, 
            "domain": "inference.vc", 
            "id": "74g8ee", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 37, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74g8ee/r_gans_are_broken_in_more_than_one_way_review_of/", 
            "score": 186, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] GANs are Broken in More Than One Way: review of \"The Numerics of GANs\"", 
            "url": "http://www.inference.vc/my-notes-on-the-numerics-of-gans/"
        }, 
        {
            "author": "fixedrl", 
            "created_utc": 1507206867.0, 
            "domain": "youtube.com", 
            "id": "74fmz0", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "two", 
            "link_flair_text": "News", 
            "media": {
                "oembed": {
                    "author_name": "The Artificial Intelligence Channel", 
                    "author_url": "https://www.youtube.com/user/Maaaarth", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/EeMCEQa85tw?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/EeMCEQa85tw/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "DeepMind's Richard Sutton - The Long-term of AI & Temporal-Difference Learning", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74fmz0/n_deepminds_richard_sutton_the_longterm_of_ai/", 
            "score": 39, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[N] DeepMind's Richard Sutton - The Long-term of AI: Temporal-Difference Learning", 
            "url": "https://www.youtube.com/watch?v=EeMCEQa85tw"
        }, 
        {
            "author": "slap_bet", 
            "created_utc": 1507203983.0, 
            "domain": "self.MachineLearning", 
            "id": "74feia", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74feia/d_a_good_list_of_conferences_and_their_deadlines/", 
            "score": 11, 
            "selftext": "Hi r/machinelearning,\nDoes anyone have a good list of high quality conferences and their schedules (deadlines and so on)? I've seen sites like this before for things like CV and security, but is there a more general one out there, or one for machine learning that filters out the noise?\nThanks", 
            "subreddit": "MachineLearning", 
            "title": "[D] A good list of conferences and their deadlines?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74feia/d_a_good_list_of_conferences_and_their_deadlines/"
        }, 
        {
            "author": "karuma10", 
            "created_utc": 1507188844.0, 
            "domain": "arxiv.org", 
            "id": "74eg30", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74eg30/rinterpretable_convolutional_neural_networks/", 
            "score": 28, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R]Interpretable Convolutional Neural Networks", 
            "url": "https://arxiv.org/abs/1710.00935"
        }, 
        {
            "author": "themathstudent", 
            "created_utc": 1507182875.0, 
            "domain": "medium.com", 
            "id": "74e2ko", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74e2ko/d_deep_learning_vs_bayesian_methods/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[D] Deep Learning vs Bayesian Methods", 
            "url": "https://medium.com/@sachin.abeywardana/deep-learning-vs-bayesian-7f8606e1e78"
        }, 
        {
            "author": "skye023", 
            "created_utc": 1507180646.0, 
            "domain": "self.MachineLearning", 
            "id": "74dx67", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74dx67/d_why_use_exponential_term_rather_than_log_term/", 
            "score": 1, 
            "selftext": "Pretty much of every codes which are implementing the VAE, has the code below.\n\nAnd I googled a lot why they use the **.exponential term**, \neven though it is clearly stated that the equation from the original paper has a **log term**,\nrather than an **.exponential** term.\n\nWhy use exponential term rather than the log term?\nGoogle gave me no answer \n\n [original paper link](https://arxiv.org/abs/1312.6114)\n\n    * see Appendix B from VAE paper:\n    * Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n    * 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n```\n    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n```", 
            "subreddit": "MachineLearning", 
            "title": "[D] Why use Exponential term rather than Log term in VAE's loss function?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74dx67/d_why_use_exponential_term_rather_than_log_term/"
        }, 
        {
            "author": "bbabenko", 
            "created_utc": 1507163383.0, 
            "domain": "bbabenko.github.io", 
            "id": "74cg28", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74cg28/project_precision_recall_an_overview/", 
            "score": 10, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[Project] Precision & recall: an overview", 
            "url": "https://bbabenko.github.io/prs/"
        }, 
        {
            "author": "Kiuhnm", 
            "created_utc": 1507162153.0, 
            "domain": "self.MachineLearning", 
            "id": "74cbmh", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74cbmh/d_question_about_continuous_neural_network/", 
            "score": 3, 
            "selftext": "I'm reading Schulman's [thesis](http://joschu.net/docs/thesis.pdf) and in 2.4 he says:\n\n> With a discrete action space, we\u2019ll use a neural network that outputs action probabilities, i.e., the final layer is a softmax layer. With a continuous action space,\nwe\u2019ll use a neural network that outputs the mean of a Gaussian distribution, with a separate set of parameters specifying a diagonal covariance matrix. Since the optimal policy in an MDP or POMDP is deterministic, we don\u2019t lose much by using a simple action distribution (e.g., a diagonal covariance matrix, rather than a full covariance matrix or a more complicated multi-model distribution.)\n\nBut isn't it the case that with function approximation we can have *state aliasing* and therefore there might not be any deterministic optimal policy? For instance, if we should really go left in s1 and right in s2, but we *can't* tell s1 and s2 apart, then going left exactly 50% of the times in s1=s2 might be the best choice.\n\n---\n\nedit: I pinpointed the location in S&B's [book](http://incompleteideas.net/sutton/book/bookdraft2017june.pdf). At page 337 (357) it reads (the emphasis is mine):\n\n> In problems with significant **function approximation**, the best approximate policy may be **stochastic**. For example, in card games with imperfect information the optimal play is often to do two different things with specific probabilities, such as when bluffing in Poker. Action-value methods have no natural way of finding stochastic optimal policies, whereas policy approximating methods can, as shown in Example 13.1. This is a third significant advantage of policy-based methods.\n\nAnd then a little example follows which shows the problem.", 
            "subreddit": "MachineLearning", 
            "title": "[D] Question about continuous neural network policies (in RL)", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74cbmh/d_question_about_continuous_neural_network/"
        }, 
        {
            "author": "smorac", 
            "created_utc": 1507158781.0, 
            "domain": "github.com", 
            "id": "74bzyr", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74bzyr/p_rasa_core_machine_learning_based_dialogue/", 
            "score": 6, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Rasa Core: Machine learning based dialogue engine for conversational software", 
            "url": "https://github.com/RasaHQ/rasa_core"
        }, 
        {
            "author": "navoshta", 
            "created_utc": 1507155006.0, 
            "domain": "kernels.io", 
            "id": "74bma9", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74bma9/p_new_version_of_kernels_beta_is_out_its_a/", 
            "score": 4, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] New version of Kernels beta is out! It's a Jupyter Notebook client for iPad \u2014 sign up for beta to install on your iPad. (x-post from /r/IPython)", 
            "url": "https://kernels.io/kernels-v-1-0-4-beta/"
        }, 
        {
            "author": "Thomjazz", 
            "created_utc": 1507146472.0, 
            "domain": "medium.com", 
            "id": "74anuw", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74anuw/p_understanding_emotions_from_keras_to_pytorch/", 
            "score": 14, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Understanding emotions \u2014 from Keras to pyTorch", 
            "url": "https://medium.com/huggingface/understanding-emotions-from-keras-to-pytorch-3ccb61d5a983"
        }, 
        {
            "author": "clbam8", 
            "created_utc": 1507145017.0, 
            "domain": "deepmind.com", 
            "id": "74ahtb", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 32, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74ahtb/r_wavenet_launches_in_the_google_assistant/", 
            "score": 107, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] WaveNet launches in the Google Assistant", 
            "url": "https://deepmind.com/blog/wavenet-launches-google-assistant/"
        }, 
        {
            "author": "akb2810", 
            "created_utc": 1507143229.0, 
            "domain": "self.MachineLearning", 
            "id": "74aabq", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74aabq/d_prediction_of_web_service_qos_good_candidate/", 
            "score": 1, 
            "selftext": "(Disclaimer - ML newbie here) \nWe have a large scale web service that allows 'publishers' to submit content (hundreds of files totaling dozens of GBs along with some metadata). We then process the files and metadata and prepare them for distribution to 'subscribers'. The end to end workflow can take several hours but varies based on various factors - characteristics of the submission itself, characteristics of our service at that point in time, other submissions that are in queue and potentially various other factors. \nWhen the publishers submit their content, they want to know an ETA. This must be a typical problem for such scenarios. Is machine learning a good approach to solve this? If yes, which algorithms are ideal for this. Simply Linear regression or do the latest advancements in ANNs make them better suited for this? Surprisingly (or maybe not), I didn't find many ML research papers on this.\n\nEdit - we have significant volume of existing data for this, which could potentially be used for training. I am not sure however if we have kept a record of all the 'relevant' features though. Beyond some obvious ones, i don't even know how to tell what data is relevant to log and use for prediction.", 
            "subreddit": "MachineLearning", 
            "title": "[D] Prediction of web service QOS - good candidate for machine learning based solutions?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74aabq/d_prediction_of_web_service_qos_good_candidate/"
        }, 
        {
            "author": "terrorlucid", 
            "created_utc": 1507138974.0, 
            "domain": "deepmind.com", 
            "id": "749sq5", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "two", 
            "link_flair_text": "News", 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/749sq5/n_deepmind_ethics_society/", 
            "score": 6, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[N] DeepMind Ethics & Society", 
            "url": "https://deepmind.com/applied/deepmind-ethics-society/"
        }, 
        {
            "author": "terrorlucid", 
            "created_utc": 1507135196.0, 
            "domain": "openaccess.thecvf.com", 
            "id": "749d8t", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/749d8t/r_iccv_2017_papers/", 
            "score": 9, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] ICCV 2017 papers", 
            "url": "http://openaccess.thecvf.com/ICCV2017.py"
        }, 
        {
            "author": "sneezophile", 
            "created_utc": 1507134855.0, 
            "domain": "self.MachineLearning", 
            "id": "749bvm", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/749bvm/d_global_average_pooling_for_a_single_class/", 
            "score": 2, 
            "selftext": "I've seen Global Average Pooling layers replacing FC layers in image recognition. The idea is that you have one output feature map for every class and then just average each and pass them through softmax. This means you only have one output feature map for a single class problem. Does this work equally well? Does anyone have any experience with this?", 
            "subreddit": "MachineLearning", 
            "title": "[D] Global Average Pooling for a single class problem", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/749bvm/d_global_average_pooling_for_a_single_class/"
        }, 
        {
            "author": "getlasterror", 
            "created_utc": 1507133938.0, 
            "domain": "github.com", 
            "id": "74984h", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74984h/p_neural_turing_machines_ntm_implemented_in/", 
            "score": 19, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Neural Turing Machines (NTM) implemented in PyTorch", 
            "url": "https://github.com/loudinthecloud/pytorch-ntm"
        }, 
        {
            "author": "vonMissesFisher", 
            "created_utc": 1507133837.0, 
            "domain": "self.MachineLearning", 
            "id": "7497ot", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/7497ot/d_what_happen_to_website_of_msrvtt_msr_video_to/", 
            "score": 1, 
            "selftext": "As title, I have tried to connect to the website to download corpus of translation from video to text several times. However, I get no response from the website, it  doesn't show anything. Is the corpus for free or any constrain?\n", 
            "subreddit": "MachineLearning", 
            "title": "[D] What happen to website of MSR-VTT ( MSR Video to Text ) ?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/7497ot/d_what_happen_to_website_of_msrvtt_msr_video_to/"
        }, 
        {
            "author": "HigherTopoi", 
            "created_utc": 1507128239.0, 
            "domain": "self.MachineLearning", 
            "id": "748l34", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/748l34/d_is_the_performance_of_rl_sensitive_to/", 
            "score": 5, 
            "selftext": "As far as I know, most RL algorithms use a MLP/CNN of depth not more than 10 or a LSTM. Does deeper CNN such as Resnet not perform significantly better than CNN of depth 5? If depth isn't very important over the depth of 5 or so, is there any hyperparameter other than learning rate that generic RL algorithm is very sensitive to?\n\n ", 
            "subreddit": "MachineLearning", 
            "title": "[D] Is the performance of RL sensitive to architecture of feedforward NN?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/748l34/d_is_the_performance_of_rl_sensitive_to/"
        }, 
        {
            "author": "e_walker", 
            "created_utc": 1507125950.0, 
            "domain": "i.redd.it", 
            "id": "748cco", 
            "is_reddit_media_domain": true, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 91, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/748cco/r_neural_color_transfer_between_images/", 
            "score": 2035, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] Neural Color Transfer between Images", 
            "url": "https://i.redd.it/1qync11pltpz.jpg"
        }, 
        {
            "author": "pmigdal", 
            "created_utc": 1507118398.0, 
            "domain": "blog.deepsense.ai", 
            "id": "747o49", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 16, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/747o49/p_solving_atari_games_with_distributed/", 
            "score": 29, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Solving Atari games with Distributed Reinforcement Learning", 
            "url": "https://blog.deepsense.ai/solving-atari-games-with-distributed-reinforcement-learning/"
        }, 
        {
            "author": "Jean-Porte", 
            "created_utc": 1507104289.0, 
            "domain": "self.MachineLearning", 
            "id": "746r5a", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/746r5a/d_are_there_keraslike_training_utilities_for/", 
            "score": 11, 
            "selftext": "Hello. When I'm using tensorflow, I often find myself struggling to replicate keras training utilities.\n\nI often need a progress bar with loss monitoring, validation loss and metrics at the end of batches, early stopping, learning rate decrease callbacks...\n\nI can do it myself but it's a pain and it's time consuming. I'm not sure tflearn is what I want but maybe I should invest time to get how it works.\n\nTensorflow is really convenient for model definition but I find training code messy. What do you usually do ? \n\nThanks", 
            "subreddit": "MachineLearning", 
            "title": "[D] Are there keras-like training utilities for tensorflow?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/746r5a/d_are_there_keraslike_training_utilities_for/"
        }, 
        {
            "author": "johnathanjones1998", 
            "created_utc": 1507091455.0, 
            "domain": "self.MachineLearning", 
            "id": "745wiu", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/745wiu/d_recognizing_handwriting_on_government_forms/", 
            "score": 6, 
            "selftext": "How would I go about doing handwriting recognition and transcription on standardized government financial forms (e.g. W2s etc). Of course this is a step above MNIST, but is there some established model that takes care of handwritten words effectively. Alternatively, is there some API that could do this for me? (the Google vision API handles handwritten text rather poorly from what i have seen)", 
            "subreddit": "MachineLearning", 
            "title": "[D] Recognizing handwriting on government forms", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/745wiu/d_recognizing_handwriting_on_government_forms/"
        }, 
        {
            "author": "beatthebrush", 
            "created_utc": 1507076442.0, 
            "domain": "i.redd.it", 
            "id": "744lb8", 
            "is_reddit_media_domain": true, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/744lb8/p_pinball/", 
            "score": 20, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Pinball", 
            "url": "https://i.redd.it/vkk2waqhfppz.gif"
        }, 
        {
            "author": "robo-terp", 
            "created_utc": 1507072691.0, 
            "domain": "self.MachineLearning", 
            "id": "7448h0", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/7448h0/d_question_rademacher_complexity_and_vc_dimension/", 
            "score": 11, 
            "selftext": "Can anyone here please explain Rademacher complexity and VC dimension? I have spent considerable amount of time on it but really couldn't understand it. It would be really helpful if someone can give some pointers on it. ", 
            "subreddit": "MachineLearning", 
            "title": "[D] [Question] Rademacher complexity and VC dimension", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/7448h0/d_question_rademacher_complexity_and_vc_dimension/"
        }, 
        {
            "author": "random65431", 
            "created_utc": 1507067413.0, 
            "domain": "self.MachineLearning", 
            "id": "743pfj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/743pfj/dquestion_are_there_any_corpus_limitations_for_lda/", 
            "score": 6, 
            "selftext": "I am working with tokens and want to reduce 100 or so unique tokens into <10 topics.  Tokens can only appear up to one time in each record and records vary in length from 5 to 90.  I have > 100M records that follow that format.  Is there anything I should worry about?", 
            "subreddit": "MachineLearning", 
            "title": "[D][Question] Are there any corpus limitations for LDA?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/743pfj/dquestion_are_there_any_corpus_limitations_for_lda/"
        }, 
        {
            "author": "Jackal008", 
            "created_utc": 1507064856.0, 
            "domain": "self.MachineLearning", 
            "id": "743flp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/743flp/d_what_are_the_blogs_for_the_different_google/", 
            "score": 3, 
            "selftext": "Hi Everyone. This is my first post on this group so please forgive my noobness.\n\nI was wondering what were the relevant websites for the different Google Brain projects? I know that most of the posts come from the Google Research blog but I found that some of the individual projects have their own blogs. \n\nI found one so far:\n1. Magenta https://magenta.tensorflow.org/blog/", 
            "subreddit": "MachineLearning", 
            "title": "[D] What are the blogs for the different Google Brain projects?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/743flp/d_what_are_the_blogs_for_the_different_google/"
        }, 
        {
            "author": "Reiinakano", 
            "created_utc": 1507059365.0, 
            "domain": "teachablemachine.withgoogle.com", 
            "id": "742t3y", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 31, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/742t3y/p_teachable_machine_teach_a_machine_using_your/", 
            "score": 159, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Teachable Machine: Teach a machine using your camera, live in the browser. No coding required.", 
            "url": "https://teachablemachine.withgoogle.com/"
        }, 
        {
            "author": "benfred", 
            "created_utc": 1507058860.0, 
            "domain": "fasttext.cc", 
            "id": "742r0d", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/742r0d/p_language_identification_with_fasttext/", 
            "score": 11, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[p] Language identification with fastText", 
            "url": "https://fasttext.cc/blog/2017/10/02/blog-post.html"
        }, 
        {
            "author": "Pavementos", 
            "created_utc": 1507056440.0, 
            "domain": "self.MachineLearning", 
            "id": "742h4w", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/742h4w/d_in_gans_what_is_meant_by_the_distribution_over/", 
            "score": 11, 
            "selftext": "I'm going through Goodfellow's original paper: \n\nhttps://arxiv.org/abs/1406.2661\n\nI believe I have a fairly good understanding of what is going on but I'm having a hard time picturing what p_x or p_data actually is. \n\nDoes G map z to the 256x256 space of images? Is the distribution they refer to the distribution over the pixel values of each image? \n", 
            "subreddit": "MachineLearning", 
            "title": "[D] In GANs, what is meant by the distribution over data p_x or p_data?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/742h4w/d_in_gans_what_is_meant_by_the_distribution_over/"
        }, 
        {
            "author": "mlconf", 
            "created_utc": 1507049626.0, 
            "domain": "youtu.be", 
            "id": "741pa5", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "two", 
            "link_flair_text": "News", 
            "media": {
                "oembed": {
                    "author_name": "MLconf", 
                    "author_url": "https://www.youtube.com/channel/UCjeM1xxYb_37bZfyparLS3Q", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/XBQzhjiaqhA?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/XBQzhjiaqhA/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "Tianqi Chen, Computer Science PhD Student, University of Washington at MLconf Seattle 2017", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/741pa5/n_tianqi_chen_computer_science_phd_student/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[N] Tianqi Chen, Computer Science PhD Student, University of Washington at MLconf Seattle 2017", 
            "url": "https://youtu.be/XBQzhjiaqhA"
        }, 
        {
            "author": "liva", 
            "created_utc": 1507048201.0, 
            "domain": "youtube.com", 
            "id": "741jk0", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "two", 
            "link_flair_text": "News", 
            "media": {
                "oembed": {
                    "author_name": "Unity", 
                    "author_url": "https://www.youtube.com/user/Unity3D", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/tmoz3ojbTn0?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/tmoz3ojbTn0/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "Unity Machine Learning Agents", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/741jk0/n_unity_game_engine_introduces_machine_learning/", 
            "score": 16, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[N] Unity Game Engine introduces Machine Learning Agents to help AI advancement", 
            "url": "https://www.youtube.com/watch?v=tmoz3ojbTn0"
        }, 
        {
            "author": "kamperh", 
            "created_utc": 1507043410.0, 
            "domain": "self.MachineLearning", 
            "id": "74106t", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74106t/d_question_what_is_the_interactive_deep_learning/", 
            "score": 17, 
            "selftext": "See from around 13:10 in the talk: https://www.youtube.com/watch?v=t4kyRyKyOpo\n\nI know the link has been posted here before, but there wasn't a discussion about this specific topic.", 
            "subreddit": "MachineLearning", 
            "title": "[D] [Question] What is the interactive deep learning data exploration technique used in the Jeremy Howard TED talk?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/74106t/d_question_what_is_the_interactive_deep_learning/"
        }, 
        {
            "author": "Dakkudakkudakku", 
            "created_utc": 1507030763.0, 
            "domain": "self.MachineLearning", 
            "id": "73ztln", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73ztln/dquestion_object_detectionrecognition/", 
            "score": 4, 
            "selftext": "What are the state-of-the-art object detection and/or recognition architectures/papers? I found \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\" very interesting, and I want to use the same idea on a very specific image domain.\n\nOnce the objects are reliably detected, i plan to apply some sort of \"information bottleneck\" auto-encoder-style architecture for the task of image compression/decompression. Maybe even add adversarial training to get \"sharper\" reconstructions. Do you know some recent literature on this topic?", 
            "subreddit": "MachineLearning", 
            "title": "[D][Question] Object detection/recognition", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73ztln/dquestion_object_detectionrecognition/"
        }, 
        {
            "author": "upulbandara", 
            "created_utc": 1507021750.0, 
            "domain": "github.com", 
            "id": "73z8ps", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73z8ps/p_semantic_segmentation_using_a_fully/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Semantic Segmentation using a Fully Convolutional Neural Network", 
            "url": "https://github.com/upul/Semantic_Segmentation"
        }, 
        {
            "author": "mdnrojb", 
            "created_utc": 1507016414.0, 
            "domain": "self.MachineLearning", 
            "id": "73yy07", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73yy07/d_sota_for_diagnostic_chatbots/", 
            "score": 4, 
            "selftext": "What is the current state of the art (SOTA) for diagnostic chatbots, like e.g. Baidu's Melody [1]?\n\n1. http://research.baidu.com/baidus-melody-ai-powered-conversational-bot-doctors-patients/", 
            "subreddit": "MachineLearning", 
            "title": "[D] SOTA for diagnostic chatbots?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73yy07/d_sota_for_diagnostic_chatbots/"
        }, 
        {
            "author": "phobrain", 
            "created_utc": 1507014787.0, 
            "domain": "self.MachineLearning", 
            "id": "73yuk4", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73yuk4/d_has_anyone_trained_on_histograms/", 
            "score": 6, 
            "selftext": "I ran out of horsepower training siamese inception v3 on a single GPU, so adapted the keras siamese mnist example for histograms instead. I don't know if any other applications would be matching histograms, but it seems an obvious thing to do, in which case I might hope for discussion. \n\nEven though the photos being compared are as different as apples and apple computers, training accuracy easily hits 100%* with 5 dense relu / dropout layers and ~15K cases across a variety of histogram types. Test accuracy interestingly diverges for portrait and landscape pairs, numbers here:\n\n    http://phobrain.com/pr/home/siamese.html\n\nI speculate that it's because portrait pairs are joined at the hip, while landscape pairs are joined at the elbow, so are more disjoint. Once I get my models into production (eve of battle), failing more informed ideas, I want to try a Poincare spherical distance function, since it has given interesting results in unguided comparisons of photos.\n\n* By 'easily hits 100%' I mean I didn't have to try. Typically > 98% but reaching 100; I didn't pay much attention to it. Backing off on training accuracy purposefully gives lower test accuracy. \n* Augmenting the data would be another thing to try.\n* A convolutional approach might be worth a try on the 2D and 3D histogram data.", 
            "subreddit": "MachineLearning", 
            "title": "[D] Has anyone trained on histograms?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73yuk4/d_has_anyone_trained_on_histograms/"
        }, 
        {
            "author": "thunderdome", 
            "created_utc": 1507002975.0, 
            "domain": "deepmind.com", 
            "id": "73y15k", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73y15k/r_the_hippocampus_as_a_predictive_map_deepmind/", 
            "score": 158, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] The hippocampus as a 'predictive map' | DeepMind", 
            "url": "https://deepmind.com/blog/hippocampus-predictive-map/"
        }, 
        {
            "author": "WanderingSamuguy", 
            "created_utc": 1507000136.0, 
            "domain": "self.MachineLearning", 
            "id": "73xsuo", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73xsuo/d_automatically_spinning_up_ml_models/", 
            "score": 0, 
            "selftext": "I am attempting to incorporate an ML model into my webapp which will have outputs that will be available for users to track and predict user specific metrics. The type of data is the same across users, but the things that each will want to track will usually be different.\n \n&nbsp;\n \nI cannot make a single general model, but I do have a single user's data available to create an architecture that works. Lets say that the model has 2 categorical features, a numeric value, and a timestamp. Each categorical feature has between 5 and 30 values. The label is created based on a combination of numeric value and time features, and it is very similar to an event detection problem.\n \n&nbsp;\n \nMy question is, if I allow users to specify what feature values and numeric value they are interested in, is there a way to automatically spin up and deploy ML models based on the one architecture I construct locally? If not, what issues will I face and how should I be thinking of this problem in order to get past this?", 
            "subreddit": "MachineLearning", 
            "title": "[D] Automatically spinning up ML models?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73xsuo/d_automatically_spinning_up_ml_models/"
        }, 
        {
            "author": "fhoffa", 
            "created_utc": 1506997093.0, 
            "domain": "cloud.google.com", 
            "id": "73xje3", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73xje3/p_genomic_ancestry_inference_with_deep_learning/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Genomic ancestry inference with deep learning", 
            "url": "https://cloud.google.com/blog/big-data/2017/09/genomic-ancestry-inference-with-deep-learning"
        }, 
        {
            "author": "8solutions", 
            "created_utc": 1506984158.0, 
            "domain": "self.MachineLearning", 
            "id": "73wcfm", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73wcfm/d_face_detection_vs_bodypose_recognition/", 
            "score": 3, 
            "selftext": "I'm currently searching for a decent body/pose estimation model and am having no luck. The goal is to detect whether a person is standing, sitting, or prone (an additional stick figure estimation would be helpful, too). I'm surprised to find that many facial detection/recognition/tracking models are so readily available but there are simply no good MIT Licensed (or comparably permissive license) for pose estimation. Tools like OpenPose are all for research purposes only.\n\n\nPose estimation seems like a more common need than facial recognition, so I'm surprised by the lack of resources. Is this due to lack of datasets, interest, or is it just a much harder problem than facial tracking?", 
            "subreddit": "MachineLearning", 
            "title": "[D] Face detection vs body/pose recognition", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73wcfm/d_face_detection_vs_bodypose_recognition/"
        }, 
        {
            "author": "Adamworks", 
            "created_utc": 1506980042.0, 
            "domain": "github.com", 
            "id": "73vwyg", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73vwyg/p_2x_image_resolution_using_decisions_trees_in_r/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] 2x Image Resolution using Decisions Trees in R", 
            "url": "https://github.com/Adamishere/2xImageResolution"
        }, 
        {
            "author": "MetricSpade007", 
            "created_utc": 1506980010.0, 
            "domain": "research.google.com", 
            "id": "73vwu8", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "two", 
            "link_flair_text": "News", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73vwu8/n_google_ai_residency_2018_announced/", 
            "score": 17, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[N] Google AI Residency 2018 Announced", 
            "url": "https://research.google.com/teams/brain/residency/"
        }, 
        {
            "author": "brigadierfrog", 
            "created_utc": 1506975583.0, 
            "domain": "self.MachineLearning", 
            "id": "73vexo", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 14, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73vexo/d_resume_building_options/", 
            "score": 6, 
            "selftext": "In looking at various options to move my career path towards machine learning and its wide variety of potential positions I started by taking Andrew Ng's Coursera course just to see if it was something I'm actually interested in. I'm about half way through in a few weeks now and I'm pretty excited by what I'm learning and what I see as potential jobs.\n\nMost positions listed I've seen list a masters degree as a requirement. Not having one seems like an overly easy way for my resume to get filtered. \n\nPhysically going to a top ranked university near me in Chicago would easily cost me close to $100k over two years. Not to mention a great deal of time, energy, and stress in simply getting to/from school and working around the class schedules.\n\nUIUC offers a masters in data science through coursera for around $20k. While UIUC is a very reputable school, obtaining my degree remotely might have some unintended downsides. Number one being a lack of connections being built in the field. Number two being the large number of skeptics out there regarding online degrees.\n\nAs another option self learning is certainly something I enjoy doing and could perhaps tackle some online challenges and steer my daily work towards putting machine learning to use. I just don't know if having a nice set of historical work is enough to avoid the \"no masters\" trash pile I imagine exists.\n\nI would really love to hear what the community has done themselves and how well it has panned out.\n\nWere you able to find a great position without a masters? If so did you have a lot of historical work to show?\n\nIf you did go the graduate degree route, was it worth it? Did you find it useful in getting in the door a few years in or was it a moot point? Did you use connections made in school to get a position out of school or after?", 
            "subreddit": "MachineLearning", 
            "title": "[D] Resume Building Options", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73vexo/d_resume_building_options/"
        }, 
        {
            "author": "VishDev", 
            "created_utc": 1506970854.0, 
            "domain": "arxiv.org", 
            "id": "73uvd1", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73uvd1/r_on_the_capacity_of_face_representation/", 
            "score": 10, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] On the Capacity of Face Representation", 
            "url": "https://arxiv.org/abs/1709.10433"
        }, 
        {
            "author": "StrawberryNumberNine", 
            "created_utc": 1506967060.0, 
            "domain": "github.com", 
            "id": "73ug0k", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73ug0k/p_dockerface_an_easy_to_use_docker_solution_for/", 
            "score": 102, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Dockerface: An easy to use docker solution for deep learning face detection.", 
            "url": "https://github.com/natanielruiz/dockerface"
        }, 
        {
            "author": "dahelpta", 
            "created_utc": 1506958297.0, 
            "domain": "self.MachineLearning", 
            "id": "73thjg", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73thjg/d_struggling_to_even_get_interviews_can_someone/", 
            "score": 0, 
            "selftext": "I am struggling to get my first internship. I have a reasonable amount of projects, but no relevant work experience. I have applied to many various data related positions with no luck and I'm starting to get frustrated. The titles I usually apply to are data analyst, business analyst, and data scientist internships.\n\nWhat gets me is that I am not even being asked to go for an interview. It's fine if they interview me and don't approve of me, but I can't even get my foot in the door. At this point I'm starting to consider mailing my CV and cover letter directly to the domicile of manager level people at firms, but that is creepy.\n\nI must be doing something wrong with my CV or my cover letter. Can someone help me out? I'd love if people in the field have a quick look at my CV and about 4-5 cover letters I've written. If you're willing to help me, send me a PM with your email and we'll go from there.\n\nThanks in advance. Sorry for my distressed tone but this is starting to get to my head.", 
            "subreddit": "MachineLearning", 
            "title": "[D] Struggling to even get interviews, can someone look at my resume?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73thjg/d_struggling_to_even_get_interviews_can_someone/"
        }, 
        {
            "author": "urban_robot", 
            "created_utc": 1506955604.0, 
            "domain": "mubaris.com", 
            "id": "73t77q", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discusssion", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73t77q/d_kmeans_clustering_in_python_from_scratch/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[D] K-Means Clustering in Python from Scratch", 
            "url": "https://mubaris.com/2017-10-01/kmeans-clustering-in-python"
        }, 
        {
            "author": "DongjunLee", 
            "created_utc": 1506952690.0, 
            "domain": "github.com", 
            "id": "73swus", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73swus/p_charrnn_implements_by_tensorflow_13_version/", 
            "score": 6, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] char-rnn implements by Tensorflow 1.3 version Higher API (Estimator, Experiment, Dataset)", 
            "url": "https://github.com/DongjunLee/char-rnn-tensorflow"
        }, 
        {
            "author": "morgangiraud", 
            "created_utc": 1506948840.0, 
            "domain": "medium.com", 
            "id": "73sksc", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73sksc/p_why_the_least_square_error/", 
            "score": 12, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] why the Least Square Error", 
            "url": "https://medium.com/@morgangiraud/ml-notes-why-the-least-square-error-bf27fdd9a721"
        }, 
        {
            "author": "xingdongrobotics", 
            "created_utc": 1506944964.0, 
            "domain": "self.MachineLearning", 
            "id": "73sa8k", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73sa8k/d_reparameterization_mean_sigmastandard_normal/", 
            "score": 6, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[D] Reparameterization: mean + sigma*standard normal noise, the noise is N(0, 1) or N(0, I), i.e. each noise for all dimensions or individual dimension ?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73sa8k/d_reparameterization_mean_sigmastandard_normal/"
        }, 
        {
            "author": "newperson77777777", 
            "created_utc": 1506940998.0, 
            "domain": "self.MachineLearning", 
            "id": "73s0rd", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 19, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73s0rd/d_anyone_know_how_to_draw_pictures_of_a_specific/", 
            "score": 12, 
            "selftext": "As my question states, does anyone know how to draw pictures of CNN architectures (like specific drawing software or something)? It would be very helpful because a lot of papers have a visual image of the CNN and it helps to explain rather than describing without something concrete to reference.", 
            "subreddit": "MachineLearning", 
            "title": "[D] Anyone know how to draw pictures of a specific CNN (like to use in a paper)?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73s0rd/d_anyone_know_how_to_draw_pictures_of_a_specific/"
        }, 
        {
            "author": "algui91", 
            "created_utc": 1506938226.0, 
            "domain": "github.com", 
            "id": "73ruox", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73ruox/p_computing_similar_posts_for_a_blog_with_sklearn/", 
            "score": 2, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Computing similar posts for a blog with Sklearn", 
            "url": "https://github.com/elbaulp/hugo_similar_posts/"
        }, 
        {
            "author": "pmigdal", 
            "created_utc": 1506937922.0, 
            "domain": "youtube.com", 
            "id": "73ru14", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": {
                "oembed": {
                    "author_name": "Michal Kosinski", 
                    "author_url": "https://www.youtube.com/channel/UCysFUK85XkqGPzL6GWJGohg", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/DYhAM34Hhzc?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/DYhAM34Hhzc/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "The End of Privacy, Keynote at CeBIT'17", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73ru14/p_the_end_of_privacy_by_michal_kosinski_keynote/", 
            "score": 40, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] \"The End of Privacy\" by Michal Kosinski, Keynote at CeBIT'17 (personality from FB likes and photos)", 
            "url": "https://www.youtube.com/watch?v=DYhAM34Hhzc"
        }, 
        {
            "author": "carlthome", 
            "created_utc": 1506937589.0, 
            "domain": "self.MachineLearning", 
            "id": "73rtd7", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 52, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73rtd7/d_do_you_still_use_relu_if_so_why/", 
            "score": 45, 
            "selftext": "Aside from establishing baselines (where ReLU is useful for comparing with references), are there reasons not to use ELU instead (particularly the scaled variant with the right initialization)? Do you still use ReLU? If so, why?", 
            "subreddit": "MachineLearning", 
            "title": "[D] Do you still use ReLU? If so, why?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73rtd7/d_do_you_still_use_relu_if_so_why/"
        }, 
        {
            "author": "_jeerr", 
            "created_utc": 1506919551.0, 
            "domain": "tooploox.com", 
            "id": "73qrjg", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73qrjg/p_implementing_nn_in_swift_lessons_learned/", 
            "score": 10, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Implementing NN in Swift, lessons learned", 
            "url": "https://www.tooploox.com/blog/deep-neural-networks-in-swift-lessons-learned"
        }, 
        {
            "author": "downtownslim", 
            "created_utc": 1506917145.0, 
            "domain": "technologyreview.com", 
            "id": "73qky1", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 30, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73qky1/r_hinton_most_conferences_consist_of_making_minor/", 
            "score": 142, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] Hinton: \u201cMost conferences consist of making minor variations \u2026 as opposed to thinking hard and saying, 'What is it about what we're doing now that's really deficient? What does it have difficulty with? Let's focus on that.'\u201d", 
            "url": "https://www.technologyreview.com/s/608911/is-ai-riding-a-one-trick-pony/"
        }, 
        {
            "author": "xingdongrobotics", 
            "created_utc": 1506906687.0, 
            "domain": "self.MachineLearning", 
            "id": "73ppr8", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73ppr8/d_how_to_backprop_this_recursive_sequential/", 
            "score": 5, 
            "selftext": "Suppose we have a [computational graph like this](https://discuss.pytorch.org/uploads/default/original/2X/1/11b137f739e55da0dae10dcdedcafd07529461c5.png), how to correctly backprop gradients if we want to update policy parameters to reduce the total summed costs ?\n\nShould dynamics model and policy network accumulates gradients for each time the upward gradients comes in ? This can be decomposed into different cases as following: (For simplicity let us suppose only 2 time steps. )\n\n1. Compute J = c1 + c2 \nBackward: \n1.1): c1 -> dynamics model -> a0 -> policy\n1.2): c2 -> dynamics model -> [a1, s1] where a1 -> policy and s1 -> dynamics -> a0 -> policy\n\nThe gradients of dynamics and policy accumulated for each time upward gradients passing through. i.e. after 1.1), both dynamics and policy have gradients. During 1.2): when firstly pass through dynamics, the gradients computed and added to old gradients (from 1.1) and so on. \n\n2. Backward pass for each time step: backward of c1 -> clean gradients of dynamics and policy -> backward of c2, then sum up the gradients of policy in each individual backwards.\n\n3. Dynamics model not accumulating gradients, only to flow gradients when backward pass. But policy accumulate gradient. \n\n4. Neither dynamics nor policy accumulates any gradients. e.g. for c2, the gradients only obtained when it reaches policy network which generates a0, all other passes of dynamics and policy, just compute local gradients and flow the gradients, not to add up gradients with their `.grad`. \n\nIt is a bit confused which might be the correct way to do it. ", 
            "subreddit": "MachineLearning", 
            "title": "[D] How to backprop this recursive sequential computational graph ?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73ppr8/d_how_to_backprop_this_recursive_sequential/"
        }, 
        {
            "author": "Neutran", 
            "created_utc": 1506881780.0, 
            "domain": "self.MachineLearning", 
            "id": "73n9pm", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 168, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73n9pm/d_confession_as_an_ai_researcher_seeking_advice/", 
            "score": 559, 
            "selftext": "I have a confession to make.\n\nI was a CS major in college and took very few advanced math or stats courses. Besides basic calculus, linear algebra, and probability 101, I took only one machine learning class. It was about very specific SVMs/decision tree/probabilistic graphical models that I rarely encounter today.\n\nI joined a machine learning lab in college and was mentored by a senior PhD. We actually had a couple of publications together, though they were nothing but minor architecture changes. Now that I\u2019m in grad school doing AI research full-time, I thought I could continue to get away with zero math and clever lego building. Unfortunately, I fail to produce anything creative. What\u2019s worse, I find it increasingly hard to read some of the latest papers, which probably don\u2019t look complicated at all to math-minded students. The gap in my math/stats knowledge is taking a hefty toll on my career.\n\nFor example, I\u2019ve never heard of the term \u201cLipschitz\u201d or \u201cWasserstein distance\u201d before, so I\u2019m unable to digest the Wasserstein GAN paper, let alone invent something like that by myself. Same with f-GAN (https://arxiv.org/pdf/1606.00709.pdf), and SeLU (https://arxiv.org/pdf/1706.02515.pdf). I don\u2019t have the slightest clue what the 100-page SeLU proof is doing. The \u201cNormalizing Flow\u201d (https://arxiv.org/pdf/1505.05770.pdf) paper even involves physics (Langevin Flow, stochastic differential equation) \u2026 each term seems to require a semester-long course to master. I don\u2019t even know where to start wrapping my head around. \n\nI\u2019ve thought about potential solutions. The top-down approach is to google each unfamiliar jargon in the paper. That doesn\u2019t work at all because the explanation of 1 unknown points to 3 more unknowns. It\u2019s an exponential tree expansion. The alternative bottom-up approach is to read real analysis, functional analysis, probability theory textbooks. I prefer a systematic treatment, but \u2026 \n\n* reading takes a huge amount of time. I have the next conference deadline to meet, so I can\u2019t just set aside two months without producing anything. My advisor wouldn\u2019t be happy.\n* but if I don\u2019t read, my mindless lego building will not yield anything publishable for the next conference. What a chicken-and-egg vicious cycle. \n* the \u201cutility density\u201d of reading those 1000-page textbooks is very low. A lot of pages are not relevant, but I don\u2019t have an efficient way to sift them out. I understand that some knowledge *might* be useful *some day*, but the reward is too sparse to justify my attention budget. The vicious cycle kicks in again. \n* in the ideal world, I can query an **oracle** with \u201cLangevin flow\u201d. The oracle would return a list of pointers, \u201cgiven your current math capability, you should first read chapter 7 of Bishop\u2019s PRML book, and then chapter 10 of information theory, and then chapter 12 of \u2026\u201d. Google is not such an oracle for my purpose. \n\nI\u2019m willing to spend 1 - 2 hours a day to polish my math, but I need a more effective oracle. \nIs it just me, or does anyone else have the same frustration? \n\nEDIT: I'd appreciate it if someone could recommend *specific* books or MOOC series that focus more on **intuition and breadth**. Google lists tons of materials on real analysis, functional analysis, information theory, stochastic process, probability and measure theory, etc. Not all of them fit my use case, since I'm not seeking to redo a rigorous math major. Thanks in advance for any recommendation! \n\nEDIT: wow, I didn't expect so many people from different backgrounds to join the discussion. Looks like there are many who resonate with me! And thank you so much for all the great advice and recommendations. Please keep adding links, book titles, and your stories! This post might help another distraught researcher out of the [Valley](https://thesiswhisperer.com/2012/05/08/the-valley-of-shit/). ", 
            "subreddit": "MachineLearning", 
            "title": "[D] Confession as an AI researcher; seeking advice", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73n9pm/d_confession_as_an_ai_researcher_seeking_advice/"
        }, 
        {
            "author": "aviennn", 
            "created_utc": 1506873681.0, 
            "domain": "ashvin.me", 
            "id": "73mfr2", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73mfr2/r_overcoming_exploration_in_reinforcement/", 
            "score": 12, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] Overcoming Exploration in Reinforcement Learning with Demonstrations", 
            "url": "http://ashvin.me/demoddpg-website/"
        }, 
        {
            "author": "singlasahil14", 
            "created_utc": 1506837917.0, 
            "domain": "medium.com", 
            "id": "73k3j4", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 53, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73k3j4/p_a_new_kind_of_pooling_layer_for_faster_and/", 
            "score": 138, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] A new kind of pooling layer for faster and sharper convergence", 
            "url": "https://medium.com/@singlasahil14/a-new-kind-of-pooling-layer-for-faster-and-sharper-convergence-1043c756a221"
        }, 
        {
            "author": "cthulhu_loves_us", 
            "created_utc": 1506822243.0, 
            "domain": "self.MachineLearning", 
            "id": "73iyqz", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73iyqz/d_good_sources_for_personality_analysis/", 
            "score": 0, 
            "selftext": "Hey all. \n\nI'm doing a design project that involves personality analysis. From the writing that is submitted I have to be able to break down an analysis of the author's personality into five factors (Five Factors: Openness, Conscientiousness, Extroversion, Agreeableness and Neuroticism). I have training data available to me. But I'm not sure of where to start with the research or methods. Does anyone have any good starting points for the learning I need to do for this project? ", 
            "subreddit": "MachineLearning", 
            "title": "[D] Good sources for Personality Analysis?", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73iyqz/d_good_sources_for_personality_analysis/"
        }, 
        {
            "author": "evc123", 
            "created_utc": 1506819907.0, 
            "domain": "dropbox.com", 
            "id": "73irvm", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 18, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73irvm/r_durk_kingmas_thesis_variational_inference_and/", 
            "score": 88, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] Durk Kingma's thesis: \"Variational Inference and Deep Learning: A New Synthesis\"", 
            "url": "https://www.dropbox.com/s/v6ua3d9yt44vgb3/cover_and_thesis.pdf?dl=0"
        }
    ], 
    "subreddit_creation_utc": 1248906884.0, 
    "subscribers": 139812, 
    "title": "Machine Learning", 
    "title_word_count_occurrences": {
        "amazon": 1, 
        "deep learning": 8, 
        "docker": 1, 
        "facebook": 1, 
        "google": 3, 
        "machine learning": 4, 
        "python": 2, 
        "swift": 1, 
        "tex": 2
    }, 
    "top_score_submissions": [
        {
            "author": "e_walker", 
            "created_utc": 1507125950.0, 
            "domain": "i.redd.it", 
            "id": "748cco", 
            "is_reddit_media_domain": true, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 91, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/748cco/r_neural_color_transfer_between_images/", 
            "score": 2035, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] Neural Color Transfer between Images", 
            "url": "https://i.redd.it/1qync11pltpz.jpg"
        }, 
        {
            "author": "Neutran", 
            "created_utc": 1506881780.0, 
            "domain": "self.MachineLearning", 
            "id": "73n9pm", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "one", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 168, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/73n9pm/d_confession_as_an_ai_researcher_seeking_advice/", 
            "score": 559, 
            "selftext": "I have a confession to make.\n\nI was a CS major in college and took very few advanced math or stats courses. Besides basic calculus, linear algebra, and probability 101, I took only one machine learning class. It was about very specific SVMs/decision tree/probabilistic graphical models that I rarely encounter today.\n\nI joined a machine learning lab in college and was mentored by a senior PhD. We actually had a couple of publications together, though they were nothing but minor architecture changes. Now that I\u2019m in grad school doing AI research full-time, I thought I could continue to get away with zero math and clever lego building. Unfortunately, I fail to produce anything creative. What\u2019s worse, I find it increasingly hard to read some of the latest papers, which probably don\u2019t look complicated at all to math-minded students. The gap in my math/stats knowledge is taking a hefty toll on my career.\n\nFor example, I\u2019ve never heard of the term \u201cLipschitz\u201d or \u201cWasserstein distance\u201d before, so I\u2019m unable to digest the Wasserstein GAN paper, let alone invent something like that by myself. Same with f-GAN (https://arxiv.org/pdf/1606.00709.pdf), and SeLU (https://arxiv.org/pdf/1706.02515.pdf). I don\u2019t have the slightest clue what the 100-page SeLU proof is doing. The \u201cNormalizing Flow\u201d (https://arxiv.org/pdf/1505.05770.pdf) paper even involves physics (Langevin Flow, stochastic differential equation) \u2026 each term seems to require a semester-long course to master. I don\u2019t even know where to start wrapping my head around. \n\nI\u2019ve thought about potential solutions. The top-down approach is to google each unfamiliar jargon in the paper. That doesn\u2019t work at all because the explanation of 1 unknown points to 3 more unknowns. It\u2019s an exponential tree expansion. The alternative bottom-up approach is to read real analysis, functional analysis, probability theory textbooks. I prefer a systematic treatment, but \u2026 \n\n* reading takes a huge amount of time. I have the next conference deadline to meet, so I can\u2019t just set aside two months without producing anything. My advisor wouldn\u2019t be happy.\n* but if I don\u2019t read, my mindless lego building will not yield anything publishable for the next conference. What a chicken-and-egg vicious cycle. \n* the \u201cutility density\u201d of reading those 1000-page textbooks is very low. A lot of pages are not relevant, but I don\u2019t have an efficient way to sift them out. I understand that some knowledge *might* be useful *some day*, but the reward is too sparse to justify my attention budget. The vicious cycle kicks in again. \n* in the ideal world, I can query an **oracle** with \u201cLangevin flow\u201d. The oracle would return a list of pointers, \u201cgiven your current math capability, you should first read chapter 7 of Bishop\u2019s PRML book, and then chapter 10 of information theory, and then chapter 12 of \u2026\u201d. Google is not such an oracle for my purpose. \n\nI\u2019m willing to spend 1 - 2 hours a day to polish my math, but I need a more effective oracle. \nIs it just me, or does anyone else have the same frustration? \n\nEDIT: I'd appreciate it if someone could recommend *specific* books or MOOC series that focus more on **intuition and breadth**. Google lists tons of materials on real analysis, functional analysis, information theory, stochastic process, probability and measure theory, etc. Not all of them fit my use case, since I'm not seeking to redo a rigorous math major. Thanks in advance for any recommendation! \n\nEDIT: wow, I didn't expect so many people from different backgrounds to join the discussion. Looks like there are many who resonate with me! And thank you so much for all the great advice and recommendations. Please keep adding links, book titles, and your stories! This post might help another distraught researcher out of the [Valley](https://thesiswhisperer.com/2012/05/08/the-valley-of-shit/). ", 
            "subreddit": "MachineLearning", 
            "title": "[D] Confession as an AI researcher; seeking advice", 
            "url": "https://www.reddit.com/r/MachineLearning/comments/73n9pm/d_confession_as_an_ai_researcher_seeking_advice/"
        }, 
        {
            "author": "finallyifoundvalidUN", 
            "created_utc": 1507218671.0, 
            "domain": "youtu.be", 
            "id": "74gual", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "two", 
            "link_flair_text": "News", 
            "media": {
                "oembed": {
                    "author_name": "3Blue1Brown", 
                    "author_url": "https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/aircAruvnKk?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/aircAruvnKk/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "But what *is* a Neural Network? | Deep learning, Part 1", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 51, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74gual/n_its_here_but_what_is_a_neural_network_deep/", 
            "score": 423, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[N] It's here! \"But what *is* a Neural Network? | Deep learning, Part 1", 
            "url": "https://youtu.be/aircAruvnKk"
        }, 
        {
            "author": "fhuszar", 
            "created_utc": 1507213018.0, 
            "domain": "inference.vc", 
            "id": "74g8ee", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "three", 
            "link_flair_text": "Research", 
            "media": null, 
            "num_comments": 37, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/74g8ee/r_gans_are_broken_in_more_than_one_way_review_of/", 
            "score": 186, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[R] GANs are Broken in More Than One Way: review of \"The Numerics of GANs\"", 
            "url": "http://www.inference.vc/my-notes-on-the-numerics-of-gans/"
        }, 
        {
            "author": "Reiinakano", 
            "created_utc": 1507059365.0, 
            "domain": "teachablemachine.withgoogle.com", 
            "id": "742t3y", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "four", 
            "link_flair_text": "Project", 
            "media": null, 
            "num_comments": 31, 
            "num_crossposts": 0, 
            "permalink": "/r/MachineLearning/comments/742t3y/p_teachable_machine_teach_a_machine_using_your/", 
            "score": 159, 
            "selftext": "", 
            "subreddit": "MachineLearning", 
            "title": "[P] Teachable Machine: Teach a machine using your camera, live in the browser. No coding required.", 
            "url": "https://teachablemachine.withgoogle.com/"
        }
    ], 
    "total_submissions": 89, 
    "utc_of_data_collection_start": "2017-10-16 18:38:15"
}