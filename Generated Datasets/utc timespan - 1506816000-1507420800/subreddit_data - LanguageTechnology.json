{
    "active_user_count": 10, 
    "advertiser_category": null, 
    "audience_target": "", 
    "avg_comment_num_per_submission": 1, 
    "avg_submission_score": 5, 
    "collection_range_end_unix_timestamp": 1507420800, 
    "collection_range_end_utc": "2017-10-08 00:00:00", 
    "collection_range_start_unix_timestamp": 1506816000, 
    "collection_range_start_utc": "2017-10-01 00:00:00", 
    "description": "Articles on natural language processing.", 
    "display_name": "LanguageTechnology", 
    "domain_occurrences": {
        "alpha.spacy.io": 1, 
        "github.com": 1, 
        "gitsuggest.com": 1, 
        "machinelearningmastery.com": 1, 
        "nlp.cogcomp.org": 1, 
        "self.LanguageTechnology": 5, 
        "techcrunch.com": 1, 
        "youtube.com": 1
    }, 
    "id": "2rkr2", 
    "num_external_website_posts": 7, 
    "num_text_posts": 5, 
    "public_description": "", 
    "submissions": [
        {
            "author": "Kyeo1983", 
            "created_utc": 1507390677.0, 
            "domain": "self.LanguageTechnology", 
            "id": "74vjcf", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/74vjcf/please_advice_on_key_sentence_extraction/", 
            "score": 2, 
            "selftext": "Hi, can anyone kindly point me to relevant materials or products to do key sentences extraction from documents?\n\nIn my use case, I have many documents written by our researchers. And I'd like to run automation over them to extract key sentences around certain areas, like key risks, key opportunities, key challenges etc. For example, a document might have a few bullet points talking about some risk factors, with subsequent pages elaborating on them. In this case, I'd like to extract those bullets points as they are already in a summarised way representative of the content.\n\nThank you. ", 
            "subreddit": "LanguageTechnology", 
            "title": "Please advice on Key Sentence Extraction techniques", 
            "url": "https://www.reddit.com/r/LanguageTechnology/comments/74vjcf/please_advice_on_key_sentence_extraction/"
        }, 
        {
            "author": "danielcer", 
            "created_utc": 1507389768.0, 
            "domain": "github.com", 
            "id": "74vg91", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/74vg91/sequence_pair_classification_using/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "LanguageTechnology", 
            "title": "Sequence Pair Classification using Sequence-Semantic-Embeddings (SSE), an encoder toolkit for NLP.", 
            "url": "https://github.com/eBay/Sequence-Semantic-Embedding"
        }, 
        {
            "author": "Kyeo1983", 
            "created_utc": 1507389735.0, 
            "domain": "self.LanguageTechnology", 
            "id": "74vg58", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/74vg58/how_likely_able_to_classify_type_of_documents/", 
            "score": 1, 
            "selftext": "Hi, I'm considering this from an Enterprise perspective. My organisation of course, has mountains of documents. Among which some are useful, like Policy PDFs, Key Presentation PPTX, Digital Contracts DOCX etc. And a lot of less useful content like draft papers, temp textual notes, weekly meeting minutes kind of stuff. \n\nHow likely am I able to apply ML to classify the importance of my new content based on knowledge of these existing ones? Like, should the ML be trying to learn the structure of official documents or detect certain keywords in the filename?\n\nHope someone can help to give some suggestions on how I could proceed to achieve this. Thank you! \n\n", 
            "subreddit": "LanguageTechnology", 
            "title": "How likely able to classify type of documents?", 
            "url": "https://www.reddit.com/r/LanguageTechnology/comments/74vg58/how_likely_able_to_classify_type_of_documents/"
        }, 
        {
            "author": "suriname0", 
            "created_utc": 1507321258.0, 
            "domain": "machinelearningmastery.com", 
            "id": "74qabc", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/74qabc/how_to_develop_word_embeddings_in_python_with/", 
            "score": 8, 
            "selftext": "", 
            "subreddit": "LanguageTechnology", 
            "title": "How to Develop Word Embeddings in Python with Gensim", 
            "url": "https://machinelearningmastery.com/develop-word-embeddings-python-gensim/"
        }, 
        {
            "author": "syllogism_", 
            "created_utc": 1507210123.0, 
            "domain": "alpha.spacy.io", 
            "id": "74fxyp", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/74fxyp/new_models_for_spacy_2_alpha_now_near/", 
            "score": 21, 
            "selftext": "", 
            "subreddit": "LanguageTechnology", 
            "title": "New models for spaCy 2 alpha -- now near state-of-the-art (NER: 86.4 F on OntoNotes; parsing: 94.4 UAS on WSJ)", 
            "url": "https://alpha.spacy.io/models/"
        }, 
        {
            "author": "smorac", 
            "created_utc": 1507158119.0, 
            "domain": "techcrunch.com", 
            "id": "74bxh6", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/74bxh6/rasa_core_kicks_up_the_context_for_chatbots/", 
            "score": 8, 
            "selftext": "", 
            "subreddit": "LanguageTechnology", 
            "title": "Rasa Core kicks up the context for chatbots", 
            "url": "https://techcrunch.com/2017/10/04/rasa-core-kicks-up-the-context-for-chatbots/"
        }, 
        {
            "author": "danieljj", 
            "created_utc": 1507087137.0, 
            "domain": "nlp.cogcomp.org", 
            "id": "745jus", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/745jus/almost_anything_you_want_in_one_demo/", 
            "score": 5, 
            "selftext": "", 
            "subreddit": "LanguageTechnology", 
            "title": "Almost anything you want, in one demo.", 
            "url": "http://nlp.cogcomp.org"
        }, 
        {
            "author": "sentient_machine", 
            "created_utc": 1506937687.0, 
            "domain": "self.LanguageTechnology", 
            "id": "73rtjl", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/73rtjl/question_on_document_frequency_thresholding/", 
            "score": 2, 
            "selftext": "I posted [a question](https://www.reddit.com/r/LanguageTechnology/comments/6ygw5j/anyone_here_familiar_with_document_frequency/) a while ago here. There I asked about a technique called document frequency thresholding (DF thresholding) to decide whether certain features (terms) really contribute to the classification or not by looking at its document frequency (DF). As suggested I apply what I understand on my dataset using scikit-learn and apparently the library has provided what I need in the form of min_df and max_df on their [TFIDF Vectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html), it doesn't improve much of the accuracy.\n\nBut anyway, I talked to my professor again and apparently that's not what he meant when he told me to try DF Thresholding. He referred me to [this paper](http://journal.uad.ac.id/index.php/TELKOMNIKA/article/download/536/pdf_44) on the subchapter \"A Feature Selection Method Based on Document Frequency improved\". The paper explained the 3 formula used on this method, *Concentration degree, Disperse degree* and *Contribution degree*. I think there's a mistake on the final formula which makes it a little confusing, so I decided to look further. I tried to find other papers on the subject, but strangely enough, I couldn't find any! I couldn't seem to find any paper that mentions this kind of technique that use concentration, disperse, and contribution degrees. Not even on the referenced papers on the paper I mentioned above. I've tried to use Google Scholar, Research Gate, IEEE, there's no similar paper I could find, it really baffled me. I've expressed my confusion to my professor but he still insisted that the formula on the paper he referred to was clear enough and that I should try to work on it first. Now I am completely stuck here, I am supposed to meet with him again in a few days and before that I just want to clear this out.\n\nMaybe you guys can take a look at the paper I linked above and who knows maybe anyone here is familiar with the technique? And maybe it has a different name that I am not aware of? Thanks!", 
            "subreddit": "LanguageTechnology", 
            "title": "Question on Document Frequency Thresholding", 
            "url": "https://www.reddit.com/r/LanguageTechnology/comments/73rtjl/question_on_document_frequency_thresholding/"
        }, 
        {
            "author": "c5urf3r", 
            "created_utc": 1506918463.0, 
            "domain": "gitsuggest.com", 
            "id": "73qor6", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/73qor6/flask_app_using_lda_to_suggest_github/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "LanguageTechnology", 
            "title": "Flask app using LDA to suggest GitHub repositories based on what you have starred.", 
            "url": "http://www.gitsuggest.com"
        }, 
        {
            "author": "rameshkjes", 
            "created_utc": 1506882929.0, 
            "domain": "self.LanguageTechnology", 
            "id": "73ne11", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/73ne11/how_to_display_dependency_tree_in_spacy_using/", 
            "score": 3, 
            "selftext": "I can check dependency tree using displaCy : https://demos.explosion.ai/displacy/\n\nBut I want to display using program in spacy, is it possible? \n\nI can check individual components such as ROOT, nsub etc. from sentence using spacy, but i want to check complete dependency tree. \n", 
            "subreddit": "LanguageTechnology", 
            "title": "How to display dependency tree in spacy using program?", 
            "url": "https://www.reddit.com/r/LanguageTechnology/comments/73ne11/how_to_display_dependency_tree_in_spacy_using/"
        }, 
        {
            "author": "rameshkjes", 
            "created_utc": 1506873349.0, 
            "domain": "self.LanguageTechnology", 
            "id": "73meii", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/73meii/how_syntactic_dependencies_is_useful_in_word/", 
            "score": 1, 
            "selftext": "I am reading research paper \"Back to Basics for Monolingual Alignment: Exploiting Word Similarity and Contextual Evidence\" , and author is performing syntactic dependencies, but I am unable to find reason how it is useful for alignment of words", 
            "subreddit": "LanguageTechnology", 
            "title": "How Syntactic Dependencies is useful in word alignment for textual similarity?", 
            "url": "https://www.reddit.com/r/LanguageTechnology/comments/73meii/how_syntactic_dependencies_is_useful_in_word/"
        }, 
        {
            "author": "his_laziness", 
            "created_utc": 1506826625.0, 
            "domain": "youtube.com", 
            "id": "73jbdc", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "Vikas Desai", 
                    "author_url": "https://www.youtube.com/channel/UC9bVLRHt2bO8EG500IkE18g", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/_j7KGOAJv5Y?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/_j7KGOAJv5Y/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "Bringing AI to the Cybersecurity Battle - SICW 2017", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/73jbdc/ibm_watson_being_used_for_cybersecurity_is_this/", 
            "score": 2, 
            "selftext": "", 
            "subreddit": "LanguageTechnology", 
            "title": "IBM Watson being used for Cybersecurity. Is this NLP?", 
            "url": "https://www.youtube.com/watch?v=_j7KGOAJv5Y"
        }
    ], 
    "subreddit_creation_utc": 1268268150.0, 
    "subscribers": 8169, 
    "title": "Natural Language Processing", 
    "title_word_count_occurrences": {
        "flask": 1, 
        "github": 1, 
        "ibm": 1, 
        "python": 1, 
        "tex": 2, 
        "watson": 1
    }, 
    "top_score_submissions": [
        {
            "author": "syllogism_", 
            "created_utc": 1507210123.0, 
            "domain": "alpha.spacy.io", 
            "id": "74fxyp", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/74fxyp/new_models_for_spacy_2_alpha_now_near/", 
            "score": 21, 
            "selftext": "", 
            "subreddit": "LanguageTechnology", 
            "title": "New models for spaCy 2 alpha -- now near state-of-the-art (NER: 86.4 F on OntoNotes; parsing: 94.4 UAS on WSJ)", 
            "url": "https://alpha.spacy.io/models/"
        }, 
        {
            "author": "suriname0", 
            "created_utc": 1507321258.0, 
            "domain": "machinelearningmastery.com", 
            "id": "74qabc", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/74qabc/how_to_develop_word_embeddings_in_python_with/", 
            "score": 8, 
            "selftext": "", 
            "subreddit": "LanguageTechnology", 
            "title": "How to Develop Word Embeddings in Python with Gensim", 
            "url": "https://machinelearningmastery.com/develop-word-embeddings-python-gensim/"
        }, 
        {
            "author": "smorac", 
            "created_utc": 1507158119.0, 
            "domain": "techcrunch.com", 
            "id": "74bxh6", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/74bxh6/rasa_core_kicks_up_the_context_for_chatbots/", 
            "score": 8, 
            "selftext": "", 
            "subreddit": "LanguageTechnology", 
            "title": "Rasa Core kicks up the context for chatbots", 
            "url": "https://techcrunch.com/2017/10/04/rasa-core-kicks-up-the-context-for-chatbots/"
        }, 
        {
            "author": "danielcer", 
            "created_utc": 1507389768.0, 
            "domain": "github.com", 
            "id": "74vg91", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/74vg91/sequence_pair_classification_using/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "LanguageTechnology", 
            "title": "Sequence Pair Classification using Sequence-Semantic-Embeddings (SSE), an encoder toolkit for NLP.", 
            "url": "https://github.com/eBay/Sequence-Semantic-Embedding"
        }, 
        {
            "author": "c5urf3r", 
            "created_utc": 1506918463.0, 
            "domain": "gitsuggest.com", 
            "id": "73qor6", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/LanguageTechnology/comments/73qor6/flask_app_using_lda_to_suggest_github/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "LanguageTechnology", 
            "title": "Flask app using LDA to suggest GitHub repositories based on what you have starred.", 
            "url": "http://www.gitsuggest.com"
        }
    ], 
    "total_submissions": 12, 
    "utc_of_data_collection_start": "2017-10-16 18:37:02"
}