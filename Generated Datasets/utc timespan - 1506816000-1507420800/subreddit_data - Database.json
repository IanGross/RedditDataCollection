{
    "active_user_count": 33, 
    "advertiser_category": null, 
    "audience_target": "", 
    "avg_comment_num_per_submission": 4, 
    "avg_submission_score": 7, 
    "collection_range_end_unix_timestamp": 1507420800, 
    "collection_range_end_utc": "2017-10-08 00:00:00", 
    "collection_range_start_unix_timestamp": 1506816000, 
    "collection_range_start_utc": "2017-10-01 00:00:00", 
    "description": "* Data and database centric technologies\n* Open and closed source database systems\n* Related technologies including NOSQL (NotOnlySQL)\n\n---\n\nRelated Reddits:\n\n* /r/ETL\n* /r/BusinessIntelligence\n* /r/Datasets\n* /r/nosql\n\n---\n\n**This is a knowledge sharing forum, not a help, how-to, or homework forum, *and such questions are likely to be removed*.**\n\n**Try** [/r/DatabaseHelp](http://www.reddit.com/r/DatabaseHelp/) **instead!**\n\n---\n\nPlatforms:\n\n* /r/MSAccess\n* /r/BigQuery\n* /r/Cassandra\n* /r/CouchDB\n* /r/DB2\n* /r/firebird\n* /r/mariadb\n* /r/MongoDB\n* /r/MySQL\n* /r/Oracle\n* /r/PostgreSQL\n* /r/Redis\n* /r/SQLServer\n\n---", 
    "display_name": "Database", 
    "domain_occurrences": {
        "blog.jooq.org": 1, 
        "crate.io": 1, 
        "postgresql.org": 1, 
        "self.Database": 7, 
        "youtu.be": 1
    }, 
    "id": "2qian", 
    "num_external_website_posts": 4, 
    "num_text_posts": 7, 
    "public_description": "", 
    "submissions": [
        {
            "author": "tornfm", 
            "created_utc": 1507374735.0, 
            "domain": "self.Database", 
            "id": "74ua9g", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/74ua9g/howwhere_can_i_save_lots_of_urls_into_a_sensible/", 
            "score": 6, 
            "selftext": "Context: I'm currently saving a large number of news article URL links to an excel spreadsheet and tagging them with numerous relevant tags e.g politics, education, etc. \n\nI currently view each article online and then look at if I should keep it. Then I copy and paste the URL and add it into excel and then tag it multiple times. It's time consuming and I'm sure there is a better more automated way. \n\nI'm not technical, so please excuse any apparent ignorance in how I'm asking this.\n\nI'd really like to be able to:\n\n- save the links as I read them ideally with a page plugin (like Pocket) that sends them to a database\n- Select the tags I want for the article there and then\n- Easily search the database I've made for relevant articles I've saved on a later date\n\nWhat programme/plugin/database tool would you advise I look into using? And/or how would you advise I make the above happen?\n\nMany thanks for any thoughts\n", 
            "subreddit": "Database", 
            "title": "How/where can I save lots of URLs into a sensible and easy-to-view database?", 
            "url": "https://www.reddit.com/r/Database/comments/74ua9g/howwhere_can_i_save_lots_of_urls_into_a_sensible/"
        }, 
        {
            "author": "Pondium", 
            "created_utc": 1507358210.0, 
            "domain": "self.Database", 
            "id": "74tdcw", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/74tdcw/database_security_concern/", 
            "score": 1, 
            "selftext": "Greetings and thanks in advance for your assistance. I recently accepted a job doing database work for a company that tracks and organizes their clients. I have only been working two weeks so I am a little worried I made a mistake. I accidentally accessed a confidential file and closed out immediately without reading any of it. Is it possible that my employer will know about this? I can't find a search history anywhere in the database. We use PRM - Partner Relationship Management. ", 
            "subreddit": "Database", 
            "title": "Database Security Concern", 
            "url": "https://www.reddit.com/r/Database/comments/74tdcw/database_security_concern/"
        }, 
        {
            "author": "TracyDream", 
            "created_utc": 1507316836.0, 
            "domain": "youtu.be", 
            "id": "74psxi", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "GK", 
                    "author_url": "https://www.youtube.com/channel/UCx9ekJlsGao1NFfOougXMzg", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/YiavTuwKP40?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/YiavTuwKP40/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "Java Vs Python - Which is easier to use?", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/74psxi/python_vs_java/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "Database", 
            "title": "Python vs Java", 
            "url": "https://youtu.be/YiavTuwKP40"
        }, 
        {
            "author": "khazarboy123", 
            "created_utc": 1507312290.0, 
            "domain": "self.Database", 
            "id": "74pb24", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 18, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/74pb24/what_is_the_proper_way_to_track_schema_changes/", 
            "score": 1, 
            "selftext": "I've been searching around and I see a lot of different strategies for tracking how database schemas change over time. Some people write their own migration scripts, some use a big/expensive enterprise solution ([red-gate](https://www.red-gate.com/?gclid=Cj0KCQjw09zOBRCqARIsAH8XF1Zh7EtvMWoKwgMDsTZx5hwp7g9kwDT30Pu1sobJjGwk9LV_VdwOAD0aAiWkEALw_wcB), etc). I even ran across stuff like this: [hyperclone.com](https://hyperclone.com), which seems interesting but I'm just not sure.\n Is there a proper way to do this stuff? Or is it a matter of personal preference? I'd love to hear your responses.", 
            "subreddit": "Database", 
            "title": "what is the proper way to track schema changes for SQL databases?", 
            "url": "https://www.reddit.com/r/Database/comments/74pb24/what_is_the_proper_way_to_track_schema_changes/"
        }, 
        {
            "author": "doublehyphen", 
            "created_utc": 1507210800.0, 
            "domain": "postgresql.org", 
            "id": "74g0dd", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/74g0dd/postgresql_10_released/", 
            "score": 32, 
            "selftext": "", 
            "subreddit": "Database", 
            "title": "PostgreSQL 10 Released", 
            "url": "https://www.postgresql.org/about/news/1786/"
        }, 
        {
            "author": "ElektroSam", 
            "created_utc": 1507139682.0, 
            "domain": "self.Database", 
            "id": "749vph", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/749vph/hypothetically_could_i_use_guids_like/", 
            "score": 2, 
            "selftext": "00000000-0000-0000-0000-00000000 \n00000000-0000-0000-0000-00000001\n\nOr is there a rule where 00000000-0000-0000-0000-00000000 is invalid!?\n\nI won't be doing it. Just interested. ", 
            "subreddit": "Database", 
            "title": "Hypothetically could I use guids like...", 
            "url": "https://www.reddit.com/r/Database/comments/749vph/hypothetically_could_i_use_guids_like/"
        }, 
        {
            "author": "nslater", 
            "created_utc": 1507133879.0, 
            "domain": "crate.io", 
            "id": "7497va", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/7497va/new_with_cratedb_22_mqtt_prometheus_telegraf_and/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "Database", 
            "title": "New with CrateDB 2.2 - MQTT, Prometheus, Telegraf, and SSL", 
            "url": "https://crate.io/a/cratedb-mqtt-prometheus-telegraf-ssl/"
        }, 
        {
            "author": "00mba", 
            "created_utc": 1507130687.0, 
            "domain": "self.Database", 
            "id": "748urf", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/748urf/looking_for_a_programming_library_net_or_js_to/", 
            "score": 3, 
            "selftext": "Hi All, \n\nWe are developing a piece of engineering software that needs to do complex calculations on data we are pulling from petrochem plant models. I am wondering if anyone knows of libraries out there for the dotnet or javascript languages that can manipulate data in a similar fashion to PowerPivot for Microsoft Excel. \n\nBasically we are pulling a ton of data from an SQL database, and then manipulating it with powerpivot, and we would like to abstract this out into our own software so we are not reliant on MS Office.\n\nAny help appreciated\n\nThanks", 
            "subreddit": "Database", 
            "title": "Looking for a programming library (.net or jS) to work with data tables, similar to power pivot", 
            "url": "https://www.reddit.com/r/Database/comments/748urf/looking_for_a_programming_library_net_or_js_to/"
        }, 
        {
            "author": "daigoba66", 
            "created_utc": 1507054950.0, 
            "domain": "blog.jooq.org", 
            "id": "742b2o", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/742b2o/10_cool_sql_optimisations_that_do_not_depend_on/", 
            "score": 22, 
            "selftext": "", 
            "subreddit": "Database", 
            "title": "10 Cool SQL Optimisations That do not Depend on the Cost Model", 
            "url": "https://blog.jooq.org/2017/09/28/10-cool-sql-optimisations-that-do-not-depend-on-the-cost-model/"
        }, 
        {
            "author": "geo_prog", 
            "created_utc": 1506892621.0, 
            "domain": "self.Database", 
            "id": "73odou", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/73odou/need_help_deciding_on_how_to_tackle_multiple/", 
            "score": 6, 
            "selftext": "Hi guys, I'm not going to ask for a complete schema or anything but I'm trying to figure out the best way to sort out how to create a database system for a project at work.\n\nA little background on what I need to make happen before I will ask the actual question:\n\nI work for a service company that provides information on field operations for multiple different oil and gas production companies. Our clients want to have a website where they can log in to their account, see which rigs we are managing and current information on said rigs.\n\nI need to link each well drilled to the company that paid for it to be drilled. However in many cases each well may be revisited 3 or 4 times in its lifetime and each time may have a different rig assigned to it, or different operations performed on it. \n\nWhere it starts to get complicated is that we need to have running data kept up to date on all of these wells that are being drilled concurrently at 0.2m increments (on wells that exceed 16000m at times) that can be queried to produce graphs of where the well is placed, the geophysical readings, penetration rate etc. \n\nShould I organize each well into its own database and keep tables for all of the pertinent information, should I have one database for each client and have huge tables for each datatype that is queried by a combination of well identifier and date, or should there be one monolithic database that keeps track of all this information for all client companies and their data and queries the data out as needed based on login credentials and selected well?\n\nOur calculations indicate that if there is one single table for all logged data, that table would grow by about 200 million records per year. \n\nI hope this was clear. I'm not great at explaining sometimes.", 
            "subreddit": "Database", 
            "title": "Need help deciding on how to tackle multiple user/multiple project database", 
            "url": "https://www.reddit.com/r/Database/comments/73odou/need_help_deciding_on_how_to_tackle_multiple/"
        }, 
        {
            "author": "boneskeller", 
            "created_utc": 1506872704.0, 
            "domain": "self.Database", 
            "id": "73mc7f", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/73mc7f/what_does_an_enterprise_arangodb_subscription_cost/", 
            "score": 0, 
            "selftext": "trying to get a ballpark figure", 
            "subreddit": "Database", 
            "title": "What does an enterprise ArangoDB subscription cost?", 
            "url": "https://www.reddit.com/r/Database/comments/73mc7f/what_does_an_enterprise_arangodb_subscription_cost/"
        }
    ], 
    "subreddit_creation_utc": 1212109332.0, 
    "subscribers": 14614, 
    "title": "Database", 
    "title_word_count_occurrences": {
        ".net": 1, 
        "java": 1, 
        "python": 1, 
        "sql": 3
    }, 
    "top_score_submissions": [
        {
            "author": "doublehyphen", 
            "created_utc": 1507210800.0, 
            "domain": "postgresql.org", 
            "id": "74g0dd", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/74g0dd/postgresql_10_released/", 
            "score": 32, 
            "selftext": "", 
            "subreddit": "Database", 
            "title": "PostgreSQL 10 Released", 
            "url": "https://www.postgresql.org/about/news/1786/"
        }, 
        {
            "author": "daigoba66", 
            "created_utc": 1507054950.0, 
            "domain": "blog.jooq.org", 
            "id": "742b2o", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/742b2o/10_cool_sql_optimisations_that_do_not_depend_on/", 
            "score": 22, 
            "selftext": "", 
            "subreddit": "Database", 
            "title": "10 Cool SQL Optimisations That do not Depend on the Cost Model", 
            "url": "https://blog.jooq.org/2017/09/28/10-cool-sql-optimisations-that-do-not-depend-on-the-cost-model/"
        }, 
        {
            "author": "nslater", 
            "created_utc": 1507133879.0, 
            "domain": "crate.io", 
            "id": "7497va", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/7497va/new_with_cratedb_22_mqtt_prometheus_telegraf_and/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "Database", 
            "title": "New with CrateDB 2.2 - MQTT, Prometheus, Telegraf, and SSL", 
            "url": "https://crate.io/a/cratedb-mqtt-prometheus-telegraf-ssl/"
        }, 
        {
            "author": "tornfm", 
            "created_utc": 1507374735.0, 
            "domain": "self.Database", 
            "id": "74ua9g", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/74ua9g/howwhere_can_i_save_lots_of_urls_into_a_sensible/", 
            "score": 6, 
            "selftext": "Context: I'm currently saving a large number of news article URL links to an excel spreadsheet and tagging them with numerous relevant tags e.g politics, education, etc. \n\nI currently view each article online and then look at if I should keep it. Then I copy and paste the URL and add it into excel and then tag it multiple times. It's time consuming and I'm sure there is a better more automated way. \n\nI'm not technical, so please excuse any apparent ignorance in how I'm asking this.\n\nI'd really like to be able to:\n\n- save the links as I read them ideally with a page plugin (like Pocket) that sends them to a database\n- Select the tags I want for the article there and then\n- Easily search the database I've made for relevant articles I've saved on a later date\n\nWhat programme/plugin/database tool would you advise I look into using? And/or how would you advise I make the above happen?\n\nMany thanks for any thoughts\n", 
            "subreddit": "Database", 
            "title": "How/where can I save lots of URLs into a sensible and easy-to-view database?", 
            "url": "https://www.reddit.com/r/Database/comments/74ua9g/howwhere_can_i_save_lots_of_urls_into_a_sensible/"
        }, 
        {
            "author": "geo_prog", 
            "created_utc": 1506892621.0, 
            "domain": "self.Database", 
            "id": "73odou", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/Database/comments/73odou/need_help_deciding_on_how_to_tackle_multiple/", 
            "score": 6, 
            "selftext": "Hi guys, I'm not going to ask for a complete schema or anything but I'm trying to figure out the best way to sort out how to create a database system for a project at work.\n\nA little background on what I need to make happen before I will ask the actual question:\n\nI work for a service company that provides information on field operations for multiple different oil and gas production companies. Our clients want to have a website where they can log in to their account, see which rigs we are managing and current information on said rigs.\n\nI need to link each well drilled to the company that paid for it to be drilled. However in many cases each well may be revisited 3 or 4 times in its lifetime and each time may have a different rig assigned to it, or different operations performed on it. \n\nWhere it starts to get complicated is that we need to have running data kept up to date on all of these wells that are being drilled concurrently at 0.2m increments (on wells that exceed 16000m at times) that can be queried to produce graphs of where the well is placed, the geophysical readings, penetration rate etc. \n\nShould I organize each well into its own database and keep tables for all of the pertinent information, should I have one database for each client and have huge tables for each datatype that is queried by a combination of well identifier and date, or should there be one monolithic database that keeps track of all this information for all client companies and their data and queries the data out as needed based on login credentials and selected well?\n\nOur calculations indicate that if there is one single table for all logged data, that table would grow by about 200 million records per year. \n\nI hope this was clear. I'm not great at explaining sometimes.", 
            "subreddit": "Database", 
            "title": "Need help deciding on how to tackle multiple user/multiple project database", 
            "url": "https://www.reddit.com/r/Database/comments/73odou/need_help_deciding_on_how_to_tackle_multiple/"
        }
    ], 
    "total_submissions": 11, 
    "utc_of_data_collection_completion": "2017-10-17 18:47:12", 
    "utc_of_data_collection_start": "2017-10-17 18:47:12"
}