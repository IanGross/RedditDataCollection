{
    "active_user_count": 112, 
    "advertiser_category": null, 
    "audience_target": "", 
    "avg_comment_num_per_submission": 5, 
    "avg_submission_score": 6, 
    "collection_range_end_unix_timestamp": 1507420800, 
    "collection_range_end_utc": "2017-10-08 00:00:00", 
    "collection_range_start_unix_timestamp": 1506816000, 
    "collection_range_start_utc": "2017-10-01 00:00:00", 
    "description": "### Homework questions are for [r/homeworkhelp](http://www.reddit.com/r/homeworkhelp); [How to ask a statistics question](http://www.statisticalanalysisconsulting.com/how-to-ask-a-statistics-question/); [Modmail us](http://www.reddit.com/message/compose?to=%2Fr%2Fstatistics) if your submission doesn't appear right away, it's probably in the spam filter.###\n\nThis is a subreddit for the discussion of statistical theory, software and application.\n_____________\n**Guidelines:**\n\n1. **This is not a subreddit for homework questions.** They will be swiftly removed, so don't waste your time!  Please kindly post those over at: [r/homeworkhelp](http://www.reddit.com/r/homeworkhelp) or /r/AskStatistics. Thank you.\n\n2. Please try to keep submissions on topic and of high quality.\n\n3. Just because it has a statistic in it doesn't make it statistics.\n\n4. Memes and image macros are not acceptable forms of content.\n\n5. Self posts with throwaway accounts will be deleted by AutoModerator\n_____________\n**Related subreddits:**\n\n* [r/askstatistics](http://www.reddit.com/r/askstatistics)\n* [r/machinelearning](http://www.reddit.com/r/machinelearning)\n* [r/probabilitytheory](http://www.reddit.com/r/probabilitytheory)\n* [r/datasets](http://www.reddit.com/r/datasets)\n* [r/opendata](http://www.reddit.com/r/opendata)\n* [r/rstats](http://www.reddit.com/r/rstats)\n* [r/econometrics](http://www.reddit.com/r/econometrics)\n* [r/dataisbeautiful](http://www.reddit.com/r/dataisbeautiful)\n* [r/sas/](http://www.reddit.com/r/sas)\n* [r/compsci/](http://www.reddit.com/r/compsci)\n* [r/ComputerScience/](http://www.reddit.com/r/ComputerScience)\n* [r/OnCourtAnalytics](http://www.reddit.com/r/OnCourtAnalytics)\n* [r/NBAanalytics/](http://www.reddit.com/r/NBAanalytics/)\n* [r/sportsanalytics/](https://www.reddit.com/r/sportsanalytics/)\n_____________\n**Data:**\n\n* [r/datasets](http://www.reddit.com/r/datasets/)\n* [KDnuggets Data Mining Data](http://www.kdnuggets.com/datasets/index.html)\n* [UC-Irvine Machine Learning Repository](http://archive.ics.uci.edu/ml/)\n* [Datamob](http://datamob.org/)\n* [datasets package in R](http://stat.ethz.ch/R-manual/R-patched/library/datasets/html/00Index.html)\n* [Kaggle](http://www.kaggle.com) <- also great for stats competitions\n* [CMU Data and Story Library](http://lib.stat.cmu.edu/DASL/)\n* [U.S. Government Data Portal](http://www.data.gov)\n* [St. Louis Fed. Reserve](http://research.stlouisfed.org/fred2/)\n* [Infochimps](http://www.infochimps.com/)\n* [AllenDowney's Stats Page](https://sites.google.com/site/thinkstats2011b/project)\n_____________\n**Useful resources for learning R:**\n\n* [r-bloggers](http://r-bloggers.com) - blog aggregator with statistics articles generally done with R software.\n* [Quick-R](http://www.statmethods.net/) - great R reference site.\n_____________\n**Related Software Links:**\n\n* [R](http://www.r-project.org/)\n* [R Studio](http://rstudio.org/)\n* [SAS](http://www.sas.com/)\n* [Stata](http://www.stata.com/)\n* [EViews](http://www.eviews.com/)\n* [JMP](http://www.jmp.com/)\n* [SPSS](http://www-01.ibm.com/software/analytics/spss/)\n* [Minitab](http://www.minitab.com)\n_____________\n**Advice for applying to grad school:**\n\n* [Submission 1](http://www.reddit.com/r/statistics/comments/ghfg0/advice_for_getting_an_ms_or_phd_in_stats/)\n_____________\n**Advice for undergrads:**\n\n* [Submission 1](http://www.reddit.com/r/statistics/comments/p7fsb/any_advice_for_a_freshman_stats_major/)\n_____________\n**Jobs and Internships**\n\nFor grads:\n\n* [ISU](http://www.stat.iastate.edu/employment/)\n\nFor undergrads:\n\n* [AMSTAT Internships](http://www.amstat.org/education/internships.cfm)\n* [NSF Internships](http://www.nsf.gov/crssprgm/reu/list_result.cfm?unitid=5044)", 
    "display_name": "statistics", 
    "domain_occurrences": {
        "blog.statsbot.co": 1, 
        "docs.google.com": 1, 
        "github.com": 1, 
        "i.redd.it": 1, 
        "medium.com": 2, 
        "npr.org": 1, 
        "psychbrief.com": 1, 
        "reddit.com": 1, 
        "self.statistics": 46, 
        "stat.fi": 1, 
        "surveymonkey.com": 1, 
        "theaccidentalengineer.com": 1, 
        "thisisstatistics.org": 1, 
        "vincentgranville.com": 1, 
        "youtube.com": 1
    }, 
    "id": "2qhfi", 
    "num_external_website_posts": 15, 
    "num_text_posts": 46, 
    "public_description": "", 
    "submissions": [
        {
            "author": "ThilebanTheEngineer", 
            "created_utc": 1507417000.0, 
            "domain": "youtube.com", 
            "id": "74y48z", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "Engineer Thileban Explains", 
                    "author_url": "https://www.youtube.com/channel/UCcnz9s70vXWoqErYJgsTzCA", 
                    "description": "Uploaded by Engineer Thileban Explains on 2017-10-07.", 
                    "height": 338, 
                    "html": "<iframe class=\"embedly-embed\" src=\"//cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2F-otQNYUOqb4%3Ffeature%3Doembed&url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D-otQNYUOqb4&image=https%3A%2F%2Fi.ytimg.com%2Fvi%2F-otQNYUOqb4%2Fhqdefault.jpg&key=522baf40bd3911e08d854040d3dc5c07&type=text%2Fhtml&schema=youtube\" width=\"600\" height=\"338\" scrolling=\"no\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/-otQNYUOqb4/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "Class interval, limits, boundaries, width and midpoint - Treatment of Experimental Data", 
                    "type": "video", 
                    "url": "http://www.youtube.com/watch?v=-otQNYUOqb4", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74y48z/class_interval_limits_boundaries_width_and/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Class interval, limits, boundaries, width and midpoint - Treatment of Ex...", 
            "url": "https://www.youtube.com/attribution_link?a=Wpsb7u-kRYk&u=%2Fwatch%3Fv%3D-otQNYUOqb4%26feature%3Dshare"
        }, 
        {
            "author": "GRZBR", 
            "created_utc": 1507342286.0, 
            "domain": "docs.google.com", 
            "id": "74s8xk", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74s8xk/survey_question_for_my_stat_class_takes_only_a/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Survey Question for my STAT class. Takes only a few seconds. Thanks!", 
            "url": "https://docs.google.com/forms/d/e/1FAIpQLSdxtFxlyKjetu3S94bmZkj6WRNk22FPBKnCaqKczxz7-Vcuxg/viewform"
        }, 
        {
            "author": "Bosschowski", 
            "created_utc": 1507340668.0, 
            "domain": "self.statistics", 
            "id": "74s48p", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74s48p/is_this_appropriate_for_repeated_measures/", 
            "score": 4, 
            "selftext": "I conducted an experiment, replicated 6 times, in a randomized complete block design. I took plant height weekly, along with several other measurements. I had 10 species, some with 3 cultivars, some with 1 cultivar, for a total of 24 experimental units. I also progressively added salt to the soil to evaluate salt tolerance. Is it appropriate to run repeated measures on these data? If not what is the best approach to b evaluate the relative salt tolerance?", 
            "subreddit": "statistics", 
            "title": "Is this appropriate for repeated measures?", 
            "url": "https://www.reddit.com/r/statistics/comments/74s48p/is_this_appropriate_for_repeated_measures/"
        }, 
        {
            "author": "ToyHarmony", 
            "created_utc": 1507336113.0, 
            "domain": "surveymonkey.com", 
            "id": "74rqos", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Research/Article", 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74rqos/looking_to_gain_some_insight_on_the_statistics_of/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Looking to gain some insight on the statistics of what people are looking for in their financial futures", 
            "url": "https://www.surveymonkey.com/r/RN6RJJ2"
        }, 
        {
            "author": "CsStan", 
            "created_utc": 1507321170.0, 
            "domain": "self.statistics", 
            "id": "74q9yd", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74q9yd/f_test_for_two_means_rejection_regions/", 
            "score": 3, 
            "selftext": "Hey,\n\nCould someone tell me the rejection regions for the F test when comparing two means for various $H_0$ ?\n\nH_0: mu1 = mu2\n\nH_A: mu_1 != mu_2\n\n\nH_0: mu_1 >= mu_2\n\nH_A: mu_1 < mu_2\n\n\nH_0: mu_1 <= mu_2\n\nH_A: mu_1 > mu_2\n\nI'm confused on how the rejection region would look for the other two cases where it is greater than or less than.\n\nThank you for reading\n\n\n", 
            "subreddit": "statistics", 
            "title": "F test for two means rejection regions?", 
            "url": "https://www.reddit.com/r/statistics/comments/74q9yd/f_test_for_two_means_rejection_regions/"
        }, 
        {
            "author": "postdochell", 
            "created_utc": 1507315912.0, 
            "domain": "self.statistics", 
            "id": "74ppev", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74ppev/how_to_run_anova_of_nonlinear_regression_curvefit/", 
            "score": 3, 
            "selftext": "I have a data set of concentration response curves that I've used to calculate EC50 and Emax values for different treatment groups. If I want to run an ANOVA of these values, should I take the calculated values for the curvefit of all data and the calculated standard error, or do curvefits of each individual replicate and enter those individual values as replicates for each mean?", 
            "subreddit": "statistics", 
            "title": "How to run ANOVA of non-linear regression curvefit values", 
            "url": "https://www.reddit.com/r/statistics/comments/74ppev/how_to_run_anova_of_nonlinear_regression_curvefit/"
        }, 
        {
            "author": "pvsa", 
            "created_utc": 1507311808.0, 
            "domain": "self.statistics", 
            "id": "74p924", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74p924/pca_and_what_axis_1_and_2_represent/", 
            "score": 0, 
            "selftext": "I did an experiment on plants with three groups (control, drought, chemical) and measured their reflectance to calculate reflectance indices. So I have 3 groups (n = 8) and 18 reflectance indices calculated for each.\n\n[Here you can see some of the data in the table, the resulting PCA graph, % variance, and the coordinates.](https://imgur.com/a/yXLTo)\n\nMy question is how to explain what is in Axis 1 and 2. What is causing the separation between my SD and SR groups?", 
            "subreddit": "statistics", 
            "title": "PCA and what Axis 1 and 2 represent", 
            "url": "https://www.reddit.com/r/statistics/comments/74p924/pca_and_what_axis_1_and_2_represent/"
        }, 
        {
            "author": "StrangerJ", 
            "created_utc": 1507301665.0, 
            "domain": "self.statistics", 
            "id": "74o46z", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74o46z/is_it_possible_for_me_to_calculate_my_curved/", 
            "score": 1, 
            "selftext": "Hey, so I'm taking my first Stats class this semester, and this is more of a general question since the class has got me thinking. No this isn't homework, yes I'm weird and am inquiring into statistic, on reddit, in my free time.\n\nSo my Econ class just had a test, but we did so poorly on it that the teacher is curving our grade. I approached him after class, and he gave me some raw data for how we did on the test. I'm wondering if it's possible for me to calculate my final grad from only the info he gave me. I tried looking online, but none of the resources I found gave instructions on how to calculate specific scores.\n\nMy Grade: 72\n\nClass mean: 53.55\n\nClass median: 52\n\nLowest grade: 24%\n\nHighest grade: 96%\n\nPopulation/Sample Size: 92 students\n\nHe never said what he was curving it to (I'm assuming an 80? idk what college teachers usually curve to), and I'm also assuming it's going to be a normal bell curve.\n\nMy stats class has gone over standard deviations, bell curves, normal distribution, and all that sorta of jazz so far, but we've never applied to anything like grade curves or normalizing one bell curve to another. Any insight would be very appreciated ", 
            "subreddit": "statistics", 
            "title": "Is it possible for me to calculate my curved score based on data I have?", 
            "url": "https://www.reddit.com/r/statistics/comments/74o46z/is_it_possible_for_me_to_calculate_my_curved/"
        }, 
        {
            "author": "mintemim", 
            "created_utc": 1507289122.0, 
            "domain": "self.statistics", 
            "id": "74mzjs", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74mzjs/graph_to_compare_three_independent_variables/", 
            "score": 2, 
            "selftext": "I want to see the relation of three continuous independent variables through graph. What kind of graph should I use using SPSS? ", 
            "subreddit": "statistics", 
            "title": "Graph to compare three independent variables", 
            "url": "https://www.reddit.com/r/statistics/comments/74mzjs/graph_to_compare_three_independent_variables/"
        }, 
        {
            "author": "poompus", 
            "created_utc": 1507283492.0, 
            "domain": "self.statistics", 
            "id": "74mmcz", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "College Advice", 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74mmcz/how_can_i_use_a_calculator_to_benefit_me_in_a/", 
            "score": 2, 
            "selftext": "I am very inadequately prepared for my upcoming statistic exam. I figured that rather then learning to do all of the caluclations/notations manually it would be far easier to learn to do them on a calculator. (this is actually allowed) Im not sure where to start with learning this or if the functions I need will be in the calculator by default or if I will need to make my own programs for the calculator. Any help on this is massively appreciated as its a huge source of stress right now. Although I am for the most part not familiar with the terms I have listed they are what will likely be on the exam if that helps in giving advice. \n\ncalculate P-values, mean,median, mode, variance, sample and populations, confidence intervals, null and alternative hypothesis, test statistic, two/one sample t-test, binomial distributions, using excel commands, two sample proportion test, chi square test, reference distribution, random variables", 
            "subreddit": "statistics", 
            "title": "How can I use a calculator to benefit me in a statistics exam?", 
            "url": "https://www.reddit.com/r/statistics/comments/74mmcz/how_can_i_use_a_calculator_to_benefit_me_in_a/"
        }, 
        {
            "author": "Xwadrythm", 
            "created_utc": 1507274698.0, 
            "domain": "self.statistics", 
            "id": "74m3x4", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74m3x4/need_help_spss_multiple_response/", 
            "score": 2, 
            "selftext": "I have around 10 risk factors for a certain condition and what I want to do is to analyze the no. Of risk factor if it's associated with outcome (ex outcome of people with 1, 2,3,4 or above risk factors) so how should I do it? Forgot to mention the risk factors have been recorded into 0 and 1 where 1 means yes but some of the risk factors have  missing values don't know if it will affect outcome. Thankyou in advance everyone. ", 
            "subreddit": "statistics", 
            "title": "Need help spss multiple response", 
            "url": "https://www.reddit.com/r/statistics/comments/74m3x4/need_help_spss_multiple_response/"
        }, 
        {
            "author": "Skidvish", 
            "created_utc": 1507274217.0, 
            "domain": "self.statistics", 
            "id": "74m2us", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74m2us/simple_poker_calculation/", 
            "score": 2, 
            "selftext": "Looking for odds of certain starting hand odds for no-limit poker. Am I correct in thinking there are 3 categories of odds? Pocket pairs, any 2 suited (Ace King Suited), and any two off-suit (Ace King off).\n\n\nAm I Calculating these correctly?\n\nPocket Pairs= (4/52)*(3/51) = 0.452%\n\nAce King Suited= (4/52)*(1/51) = 0.151%\n\nAce King off= (4/52)*(4/51) = 0.603%\n\n\n", 
            "subreddit": "statistics", 
            "title": "Simple Poker Calculation", 
            "url": "https://www.reddit.com/r/statistics/comments/74m2us/simple_poker_calculation/"
        }, 
        {
            "author": "tekkanphan", 
            "created_utc": 1507234277.0, 
            "domain": "stat.fi", 
            "id": "74ilwa", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74ilwa/the_role_of_statistics_in_the_data_revolution2001/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "The Role of Statistics in the Data Revolution?[2001]", 
            "url": "https://stat.fi/isi99/proceedings/arkisto/varasto/frie0060.pdf"
        }, 
        {
            "author": "jrzy24", 
            "created_utc": 1507233306.0, 
            "domain": "self.statistics", 
            "id": "74ii3i", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74ii3i/i_need_help_with_statistics_problem_finding/", 
            "score": 0, 
            "selftext": "I have three sets of data from a lab experiment and I need to find the confidence interval. Im using excel. I am very lost and this is my first class Ive needed statistics for. If anyone can explain what CI is that would be helpful as well.", 
            "subreddit": "statistics", 
            "title": "I need help with statistics problem finding confidence interval.", 
            "url": "https://www.reddit.com/r/statistics/comments/74ii3i/i_need_help_with_statistics_problem_finding/"
        }, 
        {
            "author": "fsen", 
            "created_utc": 1507232401.0, 
            "domain": "self.statistics", 
            "id": "74ieda", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74ieda/size_of_correlation_coefficient_for_x_and_y_is/", 
            "score": 6, 
            "selftext": "TL;DR: Does the situation in the title reflect a normal mathematical property of all correlations -- or does it tell me something important about the relationship between *X* and *Y* (my guess: heteroscedasticity)?\n\nWas reading an article in which variables *X* and *Y* were measured for the same individuals at several points in time. The authors also included a correlation coefficient for *X* and *Y* at each of these points. The authors showed a line graph of the means of *X* and *Y* over time, and it appeared that they were affected by various events administered at specific points in time. There was a small to moderate negative correlation, at all points, which was statistically significant at almost all of them.\n\nI was interested in whether these events also had an effect on the size of the correlation between *X* and *Y*, so I made [my own line graph](https://i.imgur.com/u5KoVXj.png) in excel which plotted the means of *X* and *Y* and their correlation coefficients at each of the measurement times. To make this more readable, I converted each of these variables to *Z*-scores.\n\nUpon examining the line graph I noticed something that struck me as odd. The line representing the size of the correlation between *X* and *Y* was extremely similar to the line representing the mean value of *X*. Regardless of when the measurement was taken (with respect to the timing of the events, or the passage of time in general), larger mean values for *X* seemed to be associated with larger correlation coefficients between *X* and *Y*. While there were only 8 points for each of the lines representing the mean *X* and the correlation between *X* and Y*, I did run a correlation just for a ballpark, and found a positive correlation with an *R*^2 of ~.68 (and the *R*^2 for mean *Y* and correlation between *X* and *Y* was ~.34, negative correlation).\n\nNow without the raw data (even the mean values had to be interpolated from a graph in the paper), I can't do any typical analyses to see what's going on behind the scenes. This could totally be a normal mathematical property that I am not aware of. However I don't think that's what I'm seeing. It looks as though the strength of the negative relationship between *X* and *Y* is highly dependent on how high *X* is and to a lesser extent, how low *Y* is. In other words, the relationship is strongest at one end of the spectrum, and gets weaker as it approaches the other. I suspect that what I have observed might be a manifestation of heteroscedasticity (again, without the data I can't just check that for myself). \n\nSo, the question is, normal mathematical property, or indicative of something else about the relationship between *X* and *Y*?", 
            "subreddit": "statistics", 
            "title": "Size of Correlation Coefficient for X and Y is Strongly Correlated with Sample Mean for X.", 
            "url": "https://www.reddit.com/r/statistics/comments/74ieda/size_of_correlation_coefficient_for_x_and_y_is/"
        }, 
        {
            "author": "finnigansbaked", 
            "created_utc": 1507219089.0, 
            "domain": "self.statistics", 
            "id": "74gvvp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "College Advice", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74gvvp/undergrad_in_marketing_masters_in_statistics/", 
            "score": 2, 
            "selftext": "Is this a viable option? I went to a highly ranked business school, where our marketing program was highly statistics and analytics based.", 
            "subreddit": "statistics", 
            "title": "Undergrad in Marketing, Masters in Statistics?", 
            "url": "https://www.reddit.com/r/statistics/comments/74gvvp/undergrad_in_marketing_masters_in_statistics/"
        }, 
        {
            "author": "__compactsupport__", 
            "created_utc": 1507212716.0, 
            "domain": "self.statistics", 
            "id": "74g78t", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74g78t/time_series_or_poisson_regression_for_prediction/", 
            "score": 10, 
            "selftext": "I've been picking at a forecasting model for a gym in town.  They tweet out how many people are in their gym and want to determine if they can use the data to predict usage for present day.\n\nThis smells of time series to me, but it also smells of Poisson Regression (these are counts after all).  PR would be easy, and I could do some inference, but I don't know how PR works for prediction.  Likewise,  time series is relatively easy to implement, however the gym is open between  6:00am 11:30 pm so I'm not sure how I can approach the closure period.\n\nRight now, I just use polynomial regression and am off between 9 and 15 individuals on any given day.\n\nInterested to hear your thoughts on the implementation of either method.", 
            "subreddit": "statistics", 
            "title": "Time Series or Poisson Regression for Prediction", 
            "url": "https://www.reddit.com/r/statistics/comments/74g78t/time_series_or_poisson_regression_for_prediction/"
        }, 
        {
            "author": "friscotime", 
            "created_utc": 1507212692.0, 
            "domain": "blog.statsbot.co", 
            "id": "74g752", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74g752/singular_value_decomposition_method_with_examples/", 
            "score": 37, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Singular Value Decomposition Method with Examples and Applications", 
            "url": "https://blog.statsbot.co/singular-value-decomposition-tutorial-52c695315254"
        }, 
        {
            "author": "fasnoosh", 
            "created_utc": 1507210469.0, 
            "domain": "self.statistics", 
            "id": "74fz6h", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74fz6h/whats_your_take_on_coefficient_of_variation/", 
            "score": 5, 
            "selftext": "Definition: sd(x) / mean(x)\n\nI hear about this metric a lot in the supply chain world, and it's used as a measure of relative variation. What are some of the key assumptions necessary for this to be statistically valid, and what are some suggestions or cautionary advice you would provide around using it?", 
            "subreddit": "statistics", 
            "title": "What's your take on coefficient of variation?", 
            "url": "https://www.reddit.com/r/statistics/comments/74fz6h/whats_your_take_on_coefficient_of_variation/"
        }, 
        {
            "author": "Castux", 
            "created_utc": 1507194524.0, 
            "domain": "self.statistics", 
            "id": "74eruk", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74eruk/test_of_equality_of_two_probabilities_in_a/", 
            "score": 3, 
            "selftext": "Hello! I have a problem that arose while playing games with my wife, and I found two solutions that I'd like comments on, to know if the reasonning is correct, and if not, what would be the fix. \n\n**Problem**: two persons play a series of N matches of a certain game, of which the outcomes can be player A wins, player B wins, or a draw. We wish to test the hypothesis that the players are of different strength (ie. that they have a different probability of winning).\n\nWe assume that the outcome of one match follows a categorical distribution with parameters p_A, p_B and p_draw (with p_A + p_B + p_draw = 1), and therefore the number of wins and draws after N matches follow a multinomial distribution with parameters (N, p_A, p_B, p_draw). Let's denote them x_A, x_B and x_draw with x_A + x_B + x_draw = N.\n\n**First approach: Chi-square test**\n\n* Null hypothesis: p_A = p_B = p.\n* Alternative hypothesis: p_A != p_B.\n\nUnder H0, we have 2 * p + p_draw = 1, or p = (1 - p_draw)/2. We estimate p and p_draw using the usual sample means:\n\n* p_draw_estimate = x_draw / N\n* p_estimate = (1 - p_draw_estimate) / 2 = (x_A + x_B) / (2*N)\n\nWe can then perform a Chi-square test:\n\n* Observed: x_A, x_B, x_draw\n* Expected: N * p_estimate, N * p_estimate, N * p_draw_estimate\n\nThe second line expands to: (x_A + x_B)/2, (x_A + x_B)/2, x_draw\n\nThe first two terms of the Chi^2 statistic are equal (x_A and x_B are symmetrical around their average), and the third is 0\n\n* Chi^2 = 2 * (x_A - (x_A + x_B)/2)^2 / (x_A + x_B)/2 \n* Chi^2 = (x_A - x_B)^2 / (x_A + x_B)\n\nAnd then we compare the Chi^2 statistic with the desired threshold value of a Chi^2 distribution with 2 degrees of freedom, as usual.\n\nTwo doubts here:\n\n* Since the expected values are estimated from sampling, does the Chi^2 test apply? This is not exactly the same as a test of goodness to fit where the probabilities would be known beforehand. I have the idea that Pearson proved that the difference between known probabilities and their estimates can be ignored.\n* The number of degrees of freedom. Usually for three values that have a known sum, there is one reduction, but in this case we assume that two of the probabilities are equal. Would that reduce the dofs by one more? Plus, the third term of the Chi^2 statistic is always zero, so that would perhaps confirm this suspicion?\n\n**Second approach: z-test on the difference**\n\nSame hypotheses. Assuming N large enough, the random variables X_A, X_B and X_draw are normal:\n\n* X_A ~ N(N * p_A, N * p_A * (1-p_A))\n* X_B ~ N(N * p_B, N * p_B * (1-p_B))\n* X_draw ~ N(N * p_draw, N * p_draw * (1-p_draw))\n\nAnd have non-zero covariances:\n\n* Cov(X_A, X_B) = - N * p_A * p_B\n\nUnder H0, p_A = p_B = p and these become:\n\n* X_A and X_B ~ N(N * p, N * p * (1-p))\n* Cov(X_A, X_B) = - N * p^2\n\nWe consider the difference of the means: D = (X_A - X_B) / N, which is normal with mean 0 and variance:\n\n* Var(D) = 1/N^2 * (Var(X_A) + Var(X_B) - 2 * Cov(X_A, X_B)) = 1/N^2 * (2 * N * p(1-p) + 2 * N * p^2)\n* Var(D) = 2 * p / N\n\nFinally, we estimate p from the samples, and deduce an estimate for Var(D):\n\n* p_estimate = (x_A + x_B) / (2*N)\n* Var(D)_estimate = (x_A + x_B) / N^2\n\nWe can then perform a z-test for the mean of D:\n\n* z = (0 - (x_A - x_B)) / N / sqrt((x_A + x_B) / N^2) \n* z = (x_A - x_B) / sqrt(x_A + x_B)\n\nTo compare to the desired threshold of a standard normal distribution, two-tailed.\n\n**Comments**\n\n* The fact that the results are identical (Chi^2 = z^2) suggest that both approach are valid (or both are invalid...)\n* This also suggests that in the Chi^2 test, only one degree of freedom should be used, as the Chi^2 distribution with 1 dof is exactly the standard normal distribution squared, which would make both tests identical.\n\nWould anyone be able to confirm that this is correct? Or why it is wrong? Thanks in advance!", 
            "subreddit": "statistics", 
            "title": "Test of equality of two probabilities in a multinomial distribution", 
            "url": "https://www.reddit.com/r/statistics/comments/74eruk/test_of_equality_of_two_probabilities_in_a/"
        }, 
        {
            "author": "16177880", 
            "created_utc": 1507194215.0, 
            "domain": "self.statistics", 
            "id": "74er5m", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74er5m/how_to_compare_5_non_linear_regression_data_set/", 
            "score": 0, 
            "selftext": "thank you", 
            "subreddit": "statistics", 
            "title": "How to: Compare 5 non linear regression data set", 
            "url": "https://www.reddit.com/r/statistics/comments/74er5m/how_to_compare_5_non_linear_regression_data_set/"
        }, 
        {
            "author": "themathstudent", 
            "created_utc": 1507171317.0, 
            "domain": "medium.com", 
            "id": "74d6c0", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Research/Article", 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74d6c0/deep_learning_vs_bayesian_learning/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Deep Learning vs Bayesian Learning", 
            "url": "https://medium.com/@sachin.abeywardana/deep-learning-vs-bayesian-7f8606e1e78"
        }, 
        {
            "author": "nutzki", 
            "created_utc": 1507164764.0, 
            "domain": "self.statistics", 
            "id": "74ckrd", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74ckrd/eili5_standard_error/", 
            "score": 12, 
            "selftext": "Smarter folk,\n\nI'm fairly a novice at stats and have repeatedly failed to fully grasp the application of standard error and it's relation to standard deviation, no matter how many times I read it. Explain it like I'm five, please!\n\nBest,\n\nWeenie Stats Jr.", 
            "subreddit": "statistics", 
            "title": "EILI5 standard error", 
            "url": "https://www.reddit.com/r/statistics/comments/74ckrd/eili5_standard_error/"
        }, 
        {
            "author": "HelpfuI", 
            "created_utc": 1507163171.0, 
            "domain": "self.statistics", 
            "id": "74cfav", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74cfav/a_question_about_the_field_and_potentially/", 
            "score": 5, 
            "selftext": "I am considering a degree in stats, but I was wondering what work was like for statisticians. Along with a degree in stats, I am considering a degree in sociology. Sociology is like drugs. It deals heavily in the fields I want to work, helping to do some (perceived) good in the worl, but stats seems to be the tool that sociologist Wield to accomplish those task. I'm wondering how closely statisticians are to the topics and fields they run numbers for. How knowledgable are they?\n\nWould becoming a math major for stats mean that I would be a less adept social scholar, even if that is the field I end up working in?", 
            "subreddit": "statistics", 
            "title": "A question about the field and potentially majoring", 
            "url": "https://www.reddit.com/r/statistics/comments/74cfav/a_question_about_the_field_and_potentially/"
        }, 
        {
            "author": "afactory", 
            "created_utc": 1507159787.0, 
            "domain": "self.statistics", 
            "id": "74c3kj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74c3kj/dof_with_dummy_variable_and_bonus_question/", 
            "score": 2, 
            "selftext": "I have two questions: \n\n1. Lets say you want to get the degrees of freedom to do a confidence interval. In your regression equation you have a dummy variable D(constant)*X(1 or zero). If your dummy variable for the given equation is zero, would you change your degrees of freedom because technically you have one less independent variable, thus raising your DOF by 1?\n\n2. This is hard to describe in words, but if you were to graph a regression line with a point above it: the distance from the average(mean) Ys and the regression would make up your SSR, and the distance from the regression to the point would be your SSE. My question is: what components would be SSR and SSE if the point is inbetween the regression line and the mean y values? What would they be if the point would was below the mean y values?My guess is all SSE but I want to be sure. \n\nThanks!", 
            "subreddit": "statistics", 
            "title": "DOF with dummy variable, and bonus question", 
            "url": "https://www.reddit.com/r/statistics/comments/74c3kj/dof_with_dummy_variable_and_bonus_question/"
        }, 
        {
            "author": "Datascope", 
            "created_utc": 1507159077.0, 
            "domain": "vincentgranville.com", 
            "id": "74c0zo", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74c0zo/interesting_problem_for_serious_geeks/", 
            "score": 11, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Interesting Problem for Serious Geeks: Self-correcting Random Walks", 
            "url": "http://www.vincentgranville.com/2017/10/this-is-another-off-beaten-path-problem.html"
        }, 
        {
            "author": "whdd", 
            "created_utc": 1507151275.0, 
            "domain": "self.statistics", 
            "id": "74b80w", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Career Advice", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74b80w/bookresource_recommendations_for_clinical_trial/", 
            "score": 4, 
            "selftext": "Hi all,\n\nI will be transitioning from a role analyzing purely observational epidemiological data to a role analyzing and designing clinical trials. I was wondering if you may have any recommendations for books to brush up on design and analysis of clinical trials?\n\nThanks!", 
            "subreddit": "statistics", 
            "title": "Book/resource recommendations for Clinical Trial Design and Analysis", 
            "url": "https://www.reddit.com/r/statistics/comments/74b80w/bookresource_recommendations_for_clinical_trial/"
        }, 
        {
            "author": "mathnstats", 
            "created_utc": 1507147924.0, 
            "domain": "self.statistics", 
            "id": "74au5l", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Software", 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74au5l/alternative_to_teleforms_for_automating/", 
            "score": 2, 
            "selftext": "I just got a new job, and a big part of it is creating documents for people to fill in using Teleforms. Which, I'm learning quickly, is an extremely tedious task. Given that most of the information that needs to be encoded onto a form is sent to us in a spreadsheet, it seems ripe for automation (even if not fully so).\n\nDoes anyone know of programs similar to Teleforms that can be parameterized? The only thing that comes to mind is LaTeX, but I'm not sure if that'd be the best way to do it.\n\nThanks", 
            "subreddit": "statistics", 
            "title": "Alternative to Teleforms for automating form-generation?", 
            "url": "https://www.reddit.com/r/statistics/comments/74au5l/alternative_to_teleforms_for_automating/"
        }, 
        {
            "author": "ThisisStatisticsASA", 
            "created_utc": 1507139994.0, 
            "domain": "thisisstatistics.org", 
            "id": "749x14", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/749x14/resources_roundup_2017_police_data_challenge/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Resources Roundup: 2017 Police Data Challenge", 
            "url": "http://thisisstatistics.org/resources-roundup-2017-police-data-challenge/"
        }, 
        {
            "author": "Paddmore", 
            "created_utc": 1507135779.0, 
            "domain": "psychbrief.com", 
            "id": "749fnz", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Meta", 
            "media": null, 
            "num_comments": 54, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/749fnz/should_researchers_make_sure_they_understand_the/", 
            "score": 30, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Should researchers make sure they understand the precise definition of a p-value?", 
            "url": "http://psychbrief.com/im-a-non-methodologist-does-it-matter-if-my-definition-is-slightly-wrong/"
        }, 
        {
            "author": "engineheat", 
            "created_utc": 1507134733.0, 
            "domain": "self.statistics", 
            "id": "749bd5", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/749bd5/what_if_a_regression_model_has_low_p_values_but/", 
            "score": 8, 
            "selftext": "What would you do in this situation if the goal is prediction? Clearly, low R^2 means you are not explaining much of the variance in the response.\n\nBut does the low p value for the predictors mean they are significant but the model is not right? For example, perhaps a transformation of the response and/or predictors is in order? \n\nThe situation I described might happen when, say, one of the predictors have a quadratic relationship with the response but you have no such term in the model, right?\n\nThanks", 
            "subreddit": "statistics", 
            "title": "What if a regression model has low p values but low R^2 as well?", 
            "url": "https://www.reddit.com/r/statistics/comments/749bd5/what_if_a_regression_model_has_low_p_values_but/"
        }, 
        {
            "author": "crdy93", 
            "created_utc": 1507134562.0, 
            "domain": "self.statistics", 
            "id": "749apa", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/749apa/what_kind_of_control_chart_should_i_use/", 
            "score": 3, 
            "selftext": "I want to use a control chart to illustrate that a process is out of control. I have a list of average weights taken and the acceptable standard deviation is +- 1.2 pounds with the ideal weight being 50 pounds. What type of chart would you recommend? I'm using Minitab but I could also use excel.", 
            "subreddit": "statistics", 
            "title": "What kind of control chart should I use?", 
            "url": "https://www.reddit.com/r/statistics/comments/749apa/what_kind_of_control_chart_should_i_use/"
        }, 
        {
            "author": "Ragnaroq314", 
            "created_utc": 1507128554.0, 
            "domain": "self.statistics", 
            "id": "748mbh", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/748mbh/what_are_the_odds_of_being_injured_in_a_mass/", 
            "score": 2, 
            "selftext": "This question seems to be coming up a lot after Vegas but I know that most statistics I see count domestic scenarios like the one this month in Plano, Texas in their numbers which in my mind skews the numbers when discussing this kind of attack.\n\n\n I have no idea how to figure this out so I hope you guys can help. Would the numbers be easiest discussed as odds over your lifetime vs at any one time, particularly comparing to other data points (lightning strikes, lottery jackpots, etc)?", 
            "subreddit": "statistics", 
            "title": "What are the odds of being injured in a mass shooting, excluding domestic violence?", 
            "url": "https://www.reddit.com/r/statistics/comments/748mbh/what_are_the_odds_of_being_injured_in_a_mass/"
        }, 
        {
            "author": "lobster199", 
            "created_utc": 1507069812.0, 
            "domain": "self.statistics", 
            "id": "743yb9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Career Advice", 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/743yb9/focus_on_advanced_statistics_or_econometrics/", 
            "score": 3, 
            "selftext": "Hello everyone \n\nI have some questions regarding statistics and econometrics (also posting this in r/econometrics to get their opinion).\n\nOver 2 years ago I graduated in applied economics (in a European uni). This education covered many different fields (micro and macroeconomics, finance, marketing, ...).\n\nWhen I graduated, I was really interested in macroeconomics and pursued a job/phd in that area. Unfortunately I didn't find it. After a while I found a job at a public company. I have a very decent job here, I only have overtime during specific times of the year, the job is low stress in general, I have lots of leave (even for European standards) and the pay is good.\n\nHowever, lately I've been feeling that I am capable of much more. So I dug up my maths and statistics courses (and realized that I forgot a lot). I'm almost through my courses in statistics and will be learning R and perhaps SPSS because I saw those during my education.\n\nI'm not really looking for a job as a macroeconomist anymore (although I'd accept it immediately), but a more quantitative job in general. The company I work for is very big and has quantitative jobs available, mainly in HR, finance and supply chain management. But I would consider leaving the company for an interesting job.\n\nSo, to increase my job opportunities, I'm not sure whether I should focus on econometrics or look for more advanced courses in statistics (my nephew studies maths and can give me all his notes and slides from his statistics courses), bayesian statistics also looks very interesting.\n\nStudying both advanced statistics and advanced econometrics would be best, I know, but I work full time so I have to make a choice. I remember my econometrics professor saying that knowing econometrics is a very important asset as an economist. I'll probably stay with my current company so the quantitative knowledge would be related to business economics.\nHowever, I also remember going to a job fair where only 1 of the alumni used econometrics during their jobs (he's a macroeconomist at the central bank) and even employers stated that having a good knowledge of statistics was enough for their jobs, stating that econometrics was only used my macro- and micro econometricians in central banks and universities. \n\nI'm more inclined to study econometrics because I'm interested in economics, and this would give me a better opportunity to find a job I'm really interested in, but I assume that studying statistics in general would give me more opportunities to find a job in general.\n\nThanks for your help.\n\ntl;dr should I focus on more advanced statistics or econometrics to improve my odds of finding a quantitative job?", 
            "subreddit": "statistics", 
            "title": "focus on advanced statistics or econometrics?", 
            "url": "https://www.reddit.com/r/statistics/comments/743yb9/focus_on_advanced_statistics_or_econometrics/"
        }, 
        {
            "author": "themathstudent", 
            "created_utc": 1507069808.0, 
            "domain": "medium.com", 
            "id": "743yad", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Research/Article", 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/743yad/stan_vs_pymc3_vs_edward/", 
            "score": 4, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Stan vs PyMc3 (vs Edward)", 
            "url": "https://medium.com/towards-data-science/stan-vs-pymc3-vs-edward-1d45c5d6da77"
        }, 
        {
            "author": "Asohailwahab", 
            "created_utc": 1507064405.0, 
            "domain": "self.statistics", 
            "id": "743dra", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/743dra/what_is_a_semi_experimental_study/", 
            "score": 1, 
            "selftext": "Which category does the fall?", 
            "subreddit": "statistics", 
            "title": "What is a semi experimental study?", 
            "url": "https://www.reddit.com/r/statistics/comments/743dra/what_is_a_semi_experimental_study/"
        }, 
        {
            "author": "Gracekumetat", 
            "created_utc": 1507061448.0, 
            "domain": "self.statistics", 
            "id": "7431qi", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/7431qi/simple_question/", 
            "score": 1, 
            "selftext": "How do I create a relative frequency table in Mac Numbers? I have been watching a few tutorials online and nothing is working for me!! ", 
            "subreddit": "statistics", 
            "title": "Simple Question", 
            "url": "https://www.reddit.com/r/statistics/comments/7431qi/simple_question/"
        }, 
        {
            "author": "azerusa", 
            "created_utc": 1507059151.0, 
            "domain": "self.statistics", 
            "id": "742s8i", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/742s8i/assessing_accuracy_of_point_estimates/", 
            "score": 5, 
            "selftext": "Hi All!\n\nI'm working with different point estimates of a variable with an unknown distribution, and I'm struggling to evaluate different projections for accuracy. Basically, I'm trying to see which system is best at predicting a certain value (Like, the temperature tomorrow, for instance)\n\nWhat I have done so far is get a bunch of different data points (i), and record what the projections say for the expected value (Pi). I then go back and record what the actual value was (Xi). Typically, I'd try to compare predicted percentages vs realized percentages, but I'm not sure how to best do that when I'm given only point estimates, particularly when I don't know what the distribution is.\n\n\nI've tried doing a linear regression of Pi and Xi, but that just feels wrong, as I don't get good results even if I ascribe that X is a normal variable with a mean of P and a fixed variance. Do any more statistically inclined redditors have better ideas? Am I making any sense?\n\n\nThanks in advance!", 
            "subreddit": "statistics", 
            "title": "Assessing Accuracy of Point Estimates", 
            "url": "https://www.reddit.com/r/statistics/comments/742s8i/assessing_accuracy_of_point_estimates/"
        }, 
        {
            "author": "Kaizokugari", 
            "created_utc": 1507057490.0, 
            "domain": "self.statistics", 
            "id": "742lh5", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/742lh5/betting_question/", 
            "score": 3, 
            "selftext": "Let's suppose that we have a really big statistical sample of a given sports event (e.g. the Premier League). We know that for example, for the past 50 years, in all played games, we have 40% home wins (1), 30% draws (X) and 30% away wins (2).\nLets also say that an odd from 1X2 (let's say X) delays for a number Y of games (for example, the last 20 games are chronologically something like 112X122X2X11X2X1X22X1X112221121211221), meaning the odd X has \"delayed\".\nIs it reasonable to expect, that the propability for the next game to end a draw, is higher than the respective propability inside a statistical normality, where the odd X hasn't delayed significantly?", 
            "subreddit": "statistics", 
            "title": "Betting question", 
            "url": "https://www.reddit.com/r/statistics/comments/742lh5/betting_question/"
        }, 
        {
            "author": "mattlas", 
            "created_utc": 1507052980.0, 
            "domain": "self.statistics", 
            "id": "7422zp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/7422zp/annualized_standard_deviation_using_monthly/", 
            "score": 3, 
            "selftext": "Hi everyone, I feel like I'm missing something here that I could use straightening out.\n\nI have monthly returns that I want to get the annualized standard deviation. I have exactly 99 data monthly return numbers. In excel, I put all the data in 1 column, and I did the following equation:  =STDEV.P(F4:F999) , where F4 is my first monthly return number. I used population since this is since inception and there's not a sample but the whole population (logical reasoning?). This gives me 2.06%. Now, for annualized, I did =((1+T21)^12) - 1 , where T21 is my 2.06%.  Which gives me 27.66%. Doesn't this seem rather high? I feel like I'm missing something here.... please help me out! ", 
            "subreddit": "statistics", 
            "title": "Annualized standard deviation using monthly returns, since inception 5+ years of data", 
            "url": "https://www.reddit.com/r/statistics/comments/7422zp/annualized_standard_deviation_using_monthly/"
        }, 
        {
            "author": "kronn8", 
            "created_utc": 1507047666.0, 
            "domain": "self.statistics", 
            "id": "741hgg", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/741hgg/what_statistical_test_would_be_used_to_determine/", 
            "score": 17, 
            "selftext": "Legislatures are essentially samples of the population (in both senses of the word \"population\"). Ideally, you'd want the sample (Legislature) to be representative of the population.\n\nI recently started learning about chi-square tests, f-tests, t-tests, etc, and I was wondering which test should be used in this scenario. It's relevant because the supreme court of the US will soon decide a case on Gerrymandering, and I just read that the justices say they have \"no way to establish a criterion for whether voting districts are skewed.\" I am very skeptical of that assertion, given how powerful I am finding these statistical tests to be. I know that no test is 100% certain; let's assume a 95% confidence level.", 
            "subreddit": "statistics", 
            "title": "What statistical test would be used to determine whether the composition of a legislature (with n parties) differs from population party composition due to chance?", 
            "url": "https://www.reddit.com/r/statistics/comments/741hgg/what_statistical_test_would_be_used_to_determine/"
        }, 
        {
            "author": "NewChipotleGuy", 
            "created_utc": 1507044980.0, 
            "domain": "self.statistics", 
            "id": "7416c5", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/7416c5/hypothetically_what_would_be_the_best_tests_to/", 
            "score": 0, 
            "selftext": "We can assume that the information on the sheet includes some type of unique identifier, role, years of experience and their annual salary.", 
            "subreddit": "statistics", 
            "title": "Hypothetically, what would be the best tests to run on a salary spreadsheet?", 
            "url": "https://www.reddit.com/r/statistics/comments/7416c5/hypothetically_what_would_be_the_best_tests_to/"
        }, 
        {
            "author": "Scrab22", 
            "created_utc": 1507041450.0, 
            "domain": "self.statistics", 
            "id": "740st5", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Career Advice", 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/740st5/how_is_work_like/", 
            "score": 18, 
            "selftext": "Do statisticians work in groups? Solitary?\nWhat is a day/week/month/etc's schedule like, regarding work, meetings, team work, etc?\nI know there are jobs where you work in a team, and jobs which are more solitary.\nAnything else I should know?\n\nThanks", 
            "subreddit": "statistics", 
            "title": "How Is Work Like?", 
            "url": "https://www.reddit.com/r/statistics/comments/740st5/how_is_work_like/"
        }, 
        {
            "author": "aneekshaklak", 
            "created_utc": 1507041233.0, 
            "domain": "i.redd.it", 
            "id": "740rz6", 
            "is_reddit_media_domain": true, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/740rz6/beginner_question_is_this_right/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "beginner question, is this right?", 
            "url": "https://i.redd.it/tdkowibolmpz.png"
        }, 
        {
            "author": "dooogan", 
            "created_utc": 1507037493.0, 
            "domain": "self.statistics", 
            "id": "740eaa", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Discussion", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/740eaa/exploring_variance_among_repeats_in_repeated/", 
            "score": 4, 
            "selftext": "This post got no love on cross validated, so I'm hoping I'm not making a fool of myself. \n\nI have a repeated measures design with five repeats, and a two-way randomized block ANOVA with repeated measures did not reveal my treatment as a significant predictor of the dependent variable. However, when I run a one-way ANOVA for the first repeat, I find a significant result. Considering that this is the first repeat (and independent), would it be acceptable to only perform a one-way ANOVA for this one repeat? \n\nIf it is unacceptable, or just silly, to do a one-way ANOVA on the first repeat, what are my other options for exploring this variability? What would be the relevant post-hoc tests? \n\n", 
            "subreddit": "statistics", 
            "title": "Exploring variance among repeats in repeated measures ANOVA design", 
            "url": "https://www.reddit.com/r/statistics/comments/740eaa/exploring_variance_among_repeats_in_repeated/"
        }, 
        {
            "author": "GameEconomist", 
            "created_utc": 1507034196.0, 
            "domain": "self.statistics", 
            "id": "7403os", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/7403os/ab_testing_impact_of_alpha_beta_on_required/", 
            "score": 4, 
            "selftext": "I'm trying to scope out a future A/B test.\n\nLet's assume the control group has a 1.5% conversion rate. We think the test group will have a 1.65% conversion rate (10% lift). Given these parameters, I want to ensure significance of the test.\n\nTwo levers are Alpha (probability of Type 1 Error) and Beta (probability of Type 2 error).\n\nhttps://i.gyazo.com/641161aec37650f037c036195a80d2ac.png\n\nWhere I get confused in the image I made, is comparing (Alpha 0.1; Beta 0.1) against (Alpha 0.05; Beta 0.15). If my sample size is higher (247k vs 236k), shouldn't my Beta be lower?\n\nShouldn't Alpha and Beta be a deterministic outcome based on sample size?\n\nI used this tool to produce the sample size requirements: http://clincalc.com/stats/samplesize.aspx (To get Beta, I computed 1-Power)", 
            "subreddit": "statistics", 
            "title": "A/B Testing: Impact of Alpha & Beta on Required Sample Size", 
            "url": "https://www.reddit.com/r/statistics/comments/7403os/ab_testing_impact_of_alpha_beta_on_required/"
        }, 
        {
            "author": "slugocm", 
            "created_utc": 1507029124.0, 
            "domain": "github.com", 
            "id": "73zpig", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73zpig/bayesfit_a_module_for_fitting_models_to/", 
            "score": 4, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "BayesFit: A module for fitting models to psychophysical data using PyStan and Stan.", 
            "url": "https://github.com/SlugocM/bayesfit"
        }, 
        {
            "author": "jimsankey923", 
            "created_utc": 1507009392.0, 
            "domain": "self.statistics", 
            "id": "73yifu", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73yifu/ensembling/", 
            "score": 2, 
            "selftext": "Is there a method of ensembling that would make sense to apply weights to models based on their predictive power? If so, or if such a method exists, how do you determine the non-zero weights. I imagine it would be super easy to program into an algorithm, hence my curiosity. I'm super new to predictive modeling by the way; outside of basic concepts taught in undergraduate statistics. ", 
            "subreddit": "statistics", 
            "title": "Ensembling", 
            "url": "https://www.reddit.com/r/statistics/comments/73yifu/ensembling/"
        }, 
        {
            "author": "MrsGrayGubler", 
            "created_utc": 1507002383.0, 
            "domain": "self.statistics", 
            "id": "73xzgh", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Software", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73xzgh/spss_version_question/", 
            "score": 3, 
            "selftext": "I currently have SPSS 23 on my computer. I know that 25 is the latest version, but our professor only has SPSS 24 on our syllabus. How much different is SPSS 23 from 24? I am a Masters student, and this will be the only stats class I ever have to take because I don't plan on pursuing research as a career.", 
            "subreddit": "statistics", 
            "title": "SPSS Version Question", 
            "url": "https://www.reddit.com/r/statistics/comments/73xzgh/spss_version_question/"
        }, 
        {
            "author": "gandhiarnold", 
            "created_utc": 1506999936.0, 
            "domain": "self.statistics", 
            "id": "73xs83", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73xs83/need_help_with_hazard_ratios_and_attributable_risk/", 
            "score": 4, 
            "selftext": "Is there a way to go backwards from a hazard ratio (or adjusted hazard ratio) to attributable risk? \n\nI'm analyzing a paper published in a medical journal and trying to figure out how to take the adjusted hazard ratio the authors provided and convert it to attributable risk so I can then calculate number needed to harm. ", 
            "subreddit": "statistics", 
            "title": "Need help with hazard ratios and attributable risk!", 
            "url": "https://www.reddit.com/r/statistics/comments/73xs83/need_help_with_hazard_ratios_and_attributable_risk/"
        }, 
        {
            "author": "CrabAche", 
            "created_utc": 1506999535.0, 
            "domain": "self.statistics", 
            "id": "73xr0f", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73xr0f/why_do_these_two_chisquared_calculators_give/", 
            "score": 1, 
            "selftext": "This is out of curiosity more than anything. Usually I wouldn't use online calculators for stats, but I couldn't be bothered to open a stats package out and about. But to my surprise the two chi-squared calculators I found through Google give different results.\n\nFor example, I plugged in an observed pattern of 27:13 with an Expected Pattern of 20:20, and both results came differently.\n\nGraphPAD\nhttps://www.graphpad.com/quickcalcs/chisquared2/\n\ncame up with a p value of 0.0269, and a statistic value of 4.9;\n\nwhile this one:\n\nhttp://www.socscistatistics.com/tests/chisquare/Default2.aspx\n\ncame up with a stat value of 2.5274 anf p-value 0.111884 i.e. not significant. What's with the difference?", 
            "subreddit": "statistics", 
            "title": "Why do these two chi-squared calculators give different answers?", 
            "url": "https://www.reddit.com/r/statistics/comments/73xr0f/why_do_these_two_chisquared_calculators_give/"
        }, 
        {
            "author": "Derdiedas812", 
            "created_utc": 1506981454.0, 
            "domain": "reddit.com", 
            "id": "73w2e8", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73w2e8/russian_medals_problem_rukrainianconflict/", 
            "score": 6, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Russian Medals Problem \u2022 r/UkrainianConflict", 
            "url": "https://www.reddit.com/r/UkrainianConflict/comments/73vznd/russian_medals_problem/?ref=share&ref_source=link"
        }, 
        {
            "author": "BFB_CharlesGriffith", 
            "created_utc": 1506978254.0, 
            "domain": "self.statistics", 
            "id": "73vpz9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73vpz9/need_a_method_for_inspecting_paperwork_for/", 
            "score": 1, 
            "selftext": "Allow me to explain my situation, hoping this will help clarify what I'm looking for assistance with...\n\nI work for a production lab in the Quality Assurance department.  Our Quality Assurance method doesn't involve checking the product itself, but \"document checks\" (checks on paperwork filed with each product that more or less describes manufacturing parameters.)  This documentation is either a \"Pass\" or \"Fail\" based on our inspection.\n\nWe currently perform these \"Document Checks\" on 100% of the products we complete.  However, a recent change to our lab's manning has resulted in a reduction to our QA manning.\n\nWe've decided to switch from 100% documentation checks to a sample based system.\n\nI'm no statistician and my research has yielded several different ideas, but most of these seem focused on customer's accepting / rejecting entire batches of product based on % of errors from sampling.  This is not a concern in the field of work I'm in.\n\nMy main question is this.  I have several years worth of data showing the total number of \"Products\" we have completed every month.  I also have how many \"Passed\" and \"Failed\" document checks we found during the individual months.  The highest ever recorded was a 5% documentation failure rate.\n\nIs there a statistical way to solve this data where I can reach a level of specified confidence (Let's say 95%) that we'd still be catching 99 to 100% of these errors.\n\nTL;DR:  Let's say I produce a minimum of 2455 items every month.  Of these products, 5% fail minimum quality specifications.\n\nIs there a formula I could use to where I could solve for a % of product requires inspections that would result in 95% confidence that I've caught 99 or 100 percent of the erroneous product?\n\n(I should specify the production amount and failure rates (2455 products a month / 5% quality failure rate) listed above are the very EXTREME of my line of work.  I know that changes to our production amount each would change these sample requirements, so I'm giving the extremes of the numbers to generate a safety net, accounting for changing variables.)", 
            "subreddit": "statistics", 
            "title": "Need a method for inspecting paperwork for quality assurance.", 
            "url": "https://www.reddit.com/r/statistics/comments/73vpz9/need_a_method_for_inspecting_paperwork_for/"
        }, 
        {
            "author": "nightcrawler84", 
            "created_utc": 1506971037.0, 
            "domain": "self.statistics", 
            "id": "73uw4g", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73uw4g/how_many_people_are_needed_in_a_survey_on_order/", 
            "score": 3, 
            "selftext": "Say for a country wide survey.", 
            "subreddit": "statistics", 
            "title": "How many people are needed in a survey on order to show an overall population trend?", 
            "url": "https://www.reddit.com/r/statistics/comments/73uw4g/how_many_people_are_needed_in_a_survey_on_order/"
        }, 
        {
            "author": "Homeless101", 
            "created_utc": 1506963430.0, 
            "domain": "self.statistics", 
            "id": "73u1my", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 15, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73u1my/want_to_pursue_a_graduate_degree_in_statistics/", 
            "score": 15, 
            "selftext": "I'm currently a senior in college studying statistics and operations management and am seriously considering pursuing a graduate degree in stats sometime in the future. That being said, I'm quite unsure about what my chances are and could use some advice on how to go about making myself competitive for a solid program over the next few years.\n\nIdeally, I would like to take some time off to work in the real world and return to school afterward. As far as qualifications go, I'm sitting on a 3.5 GPA at Wharton Undergrad and will have taken the following relevant courses by graduation:\n- Multivariable Calculus for Business Students (MATH110)\n- Probability Theory (STAT 430)\n- Intro to Business Statistics (STAT101 &STAT102)\n- Intro to R Programming (STAT 405)\n- Data Analytics and Statistical Computing in R (STAT470)\n- Predictive Analytics (STAT 422)\n- Modern Data Mining (STAT 471)\n\nAs you may have guessed, one of my main concerns is my lack of coursework. Our majors (called \"concentrations\") are more similar to minors in terms of length and commitment, and I have yet to take any classes in linear algebra, numerical analysis, topography, stochastic processes, or other high-level, theoretical maths. I am also unsure whether my GPA will be competitive. \n\nGiven this, are there any specific steps you would recommend for someone who is looking to go down this path but generally uninformed about stats graduate school admissions in general?", 
            "subreddit": "statistics", 
            "title": "Want to pursue a graduate degree in Statistics. Need Advice.", 
            "url": "https://www.reddit.com/r/statistics/comments/73u1my/want_to_pursue_a_graduate_degree_in_statistics/"
        }, 
        {
            "author": "Optimesh", 
            "created_utc": 1506948087.0, 
            "domain": "self.statistics", 
            "id": "73silb", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Statistics Question", 
            "media": null, 
            "num_comments": 16, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73silb/assumption_of_independence_in_the_stock_market/", 
            "score": 3, 
            "selftext": "Hello,\nI'm going to make a few generalizations and simplifications to try and be on point as to what I'm asking. To be clear, I'm asking out of pure curiosity.\n\nIf I flipped a fair coin yesterday, whatever it came out had no impact on the result of flipping the coin again today, due to the independence of events.\n\nRegarding the stock market, analysts and consultants always say 'past performance does not indicate future performance'. That's fair enough and easy to understand.\nHowever, there's no reason to assume independence of events, when for example the events are how a certain stock performed yesterday and how it will perform today. There are momentums, rallies, over inflated expectations that correct themselves, etc.\nSo let's say that I take performance history of all the stocks traded in a certain stock market, break them down to daily performance, and find there's a correlation coefficient of .7 (for example, anything \u2260 0) between the performance in t-1 and t (t is period in days). \n\nAnd let's say all companies have the same number of stocks and all stocks are $1 each.\n\nDoes this mean that if I invest in X stocks before the market opens today (when X is large enough) based on the direction of their performance yesterday, about 70% of my investments will be profitable? (excluding outlier events).\n\nI assume there's something off with my logic. Please help me understand. ", 
            "subreddit": "statistics", 
            "title": "Assumption of independence in the stock market?", 
            "url": "https://www.reddit.com/r/statistics/comments/73silb/assumption_of_independence_in_the_stock_market/"
        }, 
        {
            "author": "DeeDeeGetOutOfMyLab", 
            "created_utc": 1506910792.0, 
            "domain": "self.statistics", 
            "id": "73q2p8", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73q2p8/data_sampling/", 
            "score": 5, 
            "selftext": "So I have been tasked with making a marketing model for locations at work. We have our current location and two new ones that we are looking to expand into. I am setting up the model to analyze foot traffic and vehicle traffic. Without getting too much into it, I am curious to know if there is any statistical difference in taking sample sizes of 1 minutes or 10 minutes or 1 hour. ", 
            "subreddit": "statistics", 
            "title": "Data Sampling", 
            "url": "https://www.reddit.com/r/statistics/comments/73q2p8/data_sampling/"
        }, 
        {
            "author": "pupupeepee", 
            "created_utc": 1506907973.0, 
            "domain": "theaccidentalengineer.com", 
            "id": "73ptw9", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Career Advice", 
            "media": null, 
            "num_comments": 14, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73ptw9/i_interviewed_my_friend_rachael_maltiel_who/", 
            "score": 62, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "I interviewed my friend Rachael Maltiel who dropped out of her Stats PhD, she now heads an analytics team at eBay [video]", 
            "url": "https://theaccidentalengineer.com/marketing-math-rachael-maltiel-swenson-ebay-analytics/"
        }, 
        {
            "author": "webbed_feets", 
            "created_utc": 1506901799.0, 
            "domain": "self.statistics", 
            "id": "73p9ju", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Career Advice", 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73p9ju/i_have_a_small_portfolio_of_consulting_projects/", 
            "score": 3, 
            "selftext": "I'm a third year PhD student who wants to apply for internships. I've been doing private consulting work for other grad students for about 6 months. With the exception of one project I worked on, I never really do anything exciting: lots of ANOVA and linear models for underpowered experiments. I always present my clients with a nice writeup of what I did for them.\n\nIf I compiled some of these projects into a portfolio would anyone care? It would illustrate that I know what I'm doing, but at the same time it wouldn't be exciting. If a portfolio would help, what's the best way to share it with employers?", 
            "subreddit": "statistics", 
            "title": "I have a small portfolio of consulting projects I've worked on. Will employers care about this when I apply for internships and jobs?", 
            "url": "https://www.reddit.com/r/statistics/comments/73p9ju/i_have_a_small_portfolio_of_consulting_projects/"
        }, 
        {
            "author": "rjali", 
            "created_utc": 1506901188.0, 
            "domain": "self.statistics", 
            "id": "73p7l1", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73p7l1/thinking_about_dropping_out_of_a_masters_of/", 
            "score": 8, 
            "selftext": "Hi,\n\nI hold a BS in Math (graduated in 2005) and a Masters in Math Ed (2008). I taught math at the community college and lower-levels at the university for a span of ten years and I could never land a permanent position and decided to leave the field. \n\nI earned a GIS certificate in 2016, and then moved to Colorado. I stayed with family in Fort Collins while looking for work, but I could not find anything that would pay the bills and/or relevant to science/math/gis. I'm now doing electric and gas designs for distribution/services in Denver. I tried my best to avoid Denver. I spent most my life in the PNW and I'm just not a fan of Denver, the cost of living, all the people, etc. I want to go back to Oregon and live in a small town of Eugene or Bend. \n\nI've been taking online courses at CSU and I'm just not at all motivated to learn this stuff. The idea was to take some stats courses and that would potentially open doors for me in terms of work. However, I'm not seeing many jobs that are relevant to stats in the towns I want to live in. Given that I'm (kind of) half-stepping in my coursework, working full-time and lack time to focus, and not seeing the jobs in towns I want to live in, I'm thinking about dropping out. I just don't want to accumulate $30K in debt and not have a job or be miserable in a big where I don't want to be just to have a relevant job in stats. Plus, I'm 36 years old, and this program is taking ALL of my free time. It absolutely sucks having suck a busy schedule with work and school at this age. I can't enjoy my down time, go hiking, enjoy my dog, etc. \n\nI want to to drop, but I feel like a sucker if I do. Any life advice, suggestions, outlook/perspective of life about a masters in stats, any reality checks, etc? Anything would be helpful.\n\n\nThank you.", 
            "subreddit": "statistics", 
            "title": "Thinking about dropping out of a Masters of Applied Statistics...", 
            "url": "https://www.reddit.com/r/statistics/comments/73p7l1/thinking_about_dropping_out_of_a_masters_of/"
        }, 
        {
            "author": "coffeecoffeecoffeee", 
            "created_utc": 1506825090.0, 
            "domain": "npr.org", 
            "id": "73j734", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73j734/monty_hall_host_of_lets_make_a_deal_dies_at_96/", 
            "score": 66, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Monty Hall, Host Of 'Let's Make A Deal,' Dies At 96", 
            "url": "http://www.npr.org/sections/monkeysee/2017/09/30/554799645/monty-hall-host-of-let-s-make-a-deal-dies-at-96?"
        }
    ], 
    "subreddit_creation_utc": 1205473198.0, 
    "subscribers": 44107, 
    "title": "statistics", 
    "title_word_count_occurrences": {
        "deep learning": 1, 
        "ios": 1
    }, 
    "top_score_submissions": [
        {
            "author": "coffeecoffeecoffeee", 
            "created_utc": 1506825090.0, 
            "domain": "npr.org", 
            "id": "73j734", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73j734/monty_hall_host_of_lets_make_a_deal_dies_at_96/", 
            "score": 66, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Monty Hall, Host Of 'Let's Make A Deal,' Dies At 96", 
            "url": "http://www.npr.org/sections/monkeysee/2017/09/30/554799645/monty-hall-host-of-let-s-make-a-deal-dies-at-96?"
        }, 
        {
            "author": "pupupeepee", 
            "created_utc": 1506907973.0, 
            "domain": "theaccidentalengineer.com", 
            "id": "73ptw9", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Career Advice", 
            "media": null, 
            "num_comments": 14, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/73ptw9/i_interviewed_my_friend_rachael_maltiel_who/", 
            "score": 62, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "I interviewed my friend Rachael Maltiel who dropped out of her Stats PhD, she now heads an analytics team at eBay [video]", 
            "url": "https://theaccidentalengineer.com/marketing-math-rachael-maltiel-swenson-ebay-analytics/"
        }, 
        {
            "author": "friscotime", 
            "created_utc": 1507212692.0, 
            "domain": "blog.statsbot.co", 
            "id": "74g752", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/74g752/singular_value_decomposition_method_with_examples/", 
            "score": 37, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Singular Value Decomposition Method with Examples and Applications", 
            "url": "https://blog.statsbot.co/singular-value-decomposition-tutorial-52c695315254"
        }, 
        {
            "author": "Paddmore", 
            "created_utc": 1507135779.0, 
            "domain": "psychbrief.com", 
            "id": "749fnz", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Meta", 
            "media": null, 
            "num_comments": 54, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/749fnz/should_researchers_make_sure_they_understand_the/", 
            "score": 30, 
            "selftext": "", 
            "subreddit": "statistics", 
            "title": "Should researchers make sure they understand the precise definition of a p-value?", 
            "url": "http://psychbrief.com/im-a-non-methodologist-does-it-matter-if-my-definition-is-slightly-wrong/"
        }, 
        {
            "author": "Scrab22", 
            "created_utc": 1507041450.0, 
            "domain": "self.statistics", 
            "id": "740st5", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "", 
            "link_flair_text": "Career Advice", 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/statistics/comments/740st5/how_is_work_like/", 
            "score": 18, 
            "selftext": "Do statisticians work in groups? Solitary?\nWhat is a day/week/month/etc's schedule like, regarding work, meetings, team work, etc?\nI know there are jobs where you work in a team, and jobs which are more solitary.\nAnything else I should know?\n\nThanks", 
            "subreddit": "statistics", 
            "title": "How Is Work Like?", 
            "url": "https://www.reddit.com/r/statistics/comments/740st5/how_is_work_like/"
        }
    ], 
    "total_submissions": 61, 
    "utc_of_data_collection_completion": "2017-10-17 18:49:02", 
    "utc_of_data_collection_start": "2017-10-17 18:49:01"
}