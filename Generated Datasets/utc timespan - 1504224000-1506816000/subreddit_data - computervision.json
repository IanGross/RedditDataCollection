{
    "active_user_count": 25, 
    "advertiser_category": null, 
    "audience_target": "", 
    "avg_comment_num_per_submission": 4, 
    "avg_submission_score": 5, 
    "collection_range_end_unix_timestamp": 1506816000, 
    "collection_range_end_utc": "2017-10-01 00:00:00", 
    "collection_range_start_unix_timestamp": 1504224000, 
    "collection_range_start_utc": "2017-09-01 00:00:00", 
    "description": "Some topics: Object Tracking, Segmentation and Grouping, Computational Photography and Video, Motion and Tracking\n, Shape-from-X, Stereo and Structure from Motion, Image-Based Modeling, etc...\n\n**Related Subreddits**\n\n* /r/MachineLearning\n* /r/MLQuestions\n* /r/learnmachinelearning\n* /r/robotics\n* /r/datascience \n* /r/MLjobs\n\n[Computer Vision Slack group](https://join.slack.com/t/computervisionclub/shared_invite/enQtMjUxMjY4ODQyMDgwLTVlMjVmMTZhYjA4NzEwMjMxNjQwMzAyOGQxMTUxODRlMjI2NmRmY2IwZmQyNDAwYzdiYmM1MjNiYzc3YTZlZGU)", 
    "display_name": "computervision", 
    "domain_occurrences": {
        "arxiv.org": 1, 
        "blog.dlib.net": 1, 
        "community.elphel.com": 1, 
        "cs.nott.ac.uk": 1, 
        "github.com": 4, 
        "hackernoon.com": 1, 
        "i.redd.it": 2, 
        "learnopencv.com": 1, 
        "linkedin.com": 1, 
        "phone-vis.herokuapp.com": 1, 
        "pyimagesearch.com": 1, 
        "qupath.github.io": 1, 
        "reddit.com": 1, 
        "self.computervision": 51, 
        "ted.com": 1, 
        "troynikov.io": 1, 
        "twitter.com": 1, 
        "youtu.be": 4, 
        "youtube.com": 2
    }, 
    "id": "2rfzn", 
    "num_external_website_posts": 26, 
    "num_text_posts": 51, 
    "public_description": "", 
    "submissions": [
        {
            "author": "opencvisfun", 
            "created_utc": 1506713293.0, 
            "domain": "self.computervision", 
            "id": "73a43i", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/73a43i/opencv_python_questions/", 
            "score": 4, 
            "selftext": "Hello /r/computervision I love working in this area but I am new. I had a few questions you may be able to help me with or at least point me in the right direction. My first question was if it is possible to detect shapes that are abnormal, I understand finding contours and I can find basic shapes but what if we have a rectangle but with a dome on top can I do a detection for that? Or a rectangle with a hexagon on top.\n\nI was also wondering if it is possible when detecting rectangles for instance from a video stream to only detect once and then stop so I don't keep applying OCR to that same region for example.\n\nThanks for any and all help! I will continue reading through opencv documentation.", 
            "subreddit": "computervision", 
            "title": "Opencv python questions", 
            "url": "https://www.reddit.com/r/computervision/comments/73a43i/opencv_python_questions/"
        }, 
        {
            "author": "Medionol", 
            "created_utc": 1506695715.0, 
            "domain": "self.computervision", 
            "id": "7386k2", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/7386k2/opencv_24_vs_33_for_face_recognition/", 
            "score": 1, 
            "selftext": "Currently I am using OpenCV 2.4 with C++ for a face recognition, is there any reason to switch over to 3.3?", 
            "subreddit": "computervision", 
            "title": "OpenCV 2.4 vs 3.3 for face recognition?", 
            "url": "https://www.reddit.com/r/computervision/comments/7386k2/opencv_24_vs_33_for_face_recognition/"
        }, 
        {
            "author": "Steverob91", 
            "created_utc": 1506687431.0, 
            "domain": "self.computervision", 
            "id": "737eze", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/737eze/trying_to_read_bib_numbers_from_photographs/", 
            "score": 1, 
            "selftext": "Hi, I'm trying to read bib numbers from photos like the ones in this collection - https://imgur.com/a/ABTtT\n\nI've tried Google Vision API's OCR abilities. It's good to a certain extent. Are there some alternate approaches to this? Can we do some pre-processing to the images to improve accuracy and stuff?\n\nLooking for some directions and thoughts so I can research better :)", 
            "subreddit": "computervision", 
            "title": "Trying to read bib numbers from photographs", 
            "url": "https://www.reddit.com/r/computervision/comments/737eze/trying_to_read_bib_numbers_from_photographs/"
        }, 
        {
            "author": "Fireyf0untain", 
            "created_utc": 1506678524.0, 
            "domain": "self.computervision", 
            "id": "736t8o", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/736t8o/how_to_become_a_researcher_in_the_field_of/", 
            "score": 8, 
            "selftext": "Hi reddit folks! I'm an international student who wants to get admission for masters in CS at UIUC. But as I've learned, it's not so easy to get in for an average student like me. I have a B.S. In information technology and I wanna do research in AI and HCI, but the thing is I have zero experience in research or work. But I really want to be a professional in AI and do research in computer vision and object recognition to be specific. Do you guys have any suggestions that what I can do to get into a top university like that without any related background? I know I should have research experience and stuff but well, I don't! Do you think admission officers would give me a chance?\nI wanna know more about people who are in this area, what they struggle with, and what they'd suggest to enthusiastic people who are new to the field and would like to become an expert in AI and computer vision? What skills should I gain?\n\n", 
            "subreddit": "computervision", 
            "title": "How to become a researcher in the field of computer vision?", 
            "url": "https://www.reddit.com/r/computervision/comments/736t8o/how_to_become_a_researcher_in_the_field_of/"
        }, 
        {
            "author": "flyingmrwang", 
            "created_utc": 1506653214.0, 
            "domain": "self.computervision", 
            "id": "7352sw", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/7352sw/is_it_possible_to_generate_training_data_with/", 
            "score": 1, 
            "selftext": "I am just wondering that if we could take photo of people and automatically generate segmentation label (AKA. mask) with green screen. In this way, we can crop out the person and change the background for training image. BTW. What I am doing is to segment person from background with segmentation network.", 
            "subreddit": "computervision", 
            "title": "Is it possible to generate training data with green screen??", 
            "url": "https://www.reddit.com/r/computervision/comments/7352sw/is_it_possible_to_generate_training_data_with/"
        }, 
        {
            "author": "qeVut7tguCpxKqqMPtWU", 
            "created_utc": 1506617606.0, 
            "domain": "self.computervision", 
            "id": "731egy", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/731egy/face_reconstruction_in_the_wild/", 
            "score": 8, 
            "selftext": "Sorry if this doesn't belong here. I'm trying to understand the technique used in http://grail.cs.washington.edu/3dfaces/paper.pdf for photometric stereo in the wild. However, the result I get (for the 3d mesh) is really flat compared to their result. I think the issue is that I warp the face to the template shape which is very wide (for example George Bush's face has different dimensions than the template). Am I suppose to choose some scale initially and don't use the scale of the template? ", 
            "subreddit": "computervision", 
            "title": "Face reconstruction in the wild", 
            "url": "https://www.reddit.com/r/computervision/comments/731egy/face_reconstruction_in_the_wild/"
        }, 
        {
            "author": "goodnewsjimdotcom", 
            "created_utc": 1506585790.0, 
            "domain": "self.computervision", 
            "id": "72yp5n", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/72yp5n/is_this_a_computer_vision_technique/", 
            "score": 5, 
            "selftext": "1) For prefab parts, have a 3d model of the part like say a Mountain Dew can.\n\n2) To determine if you're looking at this part, do traditional 2d CV, but match against different angles of looking at the 3d models in the database.", 
            "subreddit": "computervision", 
            "title": "Is this a computer vision technique?", 
            "url": "https://www.reddit.com/r/computervision/comments/72yp5n/is_this_a_computer_vision_technique/"
        }, 
        {
            "author": "zuliani19", 
            "created_utc": 1506550748.0, 
            "domain": "self.computervision", 
            "id": "72vsl8", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/72vsl8/detecting_screens_position/", 
            "score": 1, 
            "selftext": "I'm new to computer vision and I'm trying to detect these screws on this image:  https://imgur.com/a/LZIYw \nI trying to use color detection but because of the colors of the background and the screws this is now working very well. What I basically need to do is use the tracking to find the position in x,y on the ''top view''... \nI've checked some tutorials but I'd like to know if there is something else besides using color that would be good in this case...", 
            "subreddit": "computervision", 
            "title": "Detecting screens position", 
            "url": "https://www.reddit.com/r/computervision/comments/72vsl8/detecting_screens_position/"
        }, 
        {
            "author": "the3liquid", 
            "created_utc": 1506447009.0, 
            "domain": "self.computervision", 
            "id": "72ly8m", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 39, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/72ly8m/what_job_interview_questions_can_a_midlevel/", 
            "score": 26, 
            "selftext": "Hi\n\nI'd like to know what job interview questions a mid-level computervision engineer can expect?", 
            "subreddit": "computervision", 
            "title": "What job interview questions can a mid-level computervision engineer expect?", 
            "url": "https://www.reddit.com/r/computervision/comments/72ly8m/what_job_interview_questions_can_a_midlevel/"
        }, 
        {
            "author": "gabegabe6", 
            "created_utc": 1506366752.0, 
            "domain": "self.computervision", 
            "id": "72epss", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/72epss/multiple_object_tracking_based_on_colors/", 
            "score": 5, 
            "selftext": "I would like to track 3 objects at the same time with the same color.\n\nI know that I just have to find the first 3 contours (sorted by area) as I would normally do with 1 object. But after than, how can I \"separate\" the detected point so I get 3 tracks?\n\nWhat kind of algorithm should I use?\n\nSo I would have 3 objects and I could see the tracked points separately.", 
            "subreddit": "computervision", 
            "title": "Multiple object tracking based on colors", 
            "url": "https://www.reddit.com/r/computervision/comments/72epss/multiple_object_tracking_based_on_colors/"
        }, 
        {
            "author": "smitherson", 
            "created_utc": 1506364259.0, 
            "domain": "self.computervision", 
            "id": "72efd1", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/72efd1/need_some_help_with_slam_reconstruction/", 
            "score": 7, 
            "selftext": "Hello, I've been developing a SLAM(for now just VO) as a personal mania. I would like to hear some opinions on how to deal with the \"floor-desk interpolation problem\" you can see in the video. \nhttps://www.youtube.com/watch?v=FYqDOd4F6IU\nThe main problem is that when we track the table edge, we get some part of the floor in the patch-tracking. Are there any existing solutions/approaches to this problem?", 
            "subreddit": "computervision", 
            "title": "Need some help with slam reconstruction", 
            "url": "https://www.reddit.com/r/computervision/comments/72efd1/need_some_help_with_slam_reconstruction/"
        }, 
        {
            "author": "emyers17", 
            "created_utc": 1506345028.0, 
            "domain": "self.computervision", 
            "id": "72cbcr", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/72cbcr/suggestion_for_image_analysis_software/", 
            "score": 3, 
            "selftext": "Hello,\n\nHope this community can help me. I'm looking for a software that can analyze an image and rate it against a another image. For example, we provide an input image of a child's cursive handwriting and compare it to an image of perfect cursive and are able to quantify the level of deviation. Is something like this even possible? Any input is welcome. Thanks.  ", 
            "subreddit": "computervision", 
            "title": "Suggestion for image analysis software", 
            "url": "https://www.reddit.com/r/computervision/comments/72cbcr/suggestion_for_image_analysis_software/"
        }, 
        {
            "author": "hurutoriya", 
            "created_utc": 1506315442.0, 
            "domain": "ted.com", 
            "id": "72abwn", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "Joseph Redmon", 
                    "author_url": "https://www.ted.com/speakers/joseph_redmon", 
                    "cache_age": 300, 
                    "description": "Ten years ago, researchers thought that getting a computer to tell the difference between a cat and a dog would be almost impossible. Today, computer vision systems do it with greater than 99 percent accuracy. How?", 
                    "height": 315, 
                    "html": "<iframe class=\"embedly-embed\" src=\"//cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fembed.ted.com%2Ftalks%2Fjoseph_redmon_how_a_computer_learns_to_recognize_objects_instantly&url=https%3A%2F%2Fwww.ted.com%2Ftalks%2Fjoseph_redmon_how_a_computer_learns_to_recognize_objects_instantly&image=https%3A%2F%2Fpe.tedcdn.com%2Fimages%2Fted%2F5e6eca9274084f2ad84e2f4a1e3022f9fe219185_240x180.jpg%3Flang%3Den&key=522baf40bd3911e08d854040d3dc5c07&type=text%2Fhtml&schema=ted\" width=\"560\" height=\"315\" scrolling=\"no\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "TED", 
                    "provider_url": "http://ted.com", 
                    "thumbnail_height": 180, 
                    "thumbnail_url": "https://pe.tedcdn.com/images/ted/5e6eca9274084f2ad84e2f4a1e3022f9fe219185_240x180.jpg?lang=en", 
                    "thumbnail_width": 240, 
                    "title": "Joseph Redmon: How computers learn to recognize objects instantly", 
                    "type": "video", 
                    "url": "https://www.ted.com/talks/joseph_redmon_how_a_computer_learns_to_recognize_objects_instantly", 
                    "version": "1.0", 
                    "width": 560
                }, 
                "type": "ted.com"
            }, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/72abwn/ted_speech_of_the_yolo_developer_how_computers/", 
            "score": 39, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "TED speech of the YOLO developer: How computers learn to recognize objects instantly", 
            "url": "https://www.ted.com/talks/joseph_redmon_how_a_computer_learns_to_recognize_objects_instantly"
        }, 
        {
            "author": "Maxcr1", 
            "created_utc": 1506306203.0, 
            "domain": "self.computervision", 
            "id": "729m85", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/729m85/getting_3d_pose_from_a_rectangle_of_known/", 
            "score": 1, 
            "selftext": "Sorry to sound naive, but does anybody have any experience getting 3D Pose from a rectangle of a known size using preferably one camera?  I've done some research on inverse homology and have messed around with Vuforia's approach at this, which leads me to believe it is possible, but I was wondering where I could find the math and logical steps behind it.  Thanks in advance", 
            "subreddit": "computervision", 
            "title": "Getting 3D Pose from a rectangle of known dimensions", 
            "url": "https://www.reddit.com/r/computervision/comments/729m85/getting_3d_pose_from_a_rectangle_of_known/"
        }, 
        {
            "author": "harvey_slash", 
            "created_utc": 1506262645.0, 
            "domain": "self.computervision", 
            "id": "72595z", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/72595z/need_some_help_with_implementing_patchmatch/", 
            "score": 2, 
            "selftext": "I have been trying to implement patch match for some time. It doesn't seem to work. Can any one be kind enough to help me with it. I have most of the framework done.  Help is greatly appreciated", 
            "subreddit": "computervision", 
            "title": "Need some help with implementing patchmatch algorithm", 
            "url": "https://www.reddit.com/r/computervision/comments/72595z/need_some_help_with_implementing_patchmatch/"
        }, 
        {
            "author": "gabegabe6", 
            "created_utc": 1506261636.0, 
            "domain": "self.computervision", 
            "id": "7255y9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/7255y9/color_tracker_module_for_python_with_opencv/", 
            "score": 2, 
            "selftext": "I've made a color tracker module for python what you can find [HERE](https://github.com/gaborvecsei/Color-Tracker).\n\nI would like to know what do you think about this and how should I improve it. I am really curious about your feedback.\n\nI know that it is nothing new and not a cutting edge module but I think this is really good not to write that OpenCV code over and over again and it is a great way to get beginners involved in CV.\n\nAs for a more advanced module what would you like to see in it?", 
            "subreddit": "computervision", 
            "title": "Color tracker module for python with OpenCV", 
            "url": "https://www.reddit.com/r/computervision/comments/7255y9/color_tracker_module_for_python_with_opencv/"
        }, 
        {
            "author": "atroyn", 
            "created_utc": 1506250199.0, 
            "domain": "troynikov.io", 
            "id": "724eqp", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/724eqp/lsd_hallucinations_when_slam_goes_wrong/", 
            "score": 17, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "LSD Hallucinations - When SLAM Goes Wrong", 
            "url": "http://troynikov.io/lsd-hallucinations/"
        }, 
        {
            "author": "sqzr1", 
            "created_utc": 1506212070.0, 
            "domain": "self.computervision", 
            "id": "721xtb", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/721xtb/determine_the_dominant_colour_values_by/", 
            "score": 4, 
            "selftext": "I can analyse a histogram of an image (3 histograms representing 3 colour channels) and determine how many dominant colours are in that image by counting histogram local maxima (that have a min height of X). For example; if my red, green, and blue histograms each have 2 large peaks and the std deviation is large I can say 'There are 2 dominant colours` in this image.\n\nBut what I can't determine from that information is what are the 2 dominant colours? Yes I have 6 peaks but which rgb values go together? Sometimes I 'mix' the colours meaning I grab the tallest peak from the red channel, the tallest peak from the green channel and the tallest peak from the blue channel but it turns out that the tallest peak on the blue channel is from the 2nd most dominant colour not the first. So I've ended up mixing the colour and my determined most dominant colour is incorrect.\n\n**Are there techniques/approaches I can use to determine which peaks in a histogram correspond to which dominant colour?**\n\nThe objective is to first; *Find the most dominant colour in a ROI of an image*. And secondly; Know when an ROI contains more than 1 dominant colours and their colour values. Where dominant colours is simply local maxima who deviate from the mean \"significantly\" (given some tolerance).\n\nI know I could use K-means to find the N most dominant colours but my understanding is there are a couple of drawbacks from this approach; I don't determine if there are N dominant colours in an ROI, I arbitrarily pick K dominant colours to find and ask K-means to tell me what they are. So if K is 6 and my ROI only has 2 dominant colours, K-means will give me 4 colours I am not interested in. And, I may be wrong on this, but K-means is more computationally expensive than using my histogram analysis approach. **My objective is fast and dirty extraction of dominant colours in an roi.** So by using 3 histograms, counting local maxima and inspecting std deviation I can quite quickly determine how many dominant colours are in an ROI but not yet determine what those dominant colours are.\n\n", 
            "subreddit": "computervision", 
            "title": "Determine the dominant colour values by inspecting histograms", 
            "url": "https://www.reddit.com/r/computervision/comments/721xtb/determine_the_dominant_colour_values_by/"
        }, 
        {
            "author": "Andrey_Filippov", 
            "created_utc": 1506193203.0, 
            "domain": "community.elphel.com", 
            "id": "7206ai", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/7206ai/long_range_multiview_stereo_with_4_sensor_rig/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Long range multi-view stereo with 4 sensor rig", 
            "url": "https://community.elphel.com/3d+map"
        }, 
        {
            "author": "davis685", 
            "created_utc": 1506179476.0, 
            "domain": "blog.dlib.net", 
            "id": "71yssd", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/71yssd/fast_multiclass_object_detection_in_dlib_197/", 
            "score": 18, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Fast Multiclass Object Detection in Dlib 19.7", 
            "url": "http://blog.dlib.net/2017/09/fast-multiclass-object-detection-in.html"
        }, 
        {
            "author": "alkasm", 
            "created_utc": 1506153988.0, 
            "domain": "reddit.com", 
            "id": "71x331", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/71x331/ripeunripe_tomato_sorter_xpost_from/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Ripe/unripe tomato sorter (x-post from r/interestingasfuck)", 
            "url": "https://www.reddit.com/r/interestingasfuck/comments/71jgos/green_tomato_sorter/"
        }, 
        {
            "author": "darien94", 
            "created_utc": 1505991213.0, 
            "domain": "self.computervision", 
            "id": "71ibsk", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/71ibsk/coefficients_of_wavelet_transform/", 
            "score": 2, 
            "selftext": "Hello, everyone!\n\nI am learning about wavelets while practicing with pywavelets library in Python. I apply the dwt2 function on an image containing edges and I want to classify the image whether the edges are predominantly vertical or horizontal.\n\nI couldn't find much information about cH and cV detail coefficients generated by the discrete wavelet transform. My assumption is that summing over the values in these 2d matrices would stand for some metric of energy of the horizontal/vertical detail? Should absolute values be summed instead? Is there a flaw in this logic?\n\nThank you for your patience!", 
            "subreddit": "computervision", 
            "title": "Coefficients of Wavelet transform", 
            "url": "https://www.reddit.com/r/computervision/comments/71ibsk/coefficients_of_wavelet_transform/"
        }, 
        {
            "author": "nguyenanhminhxd", 
            "created_utc": 1505947862.0, 
            "domain": "self.computervision", 
            "id": "71ex1a", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/71ex1a/what_are_stable_unstable_points/", 
            "score": 1, 
            "selftext": "I often come across these terms when finding materials related to computer vision, especially interest points detecting. Could anybody explain the terms to me?\nI'm a novice in this area.", 
            "subreddit": "computervision", 
            "title": "what are stable/ unstable points?", 
            "url": "https://www.reddit.com/r/computervision/comments/71ex1a/what_are_stable_unstable_points/"
        }, 
        {
            "author": "jm677zz", 
            "created_utc": 1505894001.0, 
            "domain": "youtube.com", 
            "id": "719kvs", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "e-con Systems", 
                    "author_url": "https://www.youtube.com/user/econsystems", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/tDuK0JoyXPQ?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/tDuK0JoyXPQ/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "See3CAM_CU20 Low Light Demo: 2MP USB3 Camera", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/719kvs/see3cam_cu20_low_light_demo_2mp_usb3_hdr_camera/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "See3CAM_CU20 Low Light Demo: 2MP USB3 HDR Camera", 
            "url": "https://www.youtube.com/watch?v=tDuK0JoyXPQ"
        }, 
        {
            "author": "didnteventri", 
            "created_utc": 1505848961.0, 
            "domain": "twitter.com", 
            "id": "715eqc", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/715eqc/photos_of_cities_from_rcityporn_described_by/", 
            "score": 5, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Photos of cities from /r/cityporn described by Microsoft's computer vision API", 
            "url": "https://twitter.com/citydescriber"
        }, 
        {
            "author": "Killerjdog", 
            "created_utc": 1505846977.0, 
            "domain": "i.redd.it", 
            "id": "7155xj", 
            "is_reddit_media_domain": true, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 18, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/7155xj/my_friend_sent_me_this_image_and_said_something/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "My friend sent me this image and said something was special about it. But I can't figure out what, can you help?", 
            "url": "https://i.redd.it/x4ejf4zfyvmz.jpg"
        }, 
        {
            "author": "Weihua99", 
            "created_utc": 1505781088.0, 
            "domain": "youtu.be", 
            "id": "70zb1k", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "Sully Chen", 
                    "author_url": "https://www.youtube.com/channel/UCuV-4u1ONzBkB4Oi4MSHBsQ", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/AR7MbkaMByY?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/AR7MbkaMByY/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "OpenCV Paper Scanner", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70zb1k/extracting_paper_from_an_image_in_realtime_with/", 
            "score": 20, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Extracting paper from an image in real-time [With link to source code]", 
            "url": "https://youtu.be/AR7MbkaMByY"
        }, 
        {
            "author": "zionsrogue", 
            "created_utc": 1505751498.0, 
            "domain": "pyimagesearch.com", 
            "id": "70w2o5", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70w2o5/realtime_object_detection_deep_learning_opencv_33/", 
            "score": 26, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Real-time object detection + deep learning + OpenCV 3.3", 
            "url": "http://www.pyimagesearch.com/2017/09/18/real-time-object-detection-with-deep-learning-and-opencv/"
        }, 
        {
            "author": "spmallick", 
            "created_utc": 1505750757.0, 
            "domain": "learnopencv.com", 
            "id": "70vzp9", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70vzp9/selective_search_for_object_detection_c_python/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Selective Search for Object Detection (C++ / Python)", 
            "url": "http://www.learnopencv.com/selective-search-for-object-detection-cpp-python/"
        }, 
        {
            "author": "Imindless", 
            "created_utc": 1505744286.0, 
            "domain": "self.computervision", 
            "id": "70va1t", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70va1t/what_resources_can_i_use_to_determine/", 
            "score": 2, 
            "selftext": "I'm working on a project that requires me to analyze a few thousand videos of the same content and categorize certain characteristics of the image. \n\nFor example, I need to analyze images of bark on a tree. To start, the bark will be from the same tree. I need to determine various characteristics of the bark (color, rigidness, etc) using computer vision.\n\nI'm a bit lost and hoping to get some clarification about resources I can look into (APIs, libraries, etc) that might help me create a system to do this, automatically.", 
            "subreddit": "computervision", 
            "title": "What resources can I use to determine similarities of multiple images/video of the same content?", 
            "url": "https://www.reddit.com/r/computervision/comments/70va1t/what_resources_can_i_use_to_determine/"
        }, 
        {
            "author": "tdionis", 
            "created_utc": 1505738124.0, 
            "domain": "hackernoon.com", 
            "id": "70up8n", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70up8n/how_we_hacked_gta_v_for_carvana_kaggle_challenge/", 
            "score": 14, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "How we Hacked GTA V for Carvana Kaggle Challenge", 
            "url": "https://hackernoon.com/hacking-gta-v-for-carvana-kaggle-challenge-6d0b7fb4c781"
        }, 
        {
            "author": "djnewtan", 
            "created_utc": 1505727335.0, 
            "domain": "youtu.be", 
            "id": "70twt6", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "Team PointU", 
                    "author_url": "https://www.youtube.com/channel/UCAXCmiYiz-_ZUU93Qz8IRRQ", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/t-WDIqEPQ3g?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/t-WDIqEPQ3g/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "AR in Challenging Scenarios", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70twt6/instead_of_tracking_the_static_environment_in/", 
            "score": 6, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Instead of tracking the static environment in ARCore and ARKit, we are tracking independently moving objects. Watch our video for a demo.", 
            "url": "https://youtu.be/t-WDIqEPQ3g"
        }, 
        {
            "author": "HallowsEnd31", 
            "created_utc": 1505707082.0, 
            "domain": "self.computervision", 
            "id": "70sk4i", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70sk4i/how_to_deal_with_edge_detection_in_low_contrast/", 
            "score": 7, 
            "selftext": "I\u2019m trying to figure out a way to algorithmically deal with this rather than using any kind of hardware. Any suggestions or papers I should check out?", 
            "subreddit": "computervision", 
            "title": "How to deal with edge detection in low contrast images?", 
            "url": "https://www.reddit.com/r/computervision/comments/70sk4i/how_to_deal_with_edge_detection_in_low_contrast/"
        }, 
        {
            "author": "neowww", 
            "created_utc": 1505674221.0, 
            "domain": "self.computervision", 
            "id": "70pe3l", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70pe3l/aruco_markers_rvec_and_tvec_convert_to_rotation/", 
            "score": 3, 
            "selftext": "I'm trying to find the camera's position from an aruco marker.\n\n(https://i.stack.imgur.com/3FyQ4.png) is what the camera sees, and (https://i.stack.imgur.com/068VO.png) is also what the camera sees. The Z-axis of the marker flips back and forth. I only captured Rvec and Tvec for one of the above situations.\n\nA. These are what Aruco returned:\n\nrotation vector Rvec: [1.98895, 1.67426, -0.570106]\ntranslation vector Tvec: [0.00876591, 0.100794, 0.630018]\n\nB. This is rotation matrix R, converted from Rvec:\n\n0.16674686138210792, 0.9859319291786623, -0.011563530830037305,\n0.7881094090430687, -0.14031913821875497, 0.5993280394135843, \n-0.5925192347907373, -0.09082274206159546, -0.8004200059515079\n\nC. This is the inverse transformation matrix [R|t]^-1, the R part is the rotation matrix R above, the T part is the Tvec mentioned above:\n\n0.5532041267642692, 2.62162273212768, 1.9549923883934333, -1.5007735737997756, \n0.9146872306386324, -0.46552676124283743, -0.36178537886158296, 0.2668355392503998, \n-0.513303622140676, -1.8878607068233544, -2.6554961620678954, 1.8677949864716032, \n0, 0, 0, 1\n\nAnd the final result is incorrect. The final result looks like: i.stack.imgur.com/RPDoo.png The dummyeye(or eye1) is the camera, it's way off. eye3 and eye4 are in the correct position.\n\nSo I was wondering what's wrong. Is Aruco lib giving noise? Or is the rotation matrix in B calculated wrong? Or is the inverse wrong?\n\nThanks!\n\n", 
            "subreddit": "computervision", 
            "title": "Aruco marker's Rvec and Tvec, convert to rotation matrix, then inverse the transformation matrix, somewhere along the way I got lost", 
            "url": "https://www.reddit.com/r/computervision/comments/70pe3l/aruco_markers_rvec_and_tvec_convert_to_rotation/"
        }, 
        {
            "author": "RuleAndLine", 
            "created_utc": 1505674113.0, 
            "domain": "self.computervision", 
            "id": "70pdpj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70pdpj/noob_here_learning_by_doing_object_tracking_on_a/", 
            "score": 2, 
            "selftext": "Hey, y'all!  As preface, I've gotten myself up and running with OpenCV and played with the builtin tracking classes (using Python bindings), but other than that I know nothing about cv.  Just looking for keywords and simple project tutorials to get me to the next level.  I can code, prefer to work in Python, though I don't mind getting my hands dirty with C++ if that's necessary.\n\nSo, here's a clip from one of my favorite subcultures.  Competitive [Super Smash Brothers Melee](https://www.youtube.com/watch?v=W5d4fLWtH2Y&t=36s).  I\u2019d like to track the motion of the player characters and do \u2026 other machine learning stuff after that.  In my dream the computer is extracting statistics on the match in real time, but right now my goal is just to get a bounding box that follows one of the characters around the screen.\n\nI threw the OpenCV trackers at the video (following [this code](https://www.learnopencv.com/object-tracking-using-opencv-cpp-python/) at learnopencv.com) but they all performed very poorly, losing the character after a second or two.  I\u2019m assuming at least one (maybe all) of these facts causes the poor performance:\n\n* the character models contort into different poses all the time\n* they even distort into totally different shapes (e.g. at the 39 second mark, the [Samus](https://www.ssbwiki.com/Samus_\\(SSBM\\)) character curls up into a ball)\n* the characters accelerate and decelerate a lot, and\n* they are frequently occluded by other game sprites (smoke, combat flashes, etc)\n\nPlease correct me if I\u2019m wrong, but I think this suggests some offline training.  I\u2019m just not sure where to go with that idea.\n\nOn the one hand, the internet is already full of the positive / negative resources I\u2019ll probably need.  [Here's a video](https://www.youtube.com/watch?v=wKTfDiLnw-8) of just the background stage by itself, and [here are some gifs](https://smashboards.com/threads/samus-hitboxes-and-frame-data.320253/) of the Samus character doing all her different moves.  Worst case, I can get more data just by capturing video at home.\n\nOn the other hand \u2026 \u00af\\_(\u30c4)_/\u00af I haven\u2019t found any tutorials for turning these resources into a detector, nor any tutorials for turning a home-built offline detector into a real-time tracker.\n\nAny suggestions would be much appreciated.  Thanks!", 
            "subreddit": "computervision", 
            "title": "Noob here. Learning by doing object tracking on a recording of a fighting (video) game", 
            "url": "https://www.reddit.com/r/computervision/comments/70pdpj/noob_here_learning_by_doing_object_tracking_on_a/"
        }, 
        {
            "author": "say2neeraj", 
            "created_utc": 1505593020.0, 
            "domain": "linkedin.com", 
            "id": "70j4qz", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70j4qz/unfolding_the_buzz_word_computer_vision/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Unfolding the buzz word - Computer Vision", 
            "url": "https://www.linkedin.com/feed/update/urn:li:activity:6314467999923441664"
        }, 
        {
            "author": "Run-The-Table", 
            "created_utc": 1505507617.0, 
            "domain": "self.computervision", 
            "id": "70ck37", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70ck37/noob_help_what_to_do_with_edges_once_detected/", 
            "score": 8, 
            "selftext": "Okay, so I'm a total noob to computer vision, but I've been tooling around the web, reading tutorials, and watching youtube.  I finally got opencv with python bindings installed correctly on my machine (Mac).  I've sucessfully imported images, and used color thresholds, and Canny edge detection... but now what?\n\nOnce I've found the edges, most tutorials just stop.  That's cool... what am I to do with this black and white outline of my image?\n\nMore details:  I am taking pictures of my garden over time.  Top-down images the same height every day or so. \nMy goal:  My first goal is to remove the background from my images, leaving just the plants.  With the background removed, I'd like to quantify the size of my plants, and estimate a growth rate over time (pixels/day is totally fine.)\n\nLong term:  I'd like the plants to be quantified (color histogram, or some other classification) so that I can recognize when my plants need fertilizer, or even when I've added too much nitrogen, or something of the sort.\n\nCan anyone point me in the right direction?\n\nAlso, I only know python, but I'm happy to read theory, so long as it's not insanely math heavy.", 
            "subreddit": "computervision", 
            "title": "Noob help? What to do with edges once detected?", 
            "url": "https://www.reddit.com/r/computervision/comments/70ck37/noob_help_what_to_do_with_edges_once_detected/"
        }, 
        {
            "author": "Bibzball", 
            "created_utc": 1505485580.0, 
            "domain": "self.computervision", 
            "id": "70a5vm", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70a5vm/precise_spherical_stitching_from_homography/", 
            "score": 6, 
            "selftext": "Hi!\n\nI am trying to accomplish a precise spherical stitching using OpenCV, with the final goal to create a full 360x180 panorama. But let's start simple with 2 images:\n\n- I have SURF matches : https://i.imgur.com/lST3CTL.png\n\n- From which using classic RANSAC method, I get an homography H. I am veryfing the quality of this homography by using a simple planar projection: https://i.imgur.com/rz8UKwv.png\n\n- Then, enters the camera intrinsic parameters matrix K. Knowing the FoV of my camera and the width/height of my images (they're all the same), it's easy to get K: I compute the focal using image_width * 0.5 / tan(FoV  * DEG2RAD * .5)\n\n- I compute a rotation matrix R' = K.inv() * H * K, then apply SVD onto R' to get R = U * VT. Using this rotation matrix, and under the assumption that the rotation of my first image is the Identity matrix, I can apply an equirectangular projection on both my images and stitch them together (no seamless blending for now, I want to see if my images do overlap perfectly): https://i.imgur.com/0B6aACP.png \n\nAs you can see, the result is pretty good! Unfortunately I am having trouble understanding why the same process doesn't work for all my images. For instance:\n\n- Here are the SURF matches on another pair: https://i.imgur.com/eRYMg34.png\n\n- And the resulting planar projection: https://i.imgur.com/9inS3xX.png\n\n- Still pretty good right ? Well, with the same K matrix, the equirectangular projection is... not so good: https://i.imgur.com/W2GSgEb.png\n\nIt seems like I need to change my focal (and K) to get the result I want. But why? The pictures have been taken with the same camera, with pure rotation, there should not be a different focal length. Also, if I want to get at least a full cylinder, I will have issues in my final blend if I need a different focal length between pairs: the last image will never connect with my first image correctly.\n\nAny help on the matter?\n\nThanks a lot ! :)\n\nEdit: By the way, yes I have seen stitching_detailed in opencv, but this is not very practical for a large amoun\n", 
            "subreddit": "computervision", 
            "title": "Precise Spherical Stitching from Homography Computation?", 
            "url": "https://www.reddit.com/r/computervision/comments/70a5vm/precise_spherical_stitching_from_homography/"
        }, 
        {
            "author": "spandanmadan", 
            "created_utc": 1505454754.0, 
            "domain": "phone-vis.herokuapp.com", 
            "id": "707zfp", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/707zfp/our_team_at_mit_collected_10_cvpr_2017_posters/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Our team at MIT collected 10 CVPR 2017 posters which have MIT authors, and made this web-app to view them effortlessly on a phone! (Privacy Disclaimer : The app tracks user's interactions with poster)", 
            "url": "http://phone-vis.herokuapp.com/?dataset=cvpr_mit&tag=rdt"
        }, 
        {
            "author": "ham-ar", 
            "created_utc": 1505419004.0, 
            "domain": "self.computervision", 
            "id": "704qcg", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/704qcg/forgery_detection_in_digital_images/", 
            "score": 2, 
            "selftext": "Okay, so I'm a final year computer science student. I'm working on Forgery detection in digital images as my final year project. Now, the thing is even though the concept is interesting and all, I can't seem to figure out what direction I would like to take the project into. I'm focused on non text based images. However, I still can't seem to think of a practical way of creating a product that could incorporate the idea. I feel like I don't want to do a simple research based project. Any suggestions? Please help", 
            "subreddit": "computervision", 
            "title": "Forgery Detection in digital images", 
            "url": "https://www.reddit.com/r/computervision/comments/704qcg/forgery_detection_in_digital_images/"
        }, 
        {
            "author": "qeVut7tguCpxKqqMPtWU", 
            "created_utc": 1505411003.0, 
            "domain": "self.computervision", 
            "id": "703v0o", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/703v0o/commercial_3d_morphable_face_modelsproject/", 
            "score": 2, 
            "selftext": "I'm working for a small start up and trying to follow some of the results in the literature that reconstruct 3D models from videos or images but it seems all of them use some datasets (mostly the Basel Face Model or facewarehouse) that are not accessible for commercial usage. Did anyone else encounter this issue? is there an affordable (or free) model available?", 
            "subreddit": "computervision", 
            "title": "Commercial 3D Morphable Face ModelsProject", 
            "url": "https://www.reddit.com/r/computervision/comments/703v0o/commercial_3d_morphable_face_modelsproject/"
        }, 
        {
            "author": "soulslicer0", 
            "created_utc": 1505402679.0, 
            "domain": "self.computervision", 
            "id": "702x8l", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/702x8l/anyone_has_a_caffe_prototxt_and_or_training/", 
            "score": 0, 
            "selftext": "Would be able to share?", 
            "subreddit": "computervision", 
            "title": "Anyone has a Caffe Prototxt and or training scripts for ZFNet?", 
            "url": "https://www.reddit.com/r/computervision/comments/702x8l/anyone_has_a_caffe_prototxt_and_or_training/"
        }, 
        {
            "author": "Hectic1015", 
            "created_utc": 1505397953.0, 
            "domain": "self.computervision", 
            "id": "702fd2", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/702fd2/strategies_for_capturing_photos_based_on/", 
            "score": 1, 
            "selftext": "Hi -\nWe're looking to capture photos of things as they enter into a camera's frame.  As I'm sure we're experiening common problems: blurry images, false positives in motion detection, etc.\n\nDoes anyone have any recommended strategies, including hardware, for doing this?\n\nSpecifically, we're looking to identify certain shapes, that come into the camera's frame and then get a clean photo of the item.  This would be for example a sandwich on a plate. Challenges we're facing are blurry photos when using the camera's motion detection functionality & false positives when anything enters the screen.\n\nWe've considered using something like a One-Shot model to help with this but we're wondering if other solutions that don't rely on NN are out there we should pursue.  \n\nWe're open to using any type of camera to do this.  We've used security cameras in initial trials but their firmware is quite restrictive.  Ideally, we'd like to use a camera with a light so we can get consistent lighting for training.\n\nThanks in advance to anyone who can be helpful.\n", 
            "subreddit": "computervision", 
            "title": "Strategies for capturing photos based on motion/item entering frame", 
            "url": "https://www.reddit.com/r/computervision/comments/702fd2/strategies_for_capturing_photos_based_on/"
        }, 
        {
            "author": "swingking8", 
            "created_utc": 1505392519.0, 
            "domain": "self.computervision", 
            "id": "701xce", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/701xce/how_to_mount_webcam/", 
            "score": 1, 
            "selftext": "I'm using a computer vision implementation at work that relies on  [the Logitech C920 webcam](https://www.logitech.com/en-us/product/hd-pro-webcam-c920) to take pictures.  The camera will be part of a system that is shipped and transported as it's tested by customers, and we want to make it mechanically robust to misalignment.  Mounting options like a tripod still allow some motion, so I'm not sure how to fasten the webcam.  Current concept is to 3D print something that we can fasten down, then adhere it to the camera somehow, but I thought there might be a more elegant solution.\n\nMy two questions are: Are there good ways to rigidly mount this webcam? Are there other cameras with similar performance at a similar price (i.e. <$100USD) that are easily mounted?", 
            "subreddit": "computervision", 
            "title": "How to mount webcam", 
            "url": "https://www.reddit.com/r/computervision/comments/701xce/how_to_mount_webcam/"
        }, 
        {
            "author": "esotericGames", 
            "created_utc": 1505331950.0, 
            "domain": "self.computervision", 
            "id": "6zx13g", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6zx13g/is_there_anywhere_where_i_can_get_a_complete_list/", 
            "score": 1, 
            "selftext": "Just every single 'n10153410' id? I can slowly navigate the browse function on their website but I'm just looking for a complete list in text form. Any ideas/", 
            "subreddit": "computervision", 
            "title": "Is there anywhere where I can get a complete list of image-net sysnets?", 
            "url": "https://www.reddit.com/r/computervision/comments/6zx13g/is_there_anywhere_where_i_can_get_a_complete_list/"
        }, 
        {
            "author": "skvrahul", 
            "created_utc": 1505300268.0, 
            "domain": "self.computervision", 
            "id": "6ztsqr", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6ztsqr/realtime_depth_map_using_2_webcamsstereoscopic/", 
            "score": 5, 
            "selftext": "I'm looking to create a realtime depth map using 2 identical webcams( I've mounted them such that the distance between them doesn't change).What would be the best approach to do this using OpenCV in Python?", 
            "subreddit": "computervision", 
            "title": "Realtime depth map using 2 webcams(Stereoscopic Vision)", 
            "url": "https://www.reddit.com/r/computervision/comments/6ztsqr/realtime_depth_map_using_2_webcamsstereoscopic/"
        }, 
        {
            "author": "djnewtan", 
            "created_utc": 1505297161.0, 
            "domain": "youtube.com", 
            "id": "6ztls3", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "Team PointU", 
                    "author_url": "https://www.youtube.com/channel/UCAXCmiYiz-_ZUU93Qz8IRRQ", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/videoseries?list=PLyjwACcEdWhHD41hG1g_Js6jmLDJHtPCz\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/7rKBZZHJkFk/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "From Simple to Complex Shapes", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 20, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6ztls3/we_developed_a_robotic_perception_framework_that/", 
            "score": 37, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "We developed a robotic perception framework that allows the robots to find the objects in the scene and keep track of these objects for robotic interaction at 2ms per frame per object with 1 CPU core. It also works for objects with simple and complex shapes. Watch our video to see what we can do!", 
            "url": "https://www.youtube.com/watch?v=7rKBZZHJkFk&list=PLyjwACcEdWhHD41hG1g_Js6jmLDJHtPCz"
        }, 
        {
            "author": "monsta-hd", 
            "created_utc": 1505244728.0, 
            "domain": "github.com", 
            "id": "6zpa90", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6zpa90/photo_organizer_app_using_cnns/", 
            "score": 5, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Photo organizer app using CNNs", 
            "url": "https://github.com/monsta-hd/photo-organizer"
        }, 
        {
            "author": "Hectic1015", 
            "created_utc": 1505238155.0, 
            "domain": "self.computervision", 
            "id": "6zok96", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6zok96/tools_for_computer_vision_projects/", 
            "score": 9, 
            "selftext": "Hi, I have a team embarking on a computer vision project where we'll have 10,000s of new images a day coming into our system. We're looking to identify what tools are out there to help us: - Manage the images in a logical and clever way. Managing their tags and keeping track of pre- and post-processed images - Process images in mass (e.g., cropping) - Management of multiple NN at a time. Keeping a good eye on their performance and updating them as needed.\nIf you have any other suggestions for tools you've used in commerical applications of Computer Vision, it'd be much appreciated. Everyone we've spoken to seems to have built their own which seems a bit inefficient!\nThanks so much.", 
            "subreddit": "computervision", 
            "title": "Tools for computer vision projects", 
            "url": "https://www.reddit.com/r/computervision/comments/6zok96/tools_for_computer_vision_projects/"
        }, 
        {
            "author": "crespo_modesto", 
            "created_utc": 1505193049.0, 
            "domain": "self.computervision", 
            "id": "6zkxwo", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6zkxwo/can_you_run_a_decent_object_detection_locally/", 
            "score": 0, 
            "selftext": "This may seem like an obvious \"yes\" but imagine you have a little robot, that roams around in your house and it's not dumb as in \"if it's about to run into something, turn 45 degrees and keep going forward\".\n\nI am clearly not familiar with \"pre-trained models\" and at this time I don't have a particular purpose, I'm just thinking about if you need to store an image for reference, at least one image, and how big would one be if it started scanning every thing in your house. But that depends right, angles of photos. You could assume each photo was say 1MB or smaller assuming working with a simple 12V PCB camera, maybe a lower volt version. Then going on known numbers like an 8GB SD card and division...\n\nJust had a thought, a roaming robot would not be able to fix itself if a servo died, unless it had some other machine that could take it apart and a servo existed to replace the broken one. Then thought about humans, if we broke our bodies, if it can't heal itself naturally or surgery/it's just broken, like amputation granted you could attach a prosthetic limb to your lost limb. \n\nAlright... need to read, also the cost part... code is easier to work with, no cost just write some code and execute.", 
            "subreddit": "computervision", 
            "title": "Can you run a decent object detection locally?", 
            "url": "https://www.reddit.com/r/computervision/comments/6zkxwo/can_you_run_a_decent_object_detection_locally/"
        }, 
        {
            "author": "the3liquid", 
            "created_utc": 1505119852.0, 
            "domain": "self.computervision", 
            "id": "6ze6nr", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6ze6nr/why_should_you_know_the_checkerboard_size_when/", 
            "score": 3, 
            "selftext": "Hello\n\nAccording to [this video at the moment I linkned](https://youtu.be/Ou9Uj75DJX0?t=48), one should use a known 2D-structure with a known size when doing camera callibration. \n\nI'd like to know why it is so important to know the structures size. Based on how far you hold the board from the camera, the board's squares sizes change a lot in the image. So this doesn't seem to be a very robust parameter to me.\nAlso, not knowing the actual squares size in eg cm/mm/inches or so, you would still have a relative scale.\n\nCould somebody clarify this and correct me in case I misunderstood something?\n\nThanks\n\n\n", 
            "subreddit": "computervision", 
            "title": "Why should you know the checkerboard size when doing camera calibration?", 
            "url": "https://www.reddit.com/r/computervision/comments/6ze6nr/why_should_you_know_the_checkerboard_size_when/"
        }, 
        {
            "author": "Data-Daddy", 
            "created_utc": 1505100016.0, 
            "domain": "self.computervision", 
            "id": "6zcwc7", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6zcwc7/multitask_learning_and_transfer_learning_vs_only/", 
            "score": 1, 
            "selftext": "How should I decide if I join two imagesets or only use the weights learned from the first imageset for transfer learning. \n\nExample) I am using a resnet backbone for faster rcnn pretrained with weights learned from the COCO dataset. I have a new dataset of about a thousand images that does not share much in common w/ the images from COCO. Should I only use the pretrained network for transfer learning or should I extend the COCO dataset to include the images/annotations from my new dataset?", 
            "subreddit": "computervision", 
            "title": "Multi-task Learning and Transfer Learning vs Only Transfer Learning", 
            "url": "https://www.reddit.com/r/computervision/comments/6zcwc7/multitask_learning_and_transfer_learning_vs_only/"
        }, 
        {
            "author": "wjwwjw", 
            "created_utc": 1505079912.0, 
            "domain": "self.computervision", 
            "id": "6zb4ca", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6zb4ca/basic_questions_about_pnp_camera_pose_estimation/", 
            "score": 3, 
            "selftext": "Hello\n\nI read multiple articles and publications about [Perspective-n-point](https://en.wikipedia.org/wiki/Perspective-n-Point)\n\nI do understand the maths and do understand the terminology being used. But am having some difficulties to have a real insight/understanding of how this algorithm works and allows me to know my cameras position.\n\nMy question boils down to this:\n\nWhat is the point of solving this system of equations, which -I think-actually contains no translation or rotation information: https://wikimedia.org/api/rest_v1/media/math/render/svg/44b08350499fdc91862c67cf8023fbbd606b26fb ?\n\nIf you would just perform keypoint matching between two imageframes and check how much those keypoints moved in the image space/plane you would already have an idea on a relative scale how the camera translated. Why would you need to go through all those steps described by Pnp?\n\nThanks ", 
            "subreddit": "computervision", 
            "title": "Basic questions about Pnp camera pose estimation", 
            "url": "https://www.reddit.com/r/computervision/comments/6zb4ca/basic_questions_about_pnp_camera_pose_estimation/"
        }, 
        {
            "author": "Vermeille", 
            "created_utc": 1505052491.0, 
            "domain": "github.com", 
            "id": "6z8em3", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6z8em3/depth_map_superresolution_need_help/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Depth map super-resolution - Need help", 
            "url": "https://github.com/Vermeille/depth-recovery/blob/master/Optimize%20Depth.ipynb"
        }, 
        {
            "author": "soulslicer0", 
            "created_utc": 1505041412.0, 
            "domain": "self.computervision", 
            "id": "6z7ob5", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6z7ob5/computing_3d_point_from_stereo_image_code_question/", 
            "score": 2, 
            "selftext": "I have the following snippet of code below\n\n    %For all point correspondences\n\tfor i = 1:size(M1_l,1)\n\t    % For all image locations from a list of correspondences build an A\n\t    pointInImage1 = M1_l(i,:);\n\t    pointInImage2 = M1_r(i,:);\n\t    \n\t    A = [\n\t\tpointInImage1(1)*P1(3,:) - P1(1,:);\n\t\tpointInImage1(2)*P1(3,:) - P1(2,:);\n\t\tpointInImage2(1)*P2(3,:) - P2(1,:);\n\t\tpointInImage2(2)*P2(3,:) - P2(2,:)];\n\n\t    % Compute the 3-D location using the smallest singular value from the\n\t    % singular value decomposition of the matrix A\n\t    [~,~,V]=svd(A);\n\n\t    X = V(:,end);\n\t    X = X/X(end);\n\n\t    % Store location\n\t    points3D_1(i,:) = X';\n\nThis takes in a pixel  (pointInImage1) in left camera (P1) and (pointInImage2) in right camera (P2). I have the opencv based projection matrix of both cameras. Why has the system of equations been setup as seen in A?\n\nA actually looks like this:\n\n    (Left Cam)\n\t-fx  0  (u-cx)  -Tx\n\t0   -fy  (u-cy)  0\n\t(Right Cam)\n\t-fx  0  (u-cx)  -Tx\n\t0   -fy  (u-cy)  0\n\nIt seems its Ax = 0 where x = [X Y Z 1]", 
            "subreddit": "computervision", 
            "title": "Computing 3D Point from Stereo Image - Code Question", 
            "url": "https://www.reddit.com/r/computervision/comments/6z7ob5/computing_3d_point_from_stereo_image_code_question/"
        }, 
        {
            "author": "soulslicer0", 
            "created_utc": 1505037167.0, 
            "domain": "self.computervision", 
            "id": "6z7gbu", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6z7gbu/opencv_stereo_calibration_stereo_rectify_question/", 
            "score": 1, 
            "selftext": "I'm not sure what the physical meaning of the Projection matrices P1 and P2 are for this function.\n\nIn the monocular case, the projection matrix is simply the transform from the 3d world coordinates multiplied by the instrinsic matrix. However, what does it mean in the Stereo case?\n\nIs P1 the transform from the right camera * instrinsic of left camera, and vice versa for the other?", 
            "subreddit": "computervision", 
            "title": "OpenCv Stereo Calibration - Stereo Rectify Question", 
            "url": "https://www.reddit.com/r/computervision/comments/6z7gbu/opencv_stereo_calibration_stereo_rectify_question/"
        }, 
        {
            "author": "Landon22", 
            "created_utc": 1504994876.0, 
            "domain": "self.computervision", 
            "id": "6z4kd6", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6z4kd6/cognex_checkerboard_calibration_question/", 
            "score": 1, 
            "selftext": "I have a system that is utilizing the PatMax & Find Circle, but sometimes the system will need to be calibrated. So, I talked to Cognex support to understand the SDK to learn how to calibrate when a variable is equal to 0. I also realized I have to grab the calibration image. However, when I grab the calibration image the calibrated origin may move a little due to movement of the plate (I'm using a plate with fiducial marks, and it is Cognex supplied). This leads to the main point\u2026\n\nDoes anyone know a way I can Grab the calibration image, and offset the calibrated origin to the center of the frame, but instead of it giving the position of 0,0 in millimeters (size of our square tiles are 3.175 in both X & Y), we would like the calibrated pixel position, or even better, find a way to put the origin in the center POST calibration.\n\nOur problem is that we're measuring a circle\u2019s origin and it needs to be to the thousandth position in accuracy, so that is why this is so important. I've using the Find Circle tool to basically serve as a corrected positioning system for a system later in the process. So offsets are EXTREMELY important. I'm aware that I can use the uncalibrated point, but that isn\u2019t acceptable for this application, as the entire point of calibration is to correct any distortion. I just need a way to get the Raw Calibrated Origin point every time in Pixels.\n\nThis is essentially the same thing that has to be done with Robot Guided Vision, and Cognex is the leader in respects to that. So, it must be a common action. I'm using Cognex Designer 2.6 (with Vision Pro libraries)\n\nOne solution I thought of was telling it to calibrate with no fiducial even though there is one, because I saw in the Cognex knowledge base that it could be a potential solution. I'm trying that now, but I've tried everything else, to no avail.\n\nI'm curious as to if anyone else has had this issue, or if someone has figured it out. Thank you all!", 
            "subreddit": "computervision", 
            "title": "Cognex Checkerboard Calibration Question", 
            "url": "https://www.reddit.com/r/computervision/comments/6z4kd6/cognex_checkerboard_calibration_question/"
        }, 
        {
            "author": "tentone", 
            "created_utc": 1504973963.0, 
            "domain": "github.com", 
            "id": "6z2ktw", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6z2ktw/aruco_marker_detector_for_camera_pose_estimation/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Aruco marker detector for camera pose estimation", 
            "url": "https://github.com/tentone/aruco"
        }, 
        {
            "author": "jamendox", 
            "created_utc": 1504891504.0, 
            "domain": "qupath.github.io", 
            "id": "6yw7n7", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6yw7n7/qupath_open_source_image_analysis_software_for/", 
            "score": 8, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "QuPath - Open source image analysis software for digital pathology", 
            "url": "https://qupath.github.io/"
        }, 
        {
            "author": "ajdroid", 
            "created_utc": 1504852022.0, 
            "domain": "github.com", 
            "id": "6yt2t4", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6yt2t4/sketchparse_multitask_deep_network_for_freehand/", 
            "score": 8, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "SketchParse: Multi-task deep network for freehand sketch segmentation", 
            "url": "https://github.com/val-iisc/sketch-parse"
        }, 
        {
            "author": "ykstyy", 
            "created_utc": 1504830953.0, 
            "domain": "self.computervision", 
            "id": "6yrd80", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6yrd80/hardware_to_capture_images_depth/", 
            "score": 2, 
            "selftext": "Hello all, we need frame capture of images + depth (low resolution / precision is Ok),and we are looking for suggestions for hardware. We have tried Intel Realsense camera which has a very short range (for depth), and we have not got any luck with ZED stereo camera. Is there anything else that we can use to capture aforementioned images? Thanks in advance.", 
            "subreddit": "computervision", 
            "title": "Hardware to capture images + depth", 
            "url": "https://www.reddit.com/r/computervision/comments/6yrd80/hardware_to_capture_images_depth/"
        }, 
        {
            "author": "chenqifeng", 
            "created_utc": 1504820365.0, 
            "domain": "youtu.be", 
            "id": "6yqcat", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "Intel VCL", 
                    "author_url": "https://www.youtube.com/channel/UCp3Q1Xhsu-TRljsDqp0Kj_A", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/eQyfHgLx8Dc?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/eQyfHgLx8Dc/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "Fast Image Processing with Fully-Convolutional Networks", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6yqcat/fast_image_processing_with_fullyconvolutional/", 
            "score": 4, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Fast Image Processing with Fully-Convolutional Networks", 
            "url": "https://youtu.be/eQyfHgLx8Dc"
        }, 
        {
            "author": "soulslicer0", 
            "created_utc": 1504797626.0, 
            "domain": "self.computervision", 
            "id": "6ynv9t", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6ynv9t/trying_to_understand_the_pnp_formula/", 
            "score": 2, 
            "selftext": "Hi all,\n\nWith reference to the PNP paper and wiki:\n\nhttp://www.mmrc.iss.ac.cn/~xgao/paper/ieee.pdf\n\nhttps://en.wikipedia.org/wiki/Perspective-n-Point\n\nI completely get how this (https://wikimedia.org/api/rest_v1/media/math/render/svg/44b08350499fdc91862c67cf8023fbbd606b26fb) system of equations is derived. But I have no idea how this eventually links back to the matched pixel coordinates, or how R and T are solved. \n\nIs there any resource that explains how the system of linear equations are actually setup to solve this?", 
            "subreddit": "computervision", 
            "title": "Trying to understand the PNP Formula", 
            "url": "https://www.reddit.com/r/computervision/comments/6ynv9t/trying_to_understand_the_pnp_formula/"
        }, 
        {
            "author": "uint64", 
            "created_utc": 1504781119.0, 
            "domain": "cs.nott.ac.uk", 
            "id": "6ymey5", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6ymey5/an_online_demo_of_3d_face_reconstruction_from_a/", 
            "score": 19, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "An online demo of 3D face reconstruction from a single image", 
            "url": "http://www.cs.nott.ac.uk/~psxasj/3dme/"
        }, 
        {
            "author": "Gletta", 
            "created_utc": 1504710642.0, 
            "domain": "self.computervision", 
            "id": "6yg78q", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6yg78q/computer_vision_news_of_september/", 
            "score": 16, 
            "selftext": "Here is Computer Vision News of September, published by RSIP Vision as a gift to the algorithm community.\n38 pages of computer vision, artificial intelligence, image processing and deep learning exclusive stories (with codes!). Free subscription at page 38.\nHTML5 version (recommended) ==> http://www.rsipvision.com/ComputerVisionNews-2017September/\nand\nPDF version ==> http://www.rsipvision.com/computer-vision-news-2017-september-pdf/\nEnjoy!", 
            "subreddit": "computervision", 
            "title": "Computer Vision News of September", 
            "url": "https://www.reddit.com/r/computervision/comments/6yg78q/computer_vision_news_of_september/"
        }, 
        {
            "author": "phreak121", 
            "created_utc": 1504690046.0, 
            "domain": "self.computervision", 
            "id": "6yekrp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6yekrp/discussion_im_an_undergraduate_in_cs_and_just/", 
            "score": 3, 
            "selftext": "Just to give a bit of background on my course. We have done an introduction to AI class, algorithms, stats, probability and discrete mathematics.\n\nThis project will done over the course of a year. My idea is to develop a human action recognition system. What I envisioned was to implement a system that is similar to [this](https://www.youtube.com/watch?v=kGLGgH_VAZw&index=20&list=LLLbKplVnfJLvI5GqsQqQyHA).\n\nI mentioned to my supervisor that I wanted to achieve an A grade. He said that achieve the A grade in this project I would need to have an extremely good understanding of what going on under the hood instead of just calling APIs provided by libraries like opencv, tensor flow, dlib, etc. He told me that the concepts behind this project are very mathematical and complex; and me as an undergrad won't be to understand it, especially in a years time.\n\nSo what kind of topics do you recommend that I could do a project on in a year and also show that I have very good understanding of computer vision concepts? I would be prepared to put in the work researching.\n\nHow complex would gait analysis be? Like recognising friends by walk.\n\nMaybe it could be just tracking a human and see if they cross into some restricted space?\n\nLet me know what you think anyways, thanks.\n\n", 
            "subreddit": "computervision", 
            "title": "[Discussion] I'm an undergraduate in CS and just entered my final year. I have an idea for a final year project in computer vision. I want to achieve a top grade in this but I'm afraid I don't have enough knowledge to do so. What do you recommend?", 
            "url": "https://www.reddit.com/r/computervision/comments/6yekrp/discussion_im_an_undergraduate_in_cs_and_just/"
        }, 
        {
            "author": "soulslicer0", 
            "created_utc": 1504684444.0, 
            "domain": "self.computervision", 
            "id": "6ye964", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6ye964/library_that_takes_in_camera_poses_wrt_world/", 
            "score": 1, 
            "selftext": "Hi all, is there a library, ideally c++ or python that can compile on linux, that takes in\n\nCamera Poses wrt to World\nCamera Matrixes for the cameras\nRGB Images\n(Depth data too for better optimization?)\n\nTo generate a point cloud?", 
            "subreddit": "computervision", 
            "title": "Library that takes in camera poses wrt world, camera matrix and images to generate point cloud?", 
            "url": "https://www.reddit.com/r/computervision/comments/6ye964/library_that_takes_in_camera_poses_wrt_world/"
        }, 
        {
            "author": "hashoar", 
            "created_utc": 1504595326.0, 
            "domain": "i.redd.it", 
            "id": "6y6dfl", 
            "is_reddit_media_domain": true, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6y6dfl/i_want_to_replicate_camscanner_app/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "I want to replicate camScanner app.", 
            "url": "https://i.redd.it/uwfuq7ksk0kz.jpg"
        }, 
        {
            "author": "dernster", 
            "created_utc": 1504553875.0, 
            "domain": "self.computervision", 
            "id": "6y2m6a", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6y2m6a/scs_alternative_for_icp_cpd/", 
            "score": 2, 
            "selftext": "Hey! In 3D image registration there are well known algorithms like ICP (Iterative Closest Point) and CPD (Coherent Point Drift) among others... But does anyone know an implementation of SCS (Sorting the Correspondence Space)? http://www.ros.hw.ac.uk/handle/10399/2647", 
            "subreddit": "computervision", 
            "title": "SCS (Alternative for ICP & CPD)", 
            "url": "https://www.reddit.com/r/computervision/comments/6y2m6a/scs_alternative_for_icp_cpd/"
        }, 
        {
            "author": "ArtlockScofield", 
            "created_utc": 1504542006.0, 
            "domain": "self.computervision", 
            "id": "6y1b14", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6y1b14/commercial_use_of_open_source_libraries/", 
            "score": 2, 
            "selftext": "This is slightly tangential to computer vision but here goes -   \nI want to inculcate a certain solved computer vision functionality for a startup app and for that, on top of OpenCV, I also use some open source code provided under Apache 2.0 license, and GNU v2.0 license. As the app has to be used for commercial purposes, I was wondering the following -   \n1. Is this legally okay, especially regarding GNU v2.0 (I tried reading the documentation and it seems legal, but the language is somewhat dense, so I just want to be sure)  \n2. If the answer to above is yes, do I have to make all my code public? I remember reading something like that in the document and I am not allowed to do that as the code then loses its commercial value.  ", 
            "subreddit": "computervision", 
            "title": "Commercial use of open source libraries.", 
            "url": "https://www.reddit.com/r/computervision/comments/6y1b14/commercial_use_of_open_source_libraries/"
        }, 
        {
            "author": "hkshin2", 
            "created_utc": 1504515848.0, 
            "domain": "arxiv.org", 
            "id": "6xz984", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6xz984/guetzli_perceptually_guided_jpeg_encoder/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Guetzli: Perceptually Guided JPEG Encoder", 
            "url": "http://arxiv.org/abs/1703.04421"
        }, 
        {
            "author": "Steverob91", 
            "created_utc": 1504456956.0, 
            "domain": "self.computervision", 
            "id": "6xu6zq", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6xu6zq/recognise_a_person_when_face_is_obscured/", 
            "score": 0, 
            "selftext": "I'm trying to help people pick out their photos from large albums (on our service) quickly. I tried using AWS Rekognition's SearchFaces API to index all the photos of an album and then search for a person's face (once they choose one or two photos of theirs).\n\nBut 80% of our photos do not have the face in a perfect non-obscured manner. Instead they are side poses, people with head-gear, eye-gear etc.\n\nI've turned my effort towards figuring out a way to use the entire human body of the person for performing recognition...\n\nSo once a person identifies themselves... I want to be able to search through the entire photo-set to find photos that contain this person (using face, clothes, body-shape, hair, etc).\n\nVery new to CV / MachineLearning. Hoping to find an algorithm or a library that does this already.\n\nThanks :) :)", 
            "subreddit": "computervision", 
            "title": "Recognise a person when face is obscured", 
            "url": "https://www.reddit.com/r/computervision/comments/6xu6zq/recognise_a_person_when_face_is_obscured/"
        }, 
        {
            "author": "TheJamaican", 
            "created_utc": 1504452922.0, 
            "domain": "self.computervision", 
            "id": "6xtsdn", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6xtsdn/computer_vision_environment_mapping_question/", 
            "score": 1, 
            "selftext": "Hello,\n\nI have a project where I want to mount a camera over a table, take a picture, detect shapes, and then convert the positioning of those shapes into cutting instructions for a CNC machine.\n\nI have the code to detect the shapes and find the coordinates within the image and it works pretty well.  Now I need to figure out how to mount a camera and then map the image to the table.\n\nI am hoping someone with some experience in computer vision can point me in the right direction for learning how to do this.  \n\nI'm not sure how you would go about positioning the camera to get accurate and repeatable results.  Any help is greatly appreciated!", 
            "subreddit": "computervision", 
            "title": "Computer Vision / Environment Mapping Question", 
            "url": "https://www.reddit.com/r/computervision/comments/6xtsdn/computer_vision_environment_mapping_question/"
        }, 
        {
            "author": "Dunkelfeld", 
            "created_utc": 1504432126.0, 
            "domain": "youtu.be", 
            "id": "6xsbfn", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "GeeBee", 
                    "author_url": "https://www.youtube.com/channel/UCLDMeaxoTZs1dPjUtGcDg9w", 
                    "height": 344, 
                    "html": "<iframe width=\"459\" height=\"344\" src=\"https://www.youtube.com/embed/PZuECG4-sfY?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/PZuECG4-sfY/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "Retail Customer counter Android App - working footage", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 459
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6xsbfn/simple_people_counter_on_lowend_android_phone/", 
            "score": 12, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Simple people counter on low-end Android phone", 
            "url": "https://youtu.be/PZuECG4-sfY"
        }, 
        {
            "author": "StartTrackQuestion", 
            "created_utc": 1504330147.0, 
            "domain": "self.computervision", 
            "id": "6xk0h6", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6xk0h6/tips_on_where_to_start_for_simple_ios_object/", 
            "score": 4, 
            "selftext": "I have been reading a lot of blogs on opencv, YOLO, CNN, Apple's new vision framework etc. I feel like what I want to do is straightforward - but I find it hard to find information on what's the most practical way to code something.\n\nIn the field I am working in there is a situation that involves a fixed camera. There is a person and they will be moving with a set object. All I need to do is detect, and then track, the location of the object and the person's feet. \n\nI would like to develop this on iOS. I have familiarity with basic open-cv for python, TensorFlow image recognition, as well as iOS programming (but never open-cv or anything beyond basic camera use for iOS). \n\nIf you were me, where would you start?", 
            "subreddit": "computervision", 
            "title": "Tips on where to start for simple iOS object tracking?", 
            "url": "https://www.reddit.com/r/computervision/comments/6xk0h6/tips_on_where_to_start_for_simple_ios_object/"
        }, 
        {
            "author": "the3liquid", 
            "created_utc": 1504284088.0, 
            "domain": "self.computervision", 
            "id": "6xfqo8", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6xfqo8/does_anybody_have_callibration_pictures_taken/", 
            "score": 2, 
            "selftext": "Hi\n\nI would like to try to callibrate a fisheye camera. Issue is that I don't have a fisheye camera. I calibrated a \"normal\" (non-fisheye) twice so far and would really like to try a fisheye camera once.\n\nDoes anybody of you have such pictures/video taken with a fisheye lens, or know where I can find such pictures/video online?: https://youtu.be/v7jutAmWJVQ?t=91\n\nIf you have such pictures or a video where you move such a chessboard and record/photograph it with a fisheye lens, feel free to either post it/them here or send it/them to me via PM. I'll make sure to write it in this post if someone sends me pictures via PM, so that there are is not a second person who does unnecessary effort.\n\nPersonally I think a video might be the easiest, because as you can see the person in the video even took 50 pictures.\n\nThank you in advance\n\n**EDIT:**\n\nI ended up using this image with a chessboard: https://imgur.com/a/WlLBR provided by this website: https://sites.google.com/site/scarabotix/ocamcalib-toolbox/ocamcalib-toolbox-download-page But results are still very poor: diagonal lines like the other output image I posted a bit higher.", 
            "subreddit": "computervision", 
            "title": "Does anybody have callibration pictures taken with a fisheye lens camera?", 
            "url": "https://www.reddit.com/r/computervision/comments/6xfqo8/does_anybody_have_callibration_pictures_taken/"
        }, 
        {
            "author": "aldrin12", 
            "created_utc": 1504260765.0, 
            "domain": "self.computervision", 
            "id": "6xdlyb", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6xdlyb/thesis_about_identification_of_rice_plant/", 
            "score": 5, 
            "selftext": "I'm currently in third year college and just started my thesis 2, and for my suggested title I went with \"Rice plant Disease analyzer\" i was originally planning on building the application on desktop, however upon interviewing farmers( who are the target of my app ) they told me that they prefer a mobile application instead of a desktop app.\n\n\nupon learning this, my team and I are now tweaking our documentation and are now planning on developing a mobile application on android instead.\n\n\nNow my problem here is I have zero knowledge of image processing, although I found a related literature stating techniques and algorithms I can use, I don't know where to start actually learning image processing on mobile, I tried searching online but I can't find a decent tutorial on it.\n\n\nif you guys and point me in the right direction, it would be very helpful. Thank you very much\n\n\ntarget language: Xamarin ( just starting to learn it too, not comfortable with android studio )\n\nEdit : i forgot to mention that we are severely lacking time, we have until late october for this ", 
            "subreddit": "computervision", 
            "title": "Thesis About Identification of Rice plant Diseases on Mobile", 
            "url": "https://www.reddit.com/r/computervision/comments/6xdlyb/thesis_about_identification_of_rice_plant/"
        }
    ], 
    "subreddit_creation_utc": 1263519596.0, 
    "subscribers": 12324, 
    "title": "computer vision: doing stuff with pixels", 
    "title_word_count_occurrences": {
        "android": 1, 
        "c++": 1, 
        "deep learning": 1, 
        "ios": 1, 
        "microsoft": 1, 
        "python": 3
    }, 
    "top_score_submissions": [
        {
            "author": "hurutoriya", 
            "created_utc": 1506315442.0, 
            "domain": "ted.com", 
            "id": "72abwn", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "Joseph Redmon", 
                    "author_url": "https://www.ted.com/speakers/joseph_redmon", 
                    "cache_age": 300, 
                    "description": "Ten years ago, researchers thought that getting a computer to tell the difference between a cat and a dog would be almost impossible. Today, computer vision systems do it with greater than 99 percent accuracy. How?", 
                    "height": 315, 
                    "html": "<iframe class=\"embedly-embed\" src=\"//cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fembed.ted.com%2Ftalks%2Fjoseph_redmon_how_a_computer_learns_to_recognize_objects_instantly&url=https%3A%2F%2Fwww.ted.com%2Ftalks%2Fjoseph_redmon_how_a_computer_learns_to_recognize_objects_instantly&image=https%3A%2F%2Fpe.tedcdn.com%2Fimages%2Fted%2F5e6eca9274084f2ad84e2f4a1e3022f9fe219185_240x180.jpg%3Flang%3Den&key=522baf40bd3911e08d854040d3dc5c07&type=text%2Fhtml&schema=ted\" width=\"560\" height=\"315\" scrolling=\"no\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "TED", 
                    "provider_url": "http://ted.com", 
                    "thumbnail_height": 180, 
                    "thumbnail_url": "https://pe.tedcdn.com/images/ted/5e6eca9274084f2ad84e2f4a1e3022f9fe219185_240x180.jpg?lang=en", 
                    "thumbnail_width": 240, 
                    "title": "Joseph Redmon: How computers learn to recognize objects instantly", 
                    "type": "video", 
                    "url": "https://www.ted.com/talks/joseph_redmon_how_a_computer_learns_to_recognize_objects_instantly", 
                    "version": "1.0", 
                    "width": 560
                }, 
                "type": "ted.com"
            }, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/72abwn/ted_speech_of_the_yolo_developer_how_computers/", 
            "score": 39, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "TED speech of the YOLO developer: How computers learn to recognize objects instantly", 
            "url": "https://www.ted.com/talks/joseph_redmon_how_a_computer_learns_to_recognize_objects_instantly"
        }, 
        {
            "author": "djnewtan", 
            "created_utc": 1505297161.0, 
            "domain": "youtube.com", 
            "id": "6ztls3", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "Team PointU", 
                    "author_url": "https://www.youtube.com/channel/UCAXCmiYiz-_ZUU93Qz8IRRQ", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/videoseries?list=PLyjwACcEdWhHD41hG1g_Js6jmLDJHtPCz\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/7rKBZZHJkFk/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "From Simple to Complex Shapes", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 20, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/6ztls3/we_developed_a_robotic_perception_framework_that/", 
            "score": 37, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "We developed a robotic perception framework that allows the robots to find the objects in the scene and keep track of these objects for robotic interaction at 2ms per frame per object with 1 CPU core. It also works for objects with simple and complex shapes. Watch our video to see what we can do!", 
            "url": "https://www.youtube.com/watch?v=7rKBZZHJkFk&list=PLyjwACcEdWhHD41hG1g_Js6jmLDJHtPCz"
        }, 
        {
            "author": "the3liquid", 
            "created_utc": 1506447009.0, 
            "domain": "self.computervision", 
            "id": "72ly8m", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 39, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/72ly8m/what_job_interview_questions_can_a_midlevel/", 
            "score": 26, 
            "selftext": "Hi\n\nI'd like to know what job interview questions a mid-level computervision engineer can expect?", 
            "subreddit": "computervision", 
            "title": "What job interview questions can a mid-level computervision engineer expect?", 
            "url": "https://www.reddit.com/r/computervision/comments/72ly8m/what_job_interview_questions_can_a_midlevel/"
        }, 
        {
            "author": "zionsrogue", 
            "created_utc": 1505751498.0, 
            "domain": "pyimagesearch.com", 
            "id": "70w2o5", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70w2o5/realtime_object_detection_deep_learning_opencv_33/", 
            "score": 26, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Real-time object detection + deep learning + OpenCV 3.3", 
            "url": "http://www.pyimagesearch.com/2017/09/18/real-time-object-detection-with-deep-learning-and-opencv/"
        }, 
        {
            "author": "Weihua99", 
            "created_utc": 1505781088.0, 
            "domain": "youtu.be", 
            "id": "70zb1k", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "Sully Chen", 
                    "author_url": "https://www.youtube.com/channel/UCuV-4u1ONzBkB4Oi4MSHBsQ", 
                    "height": 338, 
                    "html": "<iframe width=\"600\" height=\"338\" src=\"https://www.youtube.com/embed/AR7MbkaMByY?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "YouTube", 
                    "provider_url": "https://www.youtube.com/", 
                    "thumbnail_height": 360, 
                    "thumbnail_url": "https://i.ytimg.com/vi/AR7MbkaMByY/hqdefault.jpg", 
                    "thumbnail_width": 480, 
                    "title": "OpenCV Paper Scanner", 
                    "type": "video", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "youtube.com"
            }, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/computervision/comments/70zb1k/extracting_paper_from_an_image_in_realtime_with/", 
            "score": 20, 
            "selftext": "", 
            "subreddit": "computervision", 
            "title": "Extracting paper from an image in real-time [With link to source code]", 
            "url": "https://youtu.be/AR7MbkaMByY"
        }
    ], 
    "total_submissions": 77, 
    "utc_of_data_collection_completion": "2017-10-16 18:49:57", 
    "utc_of_data_collection_start": "2017-10-16 18:49:56"
}