{
    "active_user_count": 255, 
    "advertiser_category": null, 
    "audience_target": "", 
    "avg_comment_num_per_submission": 7, 
    "avg_submission_score": 9, 
    "collection_range_end_unix_timestamp": 1506816000, 
    "collection_range_end_utc": "2017-10-01 00:00:00", 
    "collection_range_start_unix_timestamp": 1504224000, 
    "collection_range_start_utc": "2017-09-01 00:00:00", 
    "description": "News, articles and tools covering Amazon Web Services (AWS), including S3, EC2, SQS, RDS, DynamoDB, IAM, CloudFormation, Route 53, CloudFront, Lambda, VPC, Cloudwatch, Glacier and more.\r\n\r\nResources:\r\n\r\n* [Amazon Web Services blog](https://aws.amazon.com/blogs/aws/)  \r\n* [AWS status page](http://status.aws.amazon.com/)  \r\n* [AWS documentation](http://aws.amazon.com/documentation/)  \r\n* [AWS YouTube channel](https://www.youtube.com/user/AmazonWebServices/)  \r\n* [Datamation](http://www.datamation.com/cloud-computing/)  \r\n* [High Scalability](http://www.highscalability.com/)\r\n* [HPC in the Cloud](http://www.hpcinthecloud.com/)  \r\n\r\nOther subreddits you may like:\r\n\r\n* /r/virtualization  \r\n* /r/cloudcomputing  \r\n* /r/bigdata  \r\n* /r/devops  \r\n* /r/openstack  \r\n* /r/vmware  \r\n* /r/web_infrastructure  \r\n* /r/HPC  \r\n* /r/DNS  \r\n* /r/networking  \r\n* /r/sysadmin  \r\n* /r/netsec  \r\n\r\n*^^Does ^^this ^^sidebar ^^need ^^an ^^addition ^^or ^^correction? ^^Tell ^^me ^^[here](http://www.reddit.com/message/compose/?to=Pi31415926&subject=sidebar+tweaks+-+aws)*", 
    "display_name": "aws", 
    "domain_occurrences": {
        "aws.amazon.com": 29, 
        "awsgeek.com": 3, 
        "blog.thinkst.com": 1, 
        "bluepiit.com": 1, 
        "businessinsider.in": 1, 
        "citusdata.com": 1, 
        "codeburst.io": 1, 
        "dev.acquia.com": 1, 
        "docs.aws.amazon.com": 2, 
        "github.com": 8, 
        "hackernoon.com": 1, 
        "i.redd.it": 3, 
        "info.redlock.io": 1, 
        "itproportal.com": 1, 
        "jackrothrock.com": 1, 
        "linkedin.com": 3, 
        "linuxacademy.com": 1, 
        "logz.io": 1, 
        "medium.com": 7, 
        "mherman.org": 1, 
        "michaelburge.us": 1, 
        "noneforme.com": 1, 
        "pages.awscloud.com": 2, 
        "pgconf.us": 1, 
        "pub.latency.at": 1, 
        "pypi.python.org": 1, 
        "read.acloud.guru": 1, 
        "read.iopipe.com": 1, 
        "reddit.com": 1, 
        "self.aws": 334, 
        "serverless.com": 1, 
        "simform.com": 1, 
        "slideshare.net": 1, 
        "sparrowhub.org": 1, 
        "stackoverflow.com": 1, 
        "status.aws.amazon.com": 1, 
        "tberra.com": 1, 
        "techcrunch.com": 3, 
        "virtuesecurity.com": 1
    }, 
    "id": "2qh84", 
    "num_external_website_posts": 89, 
    "num_text_posts": 334, 
    "public_description": "News, articles and tools covering Amazon Web Services (AWS), including S3, EC2, SQS, RDS, DynamoDB, IAM, CloudFormation, Route 53, CloudFront, Lambda, VPC, Cloudwatch, Glacier and more.", 
    "submissions": [
        {
            "author": "sheffus", 
            "created_utc": 1506803619.0, 
            "domain": "i.redd.it", 
            "id": "73hblk", 
            "is_reddit_media_domain": true, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73hblk/cant_register_domains/", 
            "score": 10, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Can't register domains...", 
            "url": "https://i.redd.it/vlm1z3esy2pz.jpg"
        }, 
        {
            "author": "linuxhiker", 
            "created_utc": 1506797770.0, 
            "domain": "pgconf.us", 
            "id": "73gqvv", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73gqvv/pgconf_seattle_adds_aws_and_data_science_track/", 
            "score": 11, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "PGConf Seattle adds AWS and Data Science track, submit a talk, We .. Want .. You ..", 
            "url": "https://www.pgconf.us/conferences/Seattle2017"
        }, 
        {
            "author": "wwoop", 
            "created_utc": 1506787477.0, 
            "domain": "self.aws", 
            "id": "73fq2k", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73fq2k/aws_paris_has_been_announced_more_than_1y_ago/", 
            "score": 17, 
            "selftext": "https://aws.amazon.com/blogs/aws/coming-in-2017-new-aws-region-in-france/ ... should we wait for Re:Invent for official announcement or did I miss something? They said Paris will be available in 2017, with 1 quarter left, it's unlikely they will be able to meet this deadline", 
            "subreddit": "aws", 
            "title": "AWS Paris has been announced more than 1y ago ...", 
            "url": "https://www.reddit.com/r/aws/comments/73fq2k/aws_paris_has_been_announced_more_than_1y_ago/"
        }, 
        {
            "author": "VTNite", 
            "created_utc": 1506786371.0, 
            "domain": "self.aws", 
            "id": "73fm0b", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 53, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73fm0b/what_do_you_use_for_centralized_logging_today/", 
            "score": 33, 
            "selftext": "Hey everyone,\n\nJust trying to figure out what cool kids are using these days for Centralized Logging. I mean don't get me wrong, I like CloudWatch and all, but I really miss my old Splunk dashboards back in my previous VMWare place...\n\nI see there is an AMI for Splunk... At a cost... Are they still relevant in Cloud scene in 2017? If not what are people using? ELK?\n\nMainly I'm looking for end-to-end correlation of my data and building simple dashboards\n\nWould appreciate your feedback :)\n\nTIA!\n\nEdit:\n\nRecommendations thus far:\n\n\n- Sumologic\n- ELK\n- Splunk\n- Loggly\n- Papertrail\n- AWS Athena\n- Logentries\n- Rollbar\n- Senty\n- Bugsnag\n- Stackify", 
            "subreddit": "aws", 
            "title": "What do you use for Centralized Logging TODAY?", 
            "url": "https://www.reddit.com/r/aws/comments/73fm0b/what_do_you_use_for_centralized_logging_today/"
        }, 
        {
            "author": "koalillo", 
            "created_utc": 1506765944.0, 
            "domain": "self.aws", 
            "id": "73e4zd", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 40, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73e4zd/how_many_ec2_instances_you_can_get/", 
            "score": 6, 
            "selftext": "I'm doing some investigation about bruteforcing a crypto problem and some quick calculations say that m4.10xlarge instances offer the best bang for buck for my use case. I'm made some numbers and bruteforcing my entire solution space would cost ~$125000. However, if I were to complete the bruteforcing in one week, I'd need 2000 instances.\n\nIs it realistic to be able to get 2000 m4.10xlarges? What's the maximum amount of instances you have seen?\n\nedit: I'm aware of the standard limits. We've needed to request upgrades at work. However I wonder how much they allow...", 
            "subreddit": "aws", 
            "title": "How many EC2 instances you can get?", 
            "url": "https://www.reddit.com/r/aws/comments/73e4zd/how_many_ec2_instances_you_can_get/"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1506752893.0, 
            "domain": "self.aws", 
            "id": "73dgam", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73dgam/does_lambda_support_aspnet_core_2_razor_pages/", 
            "score": 6, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Does Lambda support ASP.NET Core 2 Razor Pages?", 
            "url": "https://www.reddit.com/r/aws/comments/73dgam/does_lambda_support_aspnet_core_2_razor_pages/"
        }, 
        {
            "author": "5ekundes", 
            "created_utc": 1506741889.0, 
            "domain": "self.aws", 
            "id": "73cqpz", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73cqpz/using_projectionexpression_on_list_that_contain/", 
            "score": 6, 
            "selftext": "Say that this is the table structure:\n   \n\n     [{ name:\"test\", age:99, \n        Info: [\n        { location:\"A\", num:11  },\n        { location:\"B\", num:99  }\n        ]\n    }]\n\nWhat i want to get is something like this:\n\n    { name: \"test\", \n         Info:[\n        {location:\"A\"},\n        {location:\"B\"}\n    ]}\n\nwould that be possible? I can't seem to make it work unless I specify the index. as shown below:\n\n    ProjectionExpression=\"name, #mp[0].location\",\n    Select='SPECIFIC_ATTRIBUTES', \n    ExpressionAttributeNames={\"#mp\": \"Info\"}\n\nHow do I do this?", 
            "subreddit": "aws", 
            "title": "Using ProjectionExpression on List that contain maps", 
            "url": "https://www.reddit.com/r/aws/comments/73cqpz/using_projectionexpression_on_list_that_contain/"
        }, 
        {
            "author": "Sunlighter", 
            "created_utc": 1506734867.0, 
            "domain": "self.aws", 
            "id": "73c74k", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73c74k/t2_linux_instance_price_cut/", 
            "score": 19, 
            "selftext": "I haven't seen an announcement yet, but it looks like prices on Linux T2 instances -- on-demand and reserved -- are slightly lower than they were yesterday. For example a t2.nano three-year all-up-front reserved instance has fallen from $69 to $57.\n\n[Edit] The Windows t2.nano is a little cheaper, too.", 
            "subreddit": "aws", 
            "title": "T2 Linux Instance Price Cut?", 
            "url": "https://www.reddit.com/r/aws/comments/73c74k/t2_linux_instance_price_cut/"
        }, 
        {
            "author": "skladfin", 
            "created_utc": 1506726742.0, 
            "domain": "self.aws", 
            "id": "73bhub", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73bhub/how_to_block_certain_ips_from_accessing/", 
            "score": 4, 
            "selftext": "Hey guys, so I've tried many things so far but I can't seem to get a simple IP blocking mechanism working. I have a website and I would like to block crawlers and bots with known IP ranges from accessing the website due to load.\n\nRight now my website architecture is:\n\n* EC2 Instances in 2 Regions\n* Load Balancer in each region\n* CloudFront to serve static images/css/js\n\nI've Googled around and tried setting up WAF - which I could somehow only attach to my CloudFront but not my LoadBalancer(Not sure how to). I've also gone into the VPC ACL and blocked my own IP to see if that has any effect - nothing.\n\nWould really appreciate if someone can point me in the right direction here.\nThank you", 
            "subreddit": "aws", 
            "title": "How to block certain IPs from accessing?", 
            "url": "https://www.reddit.com/r/aws/comments/73bhub/how_to_block_certain_ips_from_accessing/"
        }, 
        {
            "author": "PVPSAAAAN", 
            "created_utc": 1506717454.0, 
            "domain": "self.aws", 
            "id": "73ak8r", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73ak8r/route_my_registered_domain_to_aws_website/", 
            "score": 6, 
            "selftext": "I uploaded my HTML website to AWS using CloudFront and it works perfectly on Safari, Chrome and iPhone. What I would like to do is route my .ae domain to the AWS website. I tried following the [instructions](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-cloudfront-distribution.html) to do it via Route 53 but it did not work. The website I bought my domain from (it is a telecom network that also controls the .ae domain) has domain management and the DNS hosting field is shown in [this photo](https://i.imgur.com/wmznk8G.png). Please note that I am a complete beginner in all of this.  ", 
            "subreddit": "aws", 
            "title": "Route my registered domain to AWS website?", 
            "url": "https://www.reddit.com/r/aws/comments/73ak8r/route_my_registered_domain_to_aws_website/"
        }, 
        {
            "author": "eikenberry", 
            "created_utc": 1506716884.0, 
            "domain": "self.aws", 
            "id": "73ai22", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73ai22/heads_up_about_issue_with_the_new_cloudformation/", 
            "score": 47, 
            "selftext": "In case you hadn't seen it, they just announced this new feature a few days ago.\n\nhttps://aws.amazon.com/about-aws/whats-new/2017/09/aws-cloudformation-now-provides-stack-termination-protection/\n\nJust wanted to give a heads up on a possible issue. Be careful about enabling it when creating a new stack. I just created one using the awscli that had an issue and went into the ROLLBACK_COMPLETE state, but it had the termination prevention enabled. So now it is stuck in limbo where it cannot be deleted due to the termination protection being active, and it can't be updated to disable it as stacks in ROLLBACK_COMPETE state can't be updated.\n\nThere is already a forum posting about it w/ no feedback as of yet.\n\nhttps://forums.aws.amazon.com/thread.jspa?messageID=807113\n\nSo if you are using this feature be sure to first create the stack and then, upon success, enable the termination prevention.", 
            "subreddit": "aws", 
            "title": "Heads up about issue with the new Cloudformation Termination Prevention feature", 
            "url": "https://www.reddit.com/r/aws/comments/73ai22/heads_up_about_issue_with_the_new_cloudformation/"
        }, 
        {
            "author": "ricktbaker", 
            "created_utc": 1506712891.0, 
            "domain": "self.aws", 
            "id": "73a2pj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73a2pj/early_dev_app_that_could_make_your_devops_life/", 
            "score": 20, 
            "selftext": "Well, at least part of your DevOps life.....\n\nSo, I work with a large number of different clients who have AWS accounts.   So I'm constantly having to login to their console account, find the server I want to connect to, figure out what key to use, see if I have to use a bastion host, etc.   It's a pain when you do this multiple times a day.\n\nSo, I've started working on a side project written in Electron and Vue to make life a little easier.\n\nIt's in the early dev phase, and is being developed on a Mac so take that into consideration.\n\nIn a nutshell it allows you to add multiple aws organizations then per region access keys to run the \"ec2:describeInstances\" command.   Scan for ssh keys needed by the servers, import said ssh keys.   List out the instances in a region and quickly connect via ssh, while using a bastion host if needed.\n\nI haven't actually built a distributable app, because it's still under constant development, but if you have node available, you should be able to run it locally.\n\nI'm just posting this here because I thought people might find it useful, and it might help me crush some design issues or just usability issues early in the dev process.\n\nhttp://ricktbaker.com/2017/09/29/devops_helper/", 
            "subreddit": "aws", 
            "title": "Early dev app that could make your DevOps life easier with AWS", 
            "url": "https://www.reddit.com/r/aws/comments/73a2pj/early_dev_app_that_could_make_your_devops_life/"
        }, 
        {
            "author": "draeath", 
            "created_utc": 1506712812.0, 
            "domain": "self.aws", 
            "id": "73a2g8", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 15, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73a2g8/poor_and_variable_write_latency_on_efs/", 
            "score": 10, 
            "selftext": "I'm playing around with [EFS](https://docs.aws.amazon.com/efs/latest/ug/whatisefs.html) - which sounds amazing. However, in practice while I have zero complaints about read throughput or read latency, I'm finding that write latencies are fairly bad (and write speed is not very good either).\n\nI'm making these observations on an r4.large instance, and I'm noticing a write latency ('avg exe' in nfsiostat) that varies between around 12ms to north of 120ms. Write speed seems to test between 100-200 mb/s pretty consistently (for comparison read latency is around 6.5ms with speeds north of a gb/s).\n\nIs this typical, and I'm not interpreting \"Low, consistent latency\" the way it's intended in when mentioned in [the documentation](https://docs.aws.amazon.com/efs/latest/ug/performance.html)? The workload I'm throwing at it isn't very heavy, a mount-lifetime average of 13 op/s that's in reality fairly bursty, and peaks around 32 op/s.\n\nI was receiving far better results when I had several small EBS volumes stripped via LVM (paid attention to EBS block sizes etc) but that method has much more management overhead.\n\n(this is non-production stuff too, so if anyone has any suggestions for tests/benchmarks/troubleshooting I'm happy to try!)\n\nOh! Using \"Amazon Linux AMI 2017.03.1.20170812 x86_64 HVM GP2\" should it matter to anyone reading. (ami-4fffc834 on us-east-1)", 
            "subreddit": "aws", 
            "title": "Poor (and variable) write latency on EFS?", 
            "url": "https://www.reddit.com/r/aws/comments/73a2g8/poor_and_variable_write_latency_on_efs/"
        }, 
        {
            "author": "rsh210m", 
            "created_utc": 1506711022.0, 
            "domain": "self.aws", 
            "id": "739vo0", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/739vo0/new_dev_environment_for_aws_lambda/", 
            "score": 8, 
            "selftext": "--- Sorry if you see this twice, based on the feedback i got i realize it would be relevant for the entire AWS audience--- \n\nWe released a new open-source project focusing on development involving AWS Lambda. It enables development of Lambda functions in a dev-friendly environment (local development experience), yet running in full context of a real life AWS Lambda environment. More details can be found in GitHub https://github.com/minutelab/mless. We hope you find it handy and valuable, as always - any feedback (let alone contributors) are more than welcome!", 
            "subreddit": "aws", 
            "title": "New Dev environment for AWS Lambda", 
            "url": "https://www.reddit.com/r/aws/comments/739vo0/new_dev_environment_for_aws_lambda/"
        }, 
        {
            "author": "rantpaht", 
            "created_utc": 1506705399.0, 
            "domain": "self.aws", 
            "id": "7399fp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/7399fp/historical_spot_prices_information/", 
            "score": 9, 
            "selftext": "Is there a website that has a longer lookback on AWS Spot pricing then what is provided by AWS?", 
            "subreddit": "aws", 
            "title": "Historical spot prices information", 
            "url": "https://www.reddit.com/r/aws/comments/7399fp/historical_spot_prices_information/"
        }, 
        {
            "author": "DB_CONNECTION_ERROR", 
            "created_utc": 1506704041.0, 
            "domain": "self.aws", 
            "id": "73941v", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73941v/how_secure_are_api_requests_to_s3/", 
            "score": 7, 
            "selftext": "Hi all, new to AWS, getting my feet wet with S3.  \n\nI'm using S3 to store millions of objects (documents) that are considered confidential.  The bucket is private, and IAM users are set up with policies to give only necessary access to my application, so that the application handles both uploading and downloading the files before streaming them back to the client (web).  \n\nI have bucket policies that all objects must be AES 256 encrypted (server side / at rest).\n\nMy question is are the upload / download API requests between my web server and S3 considered secure?  If the files / objects are considered confidential, do I also need to add some sort of layer where the API call itself is encrypted (SSL perhaps), and how would I begin configuring that?  \n\nI'm using the most recent version of the C# AWS API if that is any help.  \n\nThanks in advance!", 
            "subreddit": "aws", 
            "title": "How secure are API requests to S3?", 
            "url": "https://www.reddit.com/r/aws/comments/73941v/how_secure_are_api_requests_to_s3/"
        }, 
        {
            "author": "adisedsc", 
            "created_utc": 1506702117.0, 
            "domain": "self.aws", 
            "id": "738wd3", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/738wd3/aws_ec2_libexpatso1expat_2_0_1_rh64bit/", 
            "score": 1, 
            "selftext": "Trying to follow: http://gettaurus.org/docs/Installation/#Ubuntu\n\n    $ sudo yum install java-1.7.0-openjdk-headless.x86_64 python-devel.x86_64 libxml2-devel.x86_64 libxslt-devel.x86_64 zlib.x86_64 gcc.x86_64\n\n\n\nGetting:\n\n    Error: Package: python-libs-2.6.6-66.el6_8.x86_64 (CentOS-base)\n           Requires: libexpat.so.1(EXPAT_2_0_1_RH)(64bit)\n\nHow do I get the libexpat.so.1 dependency?\n\nI am running on:\n\n     Amazon Linux AMI 2017.03", 
            "subreddit": "aws", 
            "title": "AWS EC2 - libexpat.so.1(EXPAT_2_0_1_RH)(64bit) ??", 
            "url": "https://www.reddit.com/r/aws/comments/738wd3/aws_ec2_libexpatso1expat_2_0_1_rh64bit/"
        }, 
        {
            "author": "awsgeek", 
            "created_utc": 1506701647.0, 
            "domain": "awsgeek.com", 
            "id": "738ubb", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/738ubb/my_visual_notes_on_the_aws_application_load/", 
            "score": 54, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "My visual notes on the AWS Application Load Balancer, a core component in the AWS cloud", 
            "url": "http://www.awsgeek.com/posts/aws-alb-summary/"
        }, 
        {
            "author": "Nemesis519", 
            "created_utc": 1506701447.0, 
            "domain": "self.aws", 
            "id": "738th0", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/738th0/cloudformation_help/", 
            "score": 3, 
            "selftext": "Hey guys, I'm trying to take a CF template that was generated from a new CodeStar project and add additional resources. I've read CF documentation, watched some training videos, and understand it from a basic level. I'm still trying to completely wrap my head about it.\n\nBasically when you setup a new CodeStar project, it establishes a new git  repo, a single server and a pipeline (along with all the supporting policies / roles).\n\nI'm trying to add two additional servers so I can have a standard layout of a Dev server, QA server, and a Prod server as well as have the pipelines between everything.\n\nI was able to add the two additional servers vi CF, but I can't figure out how to have different deployment groups via pipelines. If someone can help modify my template, I think this will allow me to visualize the changes and finally have everything \"click\".\n\nI've uploaded both the yaml and the json versions of my base template without any changes (I pulled out the two new servers I added so we are starting on a clean slate)\n\nYAML - https://drive.google.com/file/d/0B0Jw22DarqjBaURJYlBfeXBLUDg/view?usp=sharing\n\nJSON - https://drive.google.com/file/d/0B0Jw22DarqjBbUxLMFU3ejlnTWc/view?usp=sharing\n\nI can manually add everything I need, but I'd love to get it working via CF and have a better understanding of writing / modifying templates. And if anyone has any tools that make this easier, please let me know.\n\nThanks!", 
            "subreddit": "aws", 
            "title": "Cloudformation help?", 
            "url": "https://www.reddit.com/r/aws/comments/738th0/cloudformation_help/"
        }, 
        {
            "author": "coinclink", 
            "created_utc": 1506701336.0, 
            "domain": "self.aws", 
            "id": "738t0h", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/738t0h/experiences_presenting_at_reinvent/", 
            "score": 12, 
            "selftext": "I've been invited to participate in a breakout session at re:Invent, which I'm really excited to do!\n\nAnyone here gotten this opportunity and want to share your experience?", 
            "subreddit": "aws", 
            "title": "Experiences Presenting at re:Invent?", 
            "url": "https://www.reddit.com/r/aws/comments/738t0h/experiences_presenting_at_reinvent/"
        }, 
        {
            "author": "Tazer79", 
            "created_utc": 1506701183.0, 
            "domain": "self.aws", 
            "id": "738se5", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/738se5/migrating_onprem_to_aws/", 
            "score": 7, 
            "selftext": "Hey guys and gals, \n\nI'm testing migrating on-prem VMWare Windows machines, and I've seen weird behavior that I'm hoping you guys can help me explain. After migrating I can login with cached credentials, but not local. I specifically made sure that this machine was in an OU that's explicitly not inheriting any GPO policies, changed the local admin password and tested logging in with that account.\n\nAfter migration, the local admin account doesn't work. I logged in using my cached AD creds and created a new admin user, and again, I can't login with that account. Not sure what the problem is. I'm simply using (10.x.x.x\\test) and then the password. \n\nAnyone seen this before? Thanks!", 
            "subreddit": "aws", 
            "title": "Migrating On-Prem to AWS", 
            "url": "https://www.reddit.com/r/aws/comments/738se5/migrating_onprem_to_aws/"
        }, 
        {
            "author": "holygamedev", 
            "created_utc": 1506700032.0, 
            "domain": "self.aws", 
            "id": "738nrt", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/738nrt/going_serverless_but_how_to_setup_a_workflow_and/", 
            "score": 6, 
            "selftext": "So I'm moving to serverless on new projects, from a Django/Python environment. I have worked with it to get a prototype up and running, but it is all setup from within AWS webGUI.\n\nI know there is a framework called Serverless and node-lambda, and was wondering of how people have their development environment setup?\n\nI'm somewhat new to JS as well, so I'm not all that familiar with grunt, gulp or webpack yet. Help would be appreciated.", 
            "subreddit": "aws", 
            "title": "Going serverless, but how to setup a workflow and development environment?", 
            "url": "https://www.reddit.com/r/aws/comments/738nrt/going_serverless_but_how_to_setup_a_workflow_and/"
        }, 
        {
            "author": "spline_reticulator", 
            "created_utc": 1506696901.0, 
            "domain": "self.aws", 
            "id": "738bc2", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/738bc2/whats_good_way_to_browse_an_efs_volume_with_a/", 
            "score": 11, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "What's good way to browse an EFS volume with a graphical file manager?", 
            "url": "https://www.reddit.com/r/aws/comments/738bc2/whats_good_way_to_browse_an_efs_volume_with_a/"
        }, 
        {
            "author": "robecorms", 
            "created_utc": 1506689551.0, 
            "domain": "self.aws", 
            "id": "737l1t", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/737l1t/ad_connector_allowing_unsigned_ldap/", 
            "score": 7, 
            "selftext": "Hi, So I'm trying to connect an AWS VPC to our on premise AD domain using the connector.\n\nThe connector requires unsigned LDAP requests to be permitted on the domain, but this seems to have been disabled at some point in the past. It happened long enough ago that we don't know who did this or what their reasons were. Obviously I know that it improves security and helps prevent replay attacks, but I'm unsure if this would have been changed in response to a pentest/audit/scan or whether someone just did it for fun.\n\nMy questions are: How bad is it to re-enable this? How great is the risk? Does anybody know of an authoritative source of information on this?\n\nWe use direct connect to route to AWS, so this is 'LAN' traffic and won't be traversing the public internet.", 
            "subreddit": "aws", 
            "title": "AD Connector - Allowing unsigned LDAP", 
            "url": "https://www.reddit.com/r/aws/comments/737l1t/ad_connector_allowing_unsigned_ldap/"
        }, 
        {
            "author": "TheCloudJedi", 
            "created_utc": 1506689016.0, 
            "domain": "self.aws", 
            "id": "737jh9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 19, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/737jh9/reinvent_how_to_link_certification/", 
            "score": 6, 
            "selftext": "Hey Guys,\nI'm having a hell of a time trying to get my certification from Kryterion linked to AWS' new portal. \n\nBut how do I link it to my Re:Invent registration? I want to make sure I can get into the certification lounge and get some sweet swag. The Re:Invent site says that you need a special marking on your badge to get in, so I'm just curious how that works.\n\nThanks,", 
            "subreddit": "aws", 
            "title": "Re:Invent - How to link certification?", 
            "url": "https://www.reddit.com/r/aws/comments/737jh9/reinvent_how_to_link_certification/"
        }, 
        {
            "author": "pepejovi", 
            "created_utc": 1506685466.0, 
            "domain": "self.aws", 
            "id": "7379ox", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/7379ox/using_1_policy_to_limit_access_for_proddev_lambda/", 
            "score": 7, 
            "selftext": "Hey, I want to make a policy that will allow a specific lambda stage ARN to do DynamoDB operations and logging.\n\nthis is what I have: https://pastebin.com/ki5q6CQf\n\nIt's currently linked into Lambda function \"testAutomagicalRoleSystem\", which I'm running through the Lambda test function.\n\n\n\n\nThis is what I'm getting:\n\n    \"message\": \"User: arn:aws:sts::id:assumed-role/<RoleName>/testAutomagicalRoleSystem is not authorized to perform: dynamodb:BatchWriteItem on resource: arn:aws:dynamodb:us-east-2:id:table/Data-DEV\",\n    \"code\": \"AccessDeniedException\",\n\n\nI'm guessing the condition is wrong as I've double, triple and quad-checked and re-copypasted the ARNs into the policy.\n\nThe policy I've pastebinned above has 2 policies, neither works. Latter one is the original attempt and the former is just my desperate scribblings.\n\n\n\nEdit: The end goal here would be to automatically restrain access of LambdaFunction:Dev to TableResource-DEV, and likewise for Prod. This way, I wouldn't have to re-set the role each time I want to release a new version of the lambda code.", 
            "subreddit": "aws", 
            "title": "Using 1 policy to limit access for prod/dev lambda functions?", 
            "url": "https://www.reddit.com/r/aws/comments/7379ox/using_1_policy_to_limit_access_for_proddev_lambda/"
        }, 
        {
            "author": "Naweze", 
            "created_utc": 1506677667.0, 
            "domain": "self.aws", 
            "id": "736rg8", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/736rg8/how_do_you_save_on_aws_s3_costs/", 
            "score": 12, 
            "selftext": "Looking for some uncommon strategies to save S3 costs.", 
            "subreddit": "aws", 
            "title": "How do you save on AWS S3 costs?", 
            "url": "https://www.reddit.com/r/aws/comments/736rg8/how_do_you_save_on_aws_s3_costs/"
        }, 
        {
            "author": "5mall5nail5", 
            "created_utc": 1506649528.0, 
            "domain": "self.aws", 
            "id": "734qpm", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/734qpm/s3_standard_vs_s3_reduced_redundancy_pricing/", 
            "score": 12, 
            "selftext": "Am I losing it?  I was just looking up S3 pricing for reference and S3 Standard is $0.0230/GB (up to 50TB) in N. Virginia.  However, RRS is $0.0240/GB for up to 1TB, then the next 49TB are $0.0236/GB.  This...   this... what?\n\nI am embarassed too because I know the differences between Standard and RRS, I got a decently high score on my AWS CA exam...  but I never bothered to look up the actual pricing.  I am confused lol.  I am sure I am missing something.", 
            "subreddit": "aws", 
            "title": "S3 Standard vs. S3 Reduced Redundancy pricing...", 
            "url": "https://www.reddit.com/r/aws/comments/734qpm/s3_standard_vs_s3_reduced_redundancy_pricing/"
        }, 
        {
            "author": "tleyden", 
            "created_utc": 1506648020.0, 
            "domain": "github.com", 
            "id": "734lof", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 23, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/734lof/keynuker_nuke_aws_keys_accidentally_leaked_to/", 
            "score": 53, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "KeyNuker - nuke AWS keys accidentally leaked to Github", 
            "url": "https://github.com/tleyden/keynuker"
        }, 
        {
            "author": "snapperplug", 
            "created_utc": 1506635917.0, 
            "domain": "aws.amazon.com", 
            "id": "733fmb", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/733fmb/nlb_now_supports_load_balancing_to_ip_addresses/", 
            "score": 10, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "NLB now supports load balancing to IP addresses as targets for AWS and on-premises resource", 
            "url": "https://aws.amazon.com/about-aws/whats-new/2017/09/elastic-load-balancing-network-load-balancer-now-supports-load-balancing-to-ip-addresses-as-targets-for-aws-and-on-premises-resources/"
        }, 
        {
            "author": "mdennis07", 
            "created_utc": 1506627075.0, 
            "domain": "self.aws", 
            "id": "732h1u", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "support", 
            "link_flair_text": "support query", 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/732h1u/converting_my_dynamodb_data_into_array_and_use_it/", 
            "score": 5, 
            "selftext": "Hi everyone.\n\nJust like what my title said. With the Lambda function below, I can see the data that it has been retrieved successfully using callback. But I'm struggling how to use this data into another array.\n\nCan someone help me to convert the scanned/filtered results from DynamoDB using my lambda function into an array/table and use it for the second function?\n\nAny help is appreciated.\n\n\t'use strict';\n\tconst AWS = require('aws-sdk'); //to read aws-sdk\n\tconst docClient = new AWS.DynamoDB.DocumentClient({region: 'us-east-1'});//get a handler for AWS DynamoDB\n\t//console.log('Loading function');\n\n\texports.handler = function(event, context, callback) {\n\t\tvar returnArray = {\n\t\t\t\"cardsToBeApproved\":[]\n\t\t};\n\tfunction fnReadDatafromDynamoDB(){\n\t\t\t// TODO implement\n\t\t\tvar filterValues = event.key1\n\t\t\tvar params = {\n\t\t\t\tTableName:'SampleTBL_TwoSecondaryIndex',\n\t\t\t\t//TableName: 'SampleDB_SecondaryIndexSort',\n\t\t\t\tIndexName: 'ServerType-LocalPath-index',\n\t\t\t\t//KeyConditionExpression: 'ServerType = :value and LocalPath = :path',\n\t\t\t\tFilterExpression: \"InstanceID = :value\",\n\t\t\t\tExpressionAttributeValues: {\n\t\t\t\t':value': 'ABC',\n\t\t\t   // ':path': 'C'\n\t\t\t   // ':topic': 'ABC'\n\t\t\t   \n\t\t\t\t},\n\t\t\t\t//FilterExpression: 'contains (InstanceID, :topic)',\n\t\t\t\tScanIndexForward: false // If False Descending; If True Ascending\n\t\t\t};\n\t\t\tdocClient.scan(params, function(err, data){\n\t\t\t\tif(err){\n\t\t\t\t\tConsole.log(err,null);\n\t\t\t\t}else{\n\t\t\t\t\t//Convert the DynamoDB data into Array and use it to DeleteFiles\n\t\t\t\t}\n\t\t\t});\n\t\t\t\n\t\t}\n\t\t\t\n\t\tfunction fnDeleteFiles(data){\n\t\t\t\n\t\t   //Need to use the Array here\n\t\t}    \n\t\t\t\n\t\tfnReadDatafromDynamoDB();\n\t};\n", 
            "subreddit": "aws", 
            "title": "Converting my DynamoDB Data into Array and use it to another function", 
            "url": "https://www.reddit.com/r/aws/comments/732h1u/converting_my_dynamodb_data_into_array_and_use_it/"
        }, 
        {
            "author": "silviadoomra", 
            "created_utc": 1506625510.0, 
            "domain": "aws.amazon.com", 
            "id": "732aop", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/732aop/testing_amazon_rds_for_oracle_plotting_latency/", 
            "score": 5, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Testing Amazon RDS for Oracle: Plotting Latency and IOPS for OLTP I/O Pattern", 
            "url": "https://aws.amazon.com/blogs/database/testing-amazon-rds-for-oracle-plotting-latency-and-iops-for-oltp-io-pattern/"
        }, 
        {
            "author": "phuque_ewe", 
            "created_utc": 1506623107.0, 
            "domain": "self.aws", 
            "id": "73212m", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 15, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/73212m/has_anyone_found_a_way_to_hide_boto3_credentials/", 
            "score": 6, 
            "selftext": "Right now I have my key and access_key embedded within my script, and we all know that's not good practice...", 
            "subreddit": "aws", 
            "title": "Has anyone found a way to hide boto3 credentials in a python script that gets called from AWS Glue?", 
            "url": "https://www.reddit.com/r/aws/comments/73212m/has_anyone_found_a_way_to_hide_boto3_credentials/"
        }, 
        {
            "author": "sheffus", 
            "created_utc": 1506621593.0, 
            "domain": "noneforme.com", 
            "id": "731ut5", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 39, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/731ut5/my_aws_reinvent_2017_guide_of_guides/", 
            "score": 33, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "My AWS re:Invent 2017 - Guide of Guides", 
            "url": "http://www.noneforme.com/2017/09/aws-reinvent-2017-guide-of-guides.html"
        }, 
        {
            "author": "guppyF1", 
            "created_utc": 1506621491.0, 
            "domain": "github.com", 
            "id": "731ued", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/731ued/post_a_formatted_notification_to_slack_when_iam/", 
            "score": 22, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Post a formatted notification to Slack when IAM policies are manipulated", 
            "url": "https://github.com/Signiant/aws-iam-slack-notifer"
        }, 
        {
            "author": "ydereky", 
            "created_utc": 1506620793.0, 
            "domain": "aws.amazon.com", 
            "id": "731rii", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/731rii/build_an_autonomous_vehicle_on_aws_and_race_it_at/", 
            "score": 22, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Build an Autonomous Vehicle on AWS and Race It at the re:Invent Robocar Rally", 
            "url": "https://aws.amazon.com/blogs/ai/build-an-autonomous-vehicle-on-aws-and-race-it-at-the-reinvent-robocar-rally/"
        }, 
        {
            "author": "crapspakkle", 
            "created_utc": 1506620117.0, 
            "domain": "self.aws", 
            "id": "731osl", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/731osl/automate_an_automation/", 
            "score": 5, 
            "selftext": "I am using EC2 Systems Manager automation to update and create new quarterly AMIs that are CISCAT hardened for Infosec.  What would be the best way to automate the automation?  Something like a cron job that would start each automation every 3 months?", 
            "subreddit": "aws", 
            "title": "Automate an automation?", 
            "url": "https://www.reddit.com/r/aws/comments/731osl/automate_an_automation/"
        }, 
        {
            "author": "coinclink", 
            "created_utc": 1506618785.0, 
            "domain": "self.aws", 
            "id": "731j7v", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/731j7v/saml_auth_to_api_gateway/", 
            "score": 5, 
            "selftext": "This has been something on my list of things to figure out for a while. Does anyone have an example of creating a custom authorizer for API Gateway that uses a SAML response from an Identity Provider like Shibboleth or ADFS? From what I've read, this is exactly what custom authorizers are designed for but I'm having trouble finding any example code out there.\n\nI also notice Cognito also allows you to create an ID Pool from an existing SAML Federated Identity Providers, but I can't really figure out if that is useful or not at this point because I haven't gotten it to work at all. ", 
            "subreddit": "aws", 
            "title": "SAML Auth to API Gateway", 
            "url": "https://www.reddit.com/r/aws/comments/731j7v/saml_auth_to_api_gateway/"
        }, 
        {
            "author": "cloudrobo", 
            "created_utc": 1506602824.0, 
            "domain": "self.aws", 
            "id": "72zu6z", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72zu6z/aws_rds_stopping/", 
            "score": 7, 
            "selftext": "AWS recently allowed the user to start and stop RDS database instances. I have a question related to it. \n\nIs there any remote possibility of losing data when database is stopped and started? What are the things an user should keep in mind while stopping and starting the database?", 
            "subreddit": "aws", 
            "title": "AWS RDS stopping", 
            "url": "https://www.reddit.com/r/aws/comments/72zu6z/aws_rds_stopping/"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1506587611.0, 
            "domain": "self.aws", 
            "id": "72ysup", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72ysup/how_does_more_than_one_security_group_behave/", 
            "score": 15, 
            "selftext": "i have read that i can have more than one security group associated with an instance and have discovered how the web console lets me do it. but i still have not found out how this works.  what i read did not say.  so i am wondering, before i run some tests to figure it out.  here are the two behavior logic schemes i think might be used:\n\n1.  the security groups form a chain where traffic must pass all security groups in some sequence to be allowed.  this is like logical and.\n\n2.  the rule of all the chosen security groups are merged so traffic allowed by any rule in any security group is allowed.  this i like logical or.\n\ncan _you_ say how it really works?  do you know from reading it somewhere, or from doing it?  do you have active design logic based on how it work?", 
            "subreddit": "aws", 
            "title": "How does more than one Security Group behave?", 
            "url": "https://www.reddit.com/r/aws/comments/72ysup/how_does_more_than_one_security_group_behave/"
        }, 
        {
            "author": "mdennis07", 
            "created_utc": 1506584673.0, 
            "domain": "self.aws", 
            "id": "72ymr8", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72ymr8/powershell_and_dynamodb_inquiry/", 
            "score": 2, 
            "selftext": "Hi guys, how can I fetch or scan all of the items in my DynamoDB using PowerShell?\n\nIn my searches, I only see it can only be achieve using AWS CLI, is it possible in PowerShell alone?\n\nI've also seen a code that fetches an item but it requires me Primary key(It acts as a query if you are using Lambda function), but I need every items so I can get these things into an array. I'm also new in DynamoDB commands so I'm still struggling in playing around with the resources at hand.\n\nAny help is appreciated. :)", 
            "subreddit": "aws", 
            "title": "PowerShell and DynamoDB inquiry", 
            "url": "https://www.reddit.com/r/aws/comments/72ymr8/powershell_and_dynamodb_inquiry/"
        }, 
        {
            "author": "Bjorn121_", 
            "created_utc": 1506584336.0, 
            "domain": "self.aws", 
            "id": "72ym1e", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72ym1e/vpn_connections_to_multiple_networks/", 
            "score": 2, 
            "selftext": "[Disclaimer: I am not a Network architect, nor an expert]\n\nI have the following situation:\n\nA client of ours is looking to create a site to site VPN, to connect securely to a VPC.  If I understood correctly, you configure a Customer Gateway per branch (they have offices around the world) and then connect them to a Virtual Private Gateway.  That VPG is attached to your VPC.\n\nOnce that's done, you create a VPN Connection and link the VPG with the CG.  \n\nThis is fairly easy to understand and straight forward.  However, there are also 3rd party suppliers who need access to the environment. \n\nI was wondering if the following assumption is true:\nVPN CloudHub allows transitive VPN connections.  So if you peer Office 1 and 2 with the same VPG, you can **optionally** allow traffic from Office 1 to Office 2 via the VPG.\n\nIf you create a Cloudhub, can you block certain transitive connections?  So if you pair a 3rd party supplier with the Virtual Private Gateway, you block them from accessing Office 1 and Office 2.\n", 
            "subreddit": "aws", 
            "title": "VPN connections to multiple Networks", 
            "url": "https://www.reddit.com/r/aws/comments/72ym1e/vpn_connections_to_multiple_networks/"
        }, 
        {
            "author": "frogsbollocks", 
            "created_utc": 1506580228.0, 
            "domain": "self.aws", 
            "id": "72ycoj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72ycoj/cloudformation_with_glue/", 
            "score": 2, 
            "selftext": "I want to start using Glue to transform some data in S3 to a more Athena-friendly format.  Rather than setup this manually I was hoping to setup a Cloudformation template that I can deploy and run using our CI tool.  \n\nIs this possible?", 
            "subreddit": "aws", 
            "title": "Cloudformation with Glue?", 
            "url": "https://www.reddit.com/r/aws/comments/72ycoj/cloudformation_with_glue/"
        }, 
        {
            "author": "RagingAnemone", 
            "created_utc": 1506571498.0, 
            "domain": "self.aws", 
            "id": "72xq73", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72xq73/createimage_question/", 
            "score": 3, 
            "selftext": "When I run a create-image command with Windows, I see windows logout (and I assume reboot).  When I do the same thing with RHEL, I stay logged into the server.  I even explicitly add the --reboot command, but I remain logged in.  Is this behaving properly?  Is it actually taking a clean snapshot?", 
            "subreddit": "aws", 
            "title": "create-image question", 
            "url": "https://www.reddit.com/r/aws/comments/72xq73/createimage_question/"
        }, 
        {
            "author": "adisedsc", 
            "created_utc": 1506564982.0, 
            "domain": "self.aws", 
            "id": "72x5k1", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72x5k1/postgresql_aws_rds_cpu_at_100_from_time_to_time/", 
            "score": 1, 
            "selftext": "From time to time when there's a burst of activity in our application (Java/Spring/Hibernate/Tomcat stack with PostgreSQL) - our RDS CPU usage go up to 100%, sometimes it persist for some period of time which slows down everything in our application\n\nRDS Usage Chart: https://imgur.com/WziVm2R\n\nThis is already improved after we found some slow queries that we improved.\n\nAt this point, we are at a lost as to what else is going on, I guess we could turn on the hibernate query logging, but that would be overwhelming amount of things to look at.\n\nAre there any smarter approach? Any particular tool that would be handy to monitor and analyze what's going on between our application and the database?", 
            "subreddit": "aws", 
            "title": "PostgreSQL (AWS RDS) CPU at 100% from time to time - how to analyze?", 
            "url": "https://www.reddit.com/r/aws/comments/72x5k1/postgresql_aws_rds_cpu_at_100_from_time_to_time/"
        }, 
        {
            "author": "BEAR-OVERDRIVE", 
            "created_utc": 1506564857.0, 
            "domain": "self.aws", 
            "id": "72x55s", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72x55s/adfs_proxy_and_aws_load_balancer/", 
            "score": 5, 
            "selftext": "Hello all. Just wanted to run something past you all and see if anyone had any ideas.\n\nI have an ADFS proxy server that I have setup on a load balancer. For now, it's just a single instance. I am trying to get a domain (for now lets call it adfs.domain.com) to resolve to the adfs setup on the instance via the load balancer, but I can't seem to get it to work.\n\nI grabbed the IP's of the load balancer and modified my local hosts file to point adfs.domain.com to one of the IP's of the load balancer (I know you're not supposed to do this for real, it's just to test). Then, when I try to browse to or auth to the adfs setup on adfs.domain.com (using https://adfs.domain.com/adfs/ls/IdpInitiatedSignon.aspx), it spins for a while and then returns \"This page isn\u2019t working, adfs.domain.com didn\u2019t send any data. ERR_EMPTY_RESPONSE\"\n\nI have the ssl cert added to the load balancer. The LB and the instance are in the same AZ, the security groups are setup to allow traffic on 443. I've tested ADFS internally on the domain and everything is working fine. I'm stuck on this one. If anyone has any ideas I'd be grateful.\n\nThanks!", 
            "subreddit": "aws", 
            "title": "ADFS Proxy and AWS Load Balancer", 
            "url": "https://www.reddit.com/r/aws/comments/72x55s/adfs_proxy_and_aws_load_balancer/"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1506558880.0, 
            "domain": "self.aws", 
            "id": "72wl9f", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72wl9f/problem_canceling_a_persistent_spot_request/", 
            "score": 2, 
            "selftext": "i've been running a persistent spot request for a while.  i no longer need for it to run.  so i canceled the spot request at the web console.  it terminated the instance, did _not_ cancel the spot request, and restarted the instance.  the stop action for the instance is grayed-out (as expected for a spot request).", 
            "subreddit": "aws", 
            "title": "problem canceling a persistent spot request", 
            "url": "https://www.reddit.com/r/aws/comments/72wl9f/problem_canceling_a_persistent_spot_request/"
        }, 
        {
            "author": "hidiegomariani", 
            "created_utc": 1506544860.0, 
            "domain": "github.com", 
            "id": "72v5w5", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72v5w5/show_raws_an_aws_lambda_function_that_looks_for/", 
            "score": 50, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Show /r/aws: An AWS Lambda function that looks for Bitcoin arbitrage opportunities", 
            "url": "https://github.com/0x13a/bitcoin-arbitrage"
        }, 
        {
            "author": "Garetht", 
            "created_utc": 1506543624.0, 
            "domain": "self.aws", 
            "id": "72v0vc", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72v0vc/upgrade_simple_ad_to_full/", 
            "score": 5, 
            "selftext": "I fear I know the answer to this, but...\n\nOur AWS environment was built using simple AD, but now I'm looking into using Duo for two factor authentication, and it only supports full-fat Active Directory.\n\nAre there any options for upgrading simple AD in AWS to the full Active Directory?", 
            "subreddit": "aws", 
            "title": "Upgrade Simple AD to full?", 
            "url": "https://www.reddit.com/r/aws/comments/72v0vc/upgrade_simple_ad_to_full/"
        }, 
        {
            "author": "eon01", 
            "created_utc": 1506540881.0, 
            "domain": "medium.com", 
            "id": "72uprq", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72uprq/creating_a_serverless_python_api_using_aws_lambda/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Creating a Serverless Python API Using AWS Lambda & Chalice", 
            "url": "https://medium.com/@eon01/creating-a-serverless-python-api-using-aws-lambda-chalice-d321dc43ce2"
        }, 
        {
            "author": "cortexprime", 
            "created_utc": 1506538677.0, 
            "domain": "self.aws", 
            "id": "72uglu", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72uglu/question_aws_workspaces/", 
            "score": 1, 
            "selftext": "I understand the IP address of an AWS Workspace remains until it is removed, but is there a way to assign or provision a specific IP to a specific user's workspace?", 
            "subreddit": "aws", 
            "title": "Question: AWS Workspaces", 
            "url": "https://www.reddit.com/r/aws/comments/72uglu/question_aws_workspaces/"
        }, 
        {
            "author": "sterlingarcher79", 
            "created_utc": 1506534218.0, 
            "domain": "self.aws", 
            "id": "72txwg", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72txwg/aws_cloud_related_blogs_from_customers/", 
            "score": 19, 
            "selftext": "Hello, what would be a good list of aws related blogs from technical teams working at client side? Netflix has a great one but would like to expand my reading list.", 
            "subreddit": "aws", 
            "title": "AWS Cloud Related Blogs from Customers", 
            "url": "https://www.reddit.com/r/aws/comments/72txwg/aws_cloud_related_blogs_from_customers/"
        }, 
        {
            "author": "silviadoomra", 
            "created_utc": 1506529991.0, 
            "domain": "aws.amazon.com", 
            "id": "72tge8", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72tge8/automating_sql_caching_for_amazon_elasticache_and/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Automating SQL Caching for Amazon ElastiCache and Amazon RDS", 
            "url": "https://aws.amazon.com/blogs/database/automating-sql-caching-for-amazon-elasticache-and-amazon-rds/"
        }, 
        {
            "author": "Maverick94", 
            "created_utc": 1506528684.0, 
            "domain": "self.aws", 
            "id": "72tayr", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72tayr/share_access_to_mysql_database_on_aws_rds/", 
            "score": 0, 
            "selftext": "Hello everyone. I'm a computer science student and a total noob at Amazon Web Services. I'm developing a web app, and up until now it was only me, so I was working with a MySQL database locally. But now 3 colleagues are joining me, and we all need to be able to work with the same database.\n\nI figured my best option would be to host said database on AWS RDS, but I can't seem to figure out how to create a group and grant it the permissions needed to read and write to that MySQL database. Any help (or an alternative as to how to \"share\" the database) would be greatly appreciated!!", 
            "subreddit": "aws", 
            "title": "Share access to MySQL database on AWS RDS", 
            "url": "https://www.reddit.com/r/aws/comments/72tayr/share_access_to_mysql_database_on_aws_rds/"
        }, 
        {
            "author": "andreal", 
            "created_utc": 1506527318.0, 
            "domain": "self.aws", 
            "id": "72t576", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72t576/aws_glue_tutorial_not_sure_how_to_get_the_name_of/", 
            "score": 2, 
            "selftext": "Hi everyone! I'm trying to follow this tutorial https://aws.amazon.com/blogs/big-data/harmonize-query-and-visualize-data-from-various-providers-using-aws-glue-amazon-athena-and-amazon-quicksight/ to understand AWS Glue a bit better, but I'm having a hard time with one of the steps\n\nIn the job generation, they have this step\n>Let\u2019s now convert that to a DataFrame.  Please replace the <DYNAMIC_FRAME_NAME> with the name generated in the script. \n\nAnd this snippet\n\n     ##----------------------------------\n     #convert to a Spark DataFrame...\n     customDF = <DYNAMIC_FRAME_NAME>.toDF()\n\nBut I can't seem to find where the <DYNAMIC_FRAME_NAME> can be found. I thought it was customDF = resolvechoice2.toDF() , but it didn't run correctly.\n\nHere's my entire code (with the edited names of the buckets, of course)\n\n    import sys\n    from awsglue.transforms import *\n    from awsglue.utils import getResolvedOptions\n    from pyspark.context import SparkContext\n    from awsglue.context import GlueContext\n    from awsglue.job import Job\n    from pyspark.sql.functions import lit\n    from awsglue.dynamicframe import DynamicFrame\n\n    ## @params: [JOB_NAME]\n    args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n\n    sc = SparkContext()\n    glueContext = GlueContext(sc)\n    spark = glueContext.spark_session\n    job = Job(glueContext)\n    job.init(args['JOB_NAME'], args)\n    ## @type: DataSource\n    ## @args: [database = \"nycitytaxianalysis\", table_name = \"blog_yellow\",    transformation_ctx = \"datasource0\"]\n    ## @return: datasource0\n    ## @inputs: []\n    datasource0 = glueContext.create_dynamic_frame.from_catalog(database = \"nycitytaxianalysis\", table_name = \"blog_yellow\", transformation_ctx = \"datasource0\")\n    ## @type: ApplyMapping\n    ## @args: [mapping = [(\"vendorid\", \"long\", \"vendorid\", \"long\"), (\"tpep_pickup_datetime\", \"string\", \"pickup_datetime\", \"timestamp\"), (\"tpep_dropoff_datetime\", \"string\", \"dropoff_datetime\", \"timestamp\"), (\"passenger_count\", \"long\", \"passenger_count\", \"long\"), (\"trip_distance\", \"double\", \"trip_distance\", \"double\"), (\"pickup_longitude\", \"double\", \"pickup_longitude\", \"double\"), (\"pickup_latitude\", \"double\", \"pickup_latitude\", \"double\"), (\"ratecodeid\", \"long\", \"ratecodeid\", \"long\"), (\"store_and_fwd_flag\", \"string\", \"store_and_fwd_flag\", \"string\"), (\"dropoff_longitude\", \"double\", \"dropoff_longitude\", \"double\"), (\"dropoff_latitude\", \"double\", \"dropoff_latitude\", \"double\"), (\"payment_type\", \"long\", \"payment_type\", \"long\"), (\"fare_amount\", \"double\", \"fare_amount\", \"double\"), (\"extra\", \"double\", \"extra\", \"double\"), (\"mta_tax\", \"double\", \"mta_tax\", \"double\"), (\"tip_amount\", \"double\", \"tip_amount\", \"double\"), (\"tolls_amount\", \"double\", \"tolls_amount\", \"double\"), (\"improvement_surcharge\", \"double\", \"improvement_surcharge\", \"double\"), (\"total_amount\", \"double\", \"total_amount\", \"double\")], transformation_ctx = \"applymapping1\"]\n    ## @return: applymapping1\n    ## @inputs: [frame = datasource0]\n    applymapping1 = ApplyMapping.apply(frame = datasource0, mappings = [(\"vendorid\", \"long\", \"vendorid\", \"long\"), (\"tpep_pickup_datetime\", \"string\", \"pickup_datetime\", \"timestamp\"), (\"tpep_dropoff_datetime\", \"string\", \"dropoff_datetime\", \"timestamp\"), (\"passenger_count\", \"long\", \"passenger_count\", \"long\"), (\"trip_distance\", \"double\", \"trip_distance\", \"double\"), (\"pickup_longitude\", \"double\", \"pickup_longitude\", \"double\"), (\"pickup_latitude\", \"double\", \"pickup_latitude\", \"double\"), (\"ratecodeid\", \"long\", \"ratecodeid\", \"long\"), (\"store_and_fwd_flag\", \"string\", \"store_and_fwd_flag\", \"string\"), (\"dropoff_longitude\", \"double\", \"dropoff_longitude\", \"double\"), (\"dropoff_latitude\", \"double\", \"dropoff_latitude\", \"double\"), (\"payment_type\", \"long\", \"payment_type\", \"long\"), (\"fare_amount\", \"double\", \"fare_amount\", \"double\"), (\"extra\", \"double\", \"extra\", \"double\"), (\"mta_tax\", \"double\", \"mta_tax\", \"double\"), (\"tip_amount\", \"double\", \"tip_amount\", \"double\"), (\"tolls_amount\", \"double\", \"tolls_amount\", \"double\"), (\"improvement_surcharge\", \"double\", \"improvement_surcharge\", \"double\"), (\"total_amount\", \"double\", \"total_amount\", \"double\")], transformation_ctx = \"applymapping1\")\n    ## @type: ResolveChoice\n    ## @args: [choice = \"make_struct\", transformation_ctx = \"resolvechoice2\"]\n    ## @return: resolvechoice2\n    ## @inputs: [frame = applymapping1]\n    resolvechoice2 = ResolveChoice.apply(frame = applymapping1, choice = \"make_struct\", transformation_ctx = \"resolvechoice2\")\n    ## @type: DropNullFields\n    ## @args: [transformation_ctx = \"dropnullfields3\"]\n    ## @return: dropnullfields3\n    ## @inputs: [frame = resolvechoice2]\n    dropnullfields3 = DropNullFields.apply(frame = resolvechoice2, transformation_ctx = \"dropnullfields3\")\n    ##----------------------------------\n    #convert to a Spark DataFrame...\n    customDF = resolvechoice2.toDF() <<---- HERE'S MY CODE \n \n    #add a new column for \"type\"\n    customDF = customDF.withColumn(\"type\", lit('yellow'))\n \n    # Convert back to a DynamicFrame for further processing.\n    customDynamicFrame = DynamicFrame.fromDF(customDF, glueContext, \"customDF_df\")\n    ##----------------------------------\n    ## @type: DataSink\n    ## @args: [connection_type = \"s3\", connection_options = {\"path\": \"s3://<<s3-bucket>>/glue-blog/\"}, format = \"parquet\", transformation_ctx = \"datasink4\"]\n    ## @return: datasink4\n    ## @inputs: [frame = customDynamicFrame]\n    datasink4 = glueContext.write_dynamic_frame.from_options(frame = customDynamicFrame, connection_type = \"s3\", connection_options = {\"path\": \"s3://<<s3-bucket>>/glue-blog/\"}, format = \"parquet\", transformation_ctx = \"datasink4\")\n    job.commit()\n\nWhere can I find the <DYNAMIC_FRAME_NAME> ?\n\nThanks!", 
            "subreddit": "aws", 
            "title": "AWS Glue Tutorial: Not sure how to get the name of the dynamic frame that is being used to write out the data", 
            "url": "https://www.reddit.com/r/aws/comments/72t576/aws_glue_tutorial_not_sure_how_to_get_the_name_of/"
        }, 
        {
            "author": "_dwig_", 
            "created_utc": 1506526505.0, 
            "domain": "self.aws", 
            "id": "72t1v8", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72t1v8/ecs_vs_docker_swarm/", 
            "score": 11, 
            "selftext": "I'm struggling to find a definitive reason to choose ECS over Docker Swarm.  The ecs-cli seems to be AWS's answer to Docker's swarm mode, considering you can you deploy services / tasks directly from a docker-compose.yml file and update / scale services just as easily.  Are there any big 'gotchas' for either of these strategies? Or does anyone have a strong inclination to choose one over the other?", 
            "subreddit": "aws", 
            "title": "ECS vs Docker Swarm", 
            "url": "https://www.reddit.com/r/aws/comments/72t1v8/ecs_vs_docker_swarm/"
        }, 
        {
            "author": "kadimi", 
            "created_utc": 1506521337.0, 
            "domain": "self.aws", 
            "id": "72shnx", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72shnx/can_an_ami_trial_license_be_abused_by_regularly/", 
            "score": 13, 
            "selftext": "From a publisher side, let's say I have an AMI published on the marketplace with an evaluation period limited in time not in functionalities. The AMI has a configuration export feature allowing to build the exact same box on other instances. \n\nCan a customer, just before the trial period expires, export the configuration, import it into a new instance and terminate the old one, and do this endlessly to avoid the subscription fees? \n\nFrom a reseller side, can one who resells the AMI subscriptions to 'ephemeral' customers, execute a new instance per customer. If the customer leaves before the trial ends, the instance is just terminated, if he stays the instance get switched to the paid subscription. If the majority of the customers leave before they reach the trial end, then the publisher doesn't make any profit, the reseller does.\n\nAny thoughts on this? What the legal terms say?", 
            "subreddit": "aws", 
            "title": "Can an AMI trial license be abused by regularly regenerating a new instance", 
            "url": "https://www.reddit.com/r/aws/comments/72shnx/can_an_ami_trial_license_be_abused_by_regularly/"
        }, 
        {
            "author": "tech_tuna", 
            "created_utc": 1506519819.0, 
            "domain": "self.aws", 
            "id": "72sc5h", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72sc5h/user_data_shell_scripts_vs_cloudinit/", 
            "score": 7, 
            "selftext": "Just curious. . . informal poll/post here. . . what do you use to bootstrap your EC2 instances?  Shell scripts or cloud-init directives?\n\nOr do you use something like a CAPS tool in lieu of shell scripts?", 
            "subreddit": "aws", 
            "title": "User data shell scripts vs cloud-init?", 
            "url": "https://www.reddit.com/r/aws/comments/72sc5h/user_data_shell_scripts_vs_cloudinit/"
        }, 
        {
            "author": "melezhik", 
            "created_utc": 1506510725.0, 
            "domain": "sparrowhub.org", 
            "id": "72rk36", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72rk36/handy_cli_utility_to_track_ec2_cpu_load_sparrowhub/", 
            "score": 12, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "handy cli utility to track ec2 CPU load / @sparrowhub", 
            "url": "https://sparrowhub.org/info/aws-cw-cpu"
        }, 
        {
            "author": "Bizzelicious", 
            "created_utc": 1506501596.0, 
            "domain": "slideshare.net", 
            "id": "72qyxz", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": {
                "oembed": {
                    "author_name": "Amazon Web Services", 
                    "author_url": "https://www.slideshare.net/AmazonWebServices", 
                    "description": "Learn what to expect at re:Invent 2017 - Learn what's new and noteworthy at re:Invent 2017 - Learn to plan your time effectively at re:Invent 2017", 
                    "height": 500, 
                    "html": "<iframe class=\"embedly-embed\" src=\"//cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.slideshare.net%2Fslideshow%2Fembed_code%2Fkey%2FwbqxIBswttZrtx&url=https%3A%2F%2Fwww.slideshare.net%2FAmazonWebServices%2Fget-ready-for-reinvent-2017-content-overview-aws-online-tech-talk&image=https%3A%2F%2Fcdn.slidesharecdn.com%2Fss_thumbnails%2F09122017-reinvent-get-ready-f-2b8a498d-0358-4e42-bec0-d50979439157-1397661748-170913195354-thumbnail-4.jpg%3Fcb%3D1505332446&key=522baf40bd3911e08d854040d3dc5c07&type=text%2Fhtml&schema=slideshare\" width=\"600\" height=\"500\" scrolling=\"no\" frameborder=\"0\" allowfullscreen></iframe>", 
                    "provider_name": "SlideShare", 
                    "provider_url": "https://www.slideshare.net/", 
                    "thumbnail_height": 432, 
                    "thumbnail_url": "https://cdn.slidesharecdn.com/ss_thumbnails/09122017-reinvent-get-ready-f-2b8a498d-0358-4e42-bec0-d50979439157-1397661748-170913195354-thumbnail-4.jpg?cb=1505332446", 
                    "thumbnail_width": 768, 
                    "title": "Get Ready for re:Invent 2017 Content Overview - AWS Online Tech Talk", 
                    "type": "rich", 
                    "version": "1.0", 
                    "width": 600
                }, 
                "type": "slideshare.net"
            }, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72qyxz/get_ready_for_reinvent_2017_content_overview_aws/", 
            "score": 14, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Get Ready for re:Invent 2017 Content Overview - AWS Online Tech Talk", 
            "url": "https://www.slideshare.net/AmazonWebServices/get-ready-for-reinvent-2017-content-overview-aws-online-tech-talk"
        }, 
        {
            "author": "readerpl", 
            "created_utc": 1506494196.0, 
            "domain": "self.aws", 
            "id": "72qiuu", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72qiuu/is_it_possible_to_run_proxy_server_on_aws_lambda/", 
            "score": 2, 
            "selftext": "Hello,\ni wonder if it is possible to run proxy server on AWS Lambda. Have You any informations about this?\nThank you", 
            "subreddit": "aws", 
            "title": "Is it possible to run proxy server on AWS Lambda?", 
            "url": "https://www.reddit.com/r/aws/comments/72qiuu/is_it_possible_to_run_proxy_server_on_aws_lambda/"
        }, 
        {
            "author": "dronemap", 
            "created_utc": 1506479060.0, 
            "domain": "self.aws", 
            "id": "72pcpg", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72pcpg/psi_support_getting_a_tax_invoice/", 
            "score": 10, 
            "selftext": "I have booked an AWS certification exam through the new provider, PSI Online. Having been charged 15% VAT on the booking fee I now need a tax invoice for the expense but am not getting anything out of PSI. I can generate a receipt on the PSI dashboard but it is not a valid tax invoice.\n\nI have submitted multiple support queries using multiple channels including on www.aws.training > Support > Certification Support (which seems to also go to PSI). On their live chat I could find out that the VAT is actually New Zealand GST (because I am from New Zealand) but they just forwarded my request for a tax invoice to the finance department and I never heard anything again. That was more than a week ago. I have contacted their support 7 times over the past 3 weeks. Each time I am promised a response in 24-48 hours but nothing ever comes out of it.\n\nHas anybody managed to get a tax invoice out of PSI? /u/jeffbarr, is this something you can help with or do you have any advice? I am now even considering contacting their Senior Network Engineer whose contact details are listed as admin contact on their domain registration.\n\n(PS: The whole PSI experience was extremely painful but I'll leave that rant for another time in an attempt to stay on topic.)", 
            "subreddit": "aws", 
            "title": "PSI Support - Getting a tax invoice", 
            "url": "https://www.reddit.com/r/aws/comments/72pcpg/psi_support_getting_a_tax_invoice/"
        }, 
        {
            "author": "andyr8939", 
            "created_utc": 1506476481.0, 
            "domain": "self.aws", 
            "id": "72p45k", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72p45k/atlassian_on_aws_roll_your_own_or_quickstarts/", 
            "score": 3, 
            "selftext": "Curious to see how many people here run some of the Atlassian suites on AWS, such as JIRA, Confluence, BitBucket?\n\nWe currently run all of them and more on-premise but are looking at moving to AWS.  The Quick Starts seems ideal but might be a bit of overkill than what we need, so was curious how many people roll their own infrastructure for these in AWS, vs using the Quick Starts?", 
            "subreddit": "aws", 
            "title": "Atlassian on AWS - Roll your own or Quickstarts", 
            "url": "https://www.reddit.com/r/aws/comments/72p45k/atlassian_on_aws_roll_your_own_or_quickstarts/"
        }, 
        {
            "author": "kgalb2", 
            "created_utc": 1506474072.0, 
            "domain": "self.aws", 
            "id": "72ow1g", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72ow1g/aws_cli_sslerror_for_latest_build_on_windows/", 
            "score": 4, 
            "selftext": "You can see the full issue [here](https://github.com/aws/aws-cli/issues/2855).\n\nThis manifested for me because my launch configs pull in the latest AWSCLI.msi and it is a bad version. Had to update all launch configs to be one version behind instead of grabbing the latest. Hopefully this gets fixed soon.", 
            "subreddit": "aws", 
            "title": "AWS CLI SSLError for latest build on Windows machines", 
            "url": "https://www.reddit.com/r/aws/comments/72ow1g/aws_cli_sslerror_for_latest_build_on_windows/"
        }, 
        {
            "author": "moduspwnens14", 
            "created_utc": 1506468234.0, 
            "domain": "docs.aws.amazon.com", 
            "id": "72oboy", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72oboy/termination_protection_now_available_for/", 
            "score": 46, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Termination protection now available for CloudFormation stacks", 
            "url": "http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-protect-stacks.html"
        }, 
        {
            "author": "crmpicco", 
            "created_utc": 1506461916.0, 
            "domain": "self.aws", 
            "id": "72nobb", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72nobb/a_free_forever_aws_solution_for_a_php_app_with_a/", 
            "score": 2, 
            "selftext": "Is there a current AWS free solution that offers a free forever deal for a PHP app with a MySQL database?\n\nThe site has very low traffic and the DB is small.\n\nThe Free tier page looks to me like it only offers a free solution for one year. Is this the case?\n\nAny advice appreciated ", 
            "subreddit": "aws", 
            "title": "A free forever AWS solution for a PHP app with a small MySQL DB", 
            "url": "https://www.reddit.com/r/aws/comments/72nobb/a_free_forever_aws_solution_for_a_php_app_with_a/"
        }, 
        {
            "author": "blank5tare", 
            "created_utc": 1506459780.0, 
            "domain": "self.aws", 
            "id": "72nfs4", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72nfs4/help_cfn_update_from_eclipse_and_aws_toolkit/", 
            "score": 3, 
            "selftext": "Expected: http://docs.aws.amazon.com/toolkit-for-eclipse/v1/user-guide/tke-cfn-editor-update-stack.html (image at Step 5)\n\nActual: https://imgur.com/v42GMl6\n\nHelp! What the heck am I doing wrong here? I saw a coworker (who is no longer with the company) do this exact procedure on his Windows machine and there were dialog boxes and values present in the \"template parameters\" screen. Why am I missing this information? If I click Finish to push the update, I get an error about missing parameters. I would try this on Windows, but we have been instructed to keep all work on this project in the company-supplied Ubuntu VM, so that is a non-option. I have already ensured that Eclipse (Neon.3 - 4.6.3), AWS plugins, and even my OS (Ubuntu 16.04.3) are up-to-date. \n\nI know I can upload the template to S3 and run it that way, but I need to figure out how to fix Eclipse as this is adding extra time and effort to my work.\n\nThanks in advance!", 
            "subreddit": "aws", 
            "title": "Help! CFN update from Eclipse and AWS Toolkit", 
            "url": "https://www.reddit.com/r/aws/comments/72nfs4/help_cfn_update_from_eclipse_and_aws_toolkit/"
        }, 
        {
            "author": "andyr8939", 
            "created_utc": 1506457083.0, 
            "domain": "self.aws", 
            "id": "72n4pa", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72n4pa/backup_question/", 
            "score": 3, 
            "selftext": "My company is starting to dip its toes into AWS but I'm struggling to get my head around the concept of backups so hopefully someone can help me clear it up.\n\nOn premise at the moment for example, backups are easy.  Take full/incremental backups on all VM's each day using a tool like Veeam, offload to tape or other media for offsite and you are done.\n\nBut in AWS, all i see mentioned are EC2 snapshots, RDS snapshots etc.   SO my question is, typically how do you guys manage your backups of your AWS infrastructure?   For S3 I'm totally fine with that and versioning, replication and offload to glacier, but for the other services, although I know how to back them up, the logic of how you structure it alludes me.", 
            "subreddit": "aws", 
            "title": "Backup Question", 
            "url": "https://www.reddit.com/r/aws/comments/72n4pa/backup_question/"
        }, 
        {
            "author": "ricktbaker", 
            "created_utc": 1506451731.0, 
            "domain": "self.aws", 
            "id": "72mi4u", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72mi4u/using_nginx_and_phpfpm_in_place_of_apache_in/", 
            "score": 14, 
            "selftext": "I recently had to convert a client over to beanstalk that wanted to use nginx and php-fpm for their wordpress/laravel app.   I hadn't done one of these for a couple years and lost my old notes.   All the documentation online I found still referred to modifying the hostmanager which is outdated.   \n\nSo, I went through the whole process strictly using ebextensions and the default PHP AMI that is used when setting up a new beanstalk application.\n\nFigured someone might find this useful:\n\nhttp://ricktbaker.com/2017/09/08/beanstalk-nginx-php/", 
            "subreddit": "aws", 
            "title": "Using nginx and php-fpm in place of apache in Beanstalk", 
            "url": "https://www.reddit.com/r/aws/comments/72mi4u/using_nginx_and_phpfpm_in_place_of_apache_in/"
        }, 
        {
            "author": "eddywebs", 
            "created_utc": 1506444423.0, 
            "domain": "self.aws", 
            "id": "72lnd9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72lnd9/aws_marketplace_sellers_how_is_your_exprience/", 
            "score": 1, 
            "selftext": "I just stumbled upon the aws marketplace >> https://aws.amazon.com/marketplace\n\nLooks like a great opportunity, any sellers out there ? Am curious to know about your experience and success ", 
            "subreddit": "aws", 
            "title": "AWS marketplace sellers - how is your exprience", 
            "url": "https://www.reddit.com/r/aws/comments/72lnd9/aws_marketplace_sellers_how_is_your_exprience/"
        }, 
        {
            "author": "hogie48", 
            "created_utc": 1506440657.0, 
            "domain": "self.aws", 
            "id": "72l7ir", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72l7ir/2017_reinvent_live_stream/", 
            "score": 13, 
            "selftext": "I am unable to attend this year unfortunately and was hoping to sign up for the live stream, but I can't seem to find any links for it... maybe just not up yet?  I know it will all be on youtube a couple days after the event is over, but in previous years there has been a live stream you can sign up for and watch everything.  Anyone have any idea if that is happening this year, and maybe it just doesn't happen until closer to the event?\n", 
            "subreddit": "aws", 
            "title": "2017 Re:Invent Live Stream?", 
            "url": "https://www.reddit.com/r/aws/comments/72l7ir/2017_reinvent_live_stream/"
        }, 
        {
            "author": "Alkanes123", 
            "created_utc": 1506439340.0, 
            "domain": "self.aws", 
            "id": "72l24j", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "support", 
            "link_flair_text": "support query", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72l24j/billing/", 
            "score": 2, 
            "selftext": "Is there a way to separate billing for different regions? For example: for any US region we would like to pay via credit card A, for a region in EU pay via credit card B and the Australian region pay via credit card C. \n\nIs this possible or do we have to setup different accounts with different payment methods?\n\nThank you!", 
            "subreddit": "aws", 
            "title": "Billing", 
            "url": "https://www.reddit.com/r/aws/comments/72l24j/billing/"
        }, 
        {
            "author": "guppyF1", 
            "created_utc": 1506436785.0, 
            "domain": "github.com", 
            "id": "72krum", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72krum/notify_slack_when_elastic_beanstalk_managed/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Notify Slack when Elastic Beanstalk managed platform updates are applied", 
            "url": "https://github.com/Signiant/aws-elasticbeanstalk-updates-notify-slack"
        }, 
        {
            "author": "Naweze", 
            "created_utc": 1506429101.0, 
            "domain": "simform.com", 
            "id": "72k0pu", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72k0pu/cloud_cost_optimization_strategies_for_compute/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Cloud Cost Optimization Strategies for Compute and Storage", 
            "url": "https://www.simform.com/cloud-cost-optimization-strategies-compute-storage/"
        }, 
        {
            "author": "epochwin", 
            "created_utc": 1506417206.0, 
            "domain": "aws.amazon.com", 
            "id": "72j6ab", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72j6ab/aws_config_rule_development_kit/", 
            "score": 24, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "AWS Config Rule Development Kit", 
            "url": "https://aws.amazon.com/blogs/mt/introducing-the-aws-config-rule-development-kit-rdk/"
        }, 
        {
            "author": "teamphy6", 
            "created_utc": 1506412446.0, 
            "domain": "self.aws", 
            "id": "72iw16", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72iw16/using_glue_to_import_detailed_billing_report_csvs/", 
            "score": 1, 
            "selftext": "Hi, I'm trying to use Glue to import the folder full of Detailed Billing Reports that AWS generates on our behalf and stores in an S3 bucket.  I believe these are just the standard ones from the AWS billing reports section.  Some are in CSV form and some are in Zips.  I created a Glue crawler that pics up all the files in the folder, and all the appropriate tables are created (Glue console, Cloudwatch logs, and Athena console confirm this).  The Glue console even gives me stats about how many rows were read.  The glue-generated schemas look fine and appropriate, however when previewing or querying the tables, there are no rows returned.  Even a select count returns 0.  Nothing in cloudwatch indicates an error.  Am I missing a step?  This is my first time using both Glue and Athena.  My understanding is that once the schema is defined and data read in, that it is queryable by Athena.", 
            "subreddit": "aws", 
            "title": "Using Glue to import Detailed Billing Report csvs, Empty Athena tables", 
            "url": "https://www.reddit.com/r/aws/comments/72iw16/using_glue_to_import_detailed_billing_report_csvs/"
        }, 
        {
            "author": "iamondemand", 
            "created_utc": 1506408741.0, 
            "domain": "self.aws", 
            "id": "72inp5", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 18, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72inp5/which_region_do_you_use_why/", 
            "score": 2, 
            "selftext": "Looking forward to the middle east region .. https://venturebeat.com/2017/09/25/amazon-to-open-its-first-aws-region-in-the-middle-east-by-2019/", 
            "subreddit": "aws", 
            "title": "Which region do you use? why?", 
            "url": "https://www.reddit.com/r/aws/comments/72inp5/which_region_do_you_use_why/"
        }, 
        {
            "author": "FlyerFocus", 
            "created_utc": 1506401814.0, 
            "domain": "self.aws", 
            "id": "72i69s", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72i69s/aws_newb_question_about_security_groups/", 
            "score": 2, 
            "selftext": "Hey Guys,  Hope this is the right place to post.  \n\nI am using a free ubunto microinstance I created and that I installed NGINX on.  NGINX is running.  I can see it when I do a ps -ef and I can telnet to localhost on port 80 and curl and whatnot. \n\nI cannot reach it from the outside world.  I am looking at the rules I have in the security group and it says allow port 80 inbound from anywhere.  I have double-checked and triple-checked that I am using THAT security group on THAT EC2 instance.  Yup.\n\nSo I thought I'd try to ping.  No ping.  So I went into the security group and turned on ICMP from anywhere.  Still no ping.\n\nOkay, so now I'm getting mad.  I am logged into the terminal via ssh/putty, so I go to the security group and I remove the ssh/port 22 inbound rule.  I'm expecting the putty to disconnect but nope.  Still logged in.  The cursor mocks me.\n\nIs there something I have to do to apply rule changes and make them effective?  I'm pretty sure I do not have to reboot the ubuntu instance.  And I quadruple checked that I am applying THAT security group to THAT server/instance.\n\nAny ideas will be fascinating to entertain.", 
            "subreddit": "aws", 
            "title": "AWS Newb Question about Security Groups", 
            "url": "https://www.reddit.com/r/aws/comments/72i69s/aws_newb_question_about_security_groups/"
        }, 
        {
            "author": "acegdyjh", 
            "created_utc": 1506389153.0, 
            "domain": "self.aws", 
            "id": "72h2nm", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72h2nm/scanning_s3_buckets_for_auditing_purposes/", 
            "score": 1, 
            "selftext": "Hi Reddit,\n\nWhat is the best way to scan data in S3 (for auditing purposes, possibly)? I was asked to do some research on this and utilizing AWS Athena was the first idea I could think of. But if you can provide more knowledge/ideas, I'd appreciate it.\n\nThanks!", 
            "subreddit": "aws", 
            "title": "Scanning S3 buckets for auditing purposes", 
            "url": "https://www.reddit.com/r/aws/comments/72h2nm/scanning_s3_buckets_for_auditing_purposes/"
        }, 
        {
            "author": "ydereky", 
            "created_utc": 1506377837.0, 
            "domain": "aws.amazon.com", 
            "id": "72fxs1", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72fxs1/create_a_question_and_answer_bot_with_amazon_lex/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Create a Question and Answer Bot with Amazon Lex and Amazon Alexa | Amazon Web Services", 
            "url": "https://aws.amazon.com/blogs/ai/creating-a-question-and-answer-bot-with-amazon-lex-and-amazon-alexa/"
        }, 
        {
            "author": "ydereky", 
            "created_utc": 1506377812.0, 
            "domain": "aws.amazon.com", 
            "id": "72fxos", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72fxos/build_a_voice_kit_with_amazon_lex_and_a_raspberry/", 
            "score": 2, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Build a Voice Kit with Amazon Lex and a Raspberry Pi | Amazon Web Services", 
            "url": "https://aws.amazon.com/blogs/ai/build-a-voice-kit-with-amazon-lex-and-a-raspberry-pi/"
        }, 
        {
            "author": "anderiv", 
            "created_utc": 1506377264.0, 
            "domain": "self.aws", 
            "id": "72fvu8", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72fvu8/rant_time_aws_account_manager_churn/", 
            "score": 12, 
            "selftext": "So, I manage AWS accounts, and provide AWS architectural direction for a group of ~5 companies or so. I don't require a whole lot of our account manager, but I do end up finding the need to email them once/month or so on various topics.\n\nIn the ~5 years I've been working with AWS, I've been through 5 account managers. It seems as if they rotate through on an annual basis. Right when I've established some amount of rapport with the rep and they understand my involvement with AWS and our use cases, they get moved around and I need to restart the same introductory song and dance with whomever is our new rep.\n\nTo add insult to injury, we're never informed of this change directly. I typically learn about it after emailing (whom I thought was) my account rep, then waiting a few days, then getting an email from a new person stating that they had been forwarded my email from the old rep.\n\nIs this similar to what you all are experiencing? Most of the account managers we've had have been decent from technical and communication perspective, which I appreciate, but the churn and annual reset makes for a really poor experience. I suspect that there's more continuity in account representatives once an org gets to higher levels of monthly spend, but perhaps not?\n\nAnyway, I just wanted to see if I've just been unlucky or if this is par-for-the-course.", 
            "subreddit": "aws", 
            "title": "Rant time: AWS Account Manager churn", 
            "url": "https://www.reddit.com/r/aws/comments/72fvu8/rant_time_aws_account_manager_churn/"
        }, 
        {
            "author": "penguinforpresident", 
            "created_utc": 1506374474.0, 
            "domain": "self.aws", 
            "id": "72flj0", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 14, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72flj0/easiest_way_to_run_a_scheduled_task_in_ec2/", 
            "score": 2, 
            "selftext": "I'm trying to figure out the easiest way to spin up an EC2 instance, run a command on the instance, and shut it down on a daily basis.  I'm leaning towards using lambda to script this through the python API (similar to this example: http://docs.aws.amazon.com/lambda/latest/dg/with-scheduledevents-example.html).  I can't script the entire command simply in lambda because I need around 20GB of disk space (running a pgdump), and it appears that lambda only provides a maximum of 512MB.  Am I on the right track?  Does anyone have suggestions for another way I can accomplish this?  Thanks!!", 
            "subreddit": "aws", 
            "title": "Easiest way to run a scheduled task in EC2", 
            "url": "https://www.reddit.com/r/aws/comments/72flj0/easiest_way_to_run_a_scheduled_task_in_ec2/"
        }, 
        {
            "author": "this_is_my_fake1", 
            "created_utc": 1506367790.0, 
            "domain": "self.aws", 
            "id": "72eu2k", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72eu2k/whizlabs_for_aws_caa/", 
            "score": 6, 
            "selftext": "What is everyone's thoughts on Whizlabs for the AWS Certified Associate Architect test? I took the cloudguru course and been going through Whizlabs. I've been told Whizlabs is basically a braindump mostly with \"real\" questions. I'm scheduled to take my test soon, and I'm nervous as hell.\n\n**EDIT UPDATE**: Well, I passed! BARELY. \n\nWhile Whizlabs wasn't exactly a braindump, they were *very* similar to the questions. Very close, but they were definitely not \"illegal\" at least from mine. If you try to memorize Whizlabs, you'll fail hard. But take all the practice tests numerous times and study the shit out of any concept you get wrong. I kept getting RDS questions wrong in general on practice, then once I studied up on Multi-AZ and Read Replica stuff, I knew it inside and out - definitely helped with a few exam questions to prep there. Not too many though.\n\nA Cloud Guru's \"Final Practice Exam\" was probably the level of difficulty I'd say. It's hard as shit, and very accurate for what my exam score was. I scored 63% and 72% on that one 2 nights ago and last night. I was nervous as hell since usually you should be hitting 90%+ on practice tests in my experience to be confident you'll pass. After reading discussions on ACG, it seemed like their practice tests were especially hard and that most people would barely/not pass them then pass their actual exam \"fine\". I do wish they'd remove their practice questions that have plugs for LOL YOU SHOULD TELL THEM TO STUDY ON CLOUD GURU though. Great course, but little details like that bothered me a bit.\n\nI won't say what my actual score was since it wasn't wonderful, but I did pass. As many have said, make sure you know VPC inside and out. That is what probably nearly cost me the exam. Know the difference between Classic and Application ELB's. I don't think really any practice test I took had much between the 2. I only know those from on-the-job experience. Also know ECS concepts. Classic vs. Application ELB and ECS concepts are probably the things least emphasized on any prep/note site I've come across. Lambda and API Gateway was on it, but those are things everyone warned about so I was a little ready for them. ", 
            "subreddit": "aws", 
            "title": "Whizlabs for AWS CAA?", 
            "url": "https://www.reddit.com/r/aws/comments/72eu2k/whizlabs_for_aws_caa/"
        }, 
        {
            "author": "alexdebrie", 
            "created_utc": 1506358346.0, 
            "domain": "serverless.com", 
            "id": "72dqbr", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72dqbr/how_to_deploy_multiple_serverless_services_to_the/", 
            "score": 5, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "How to deploy multiple Serverless services to the same domain", 
            "url": "https://serverless.com/blog/api-gateway-multiple-services"
        }, 
        {
            "author": "awsgeek", 
            "created_utc": 1506357200.0, 
            "domain": "awsgeek.com", 
            "id": "72dliw", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72dliw/summarynotes_on_the_amazon_machine_learning/", 
            "score": 32, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Summary/notes on the Amazon Machine Learning service, now to find the time to play with it", 
            "url": "http://www.awsgeek.com/posts/amazon-machine-learning-summary/"
        }, 
        {
            "author": "silviadoomra", 
            "created_utc": 1506356690.0, 
            "domain": "aws.amazon.com", 
            "id": "72djgh", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72djgh/get_started_with_amazon_elasticsearch_service/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Get Started with Amazon Elasticsearch Service: Filter Aggregations in Kibana", 
            "url": "https://aws.amazon.com/blogs/database/get-started-with-amazon-elasticsearch-service-filter-aggregations-in-kibana/"
        }, 
        {
            "author": "mkorejo", 
            "created_utc": 1506353062.0, 
            "domain": "self.aws", 
            "id": "72d4mm", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72d4mm/do_lambdas_wvpc_configuration_not_communicate/", 
            "score": 1, 
            "selftext": "I am working on a project where we are deploying Lambdas with VPC configuration (since they must talk to RDS in private subnet). All Lambdas are in same subnet and security group. Based on the documentation, Lambdas in a VPC get an ENI to communicate with other resources in the VPC:\nhttp://docs.aws.amazon.com/lambda/latest/dg/vpc.html\n\nDoes \"other resources in the VPC\" include other Lambdas? We have Lambdas that call another Lambda. Our subnet does not allow direct public access, but rather a proxy must be set using an environment variable. We are finding that the proxy environment variable is required even though all Lambdas should be right next to each other in the VPC.\n\nIs this working as designed? I know VPC Endpoints are not available for Lambda, but the VPC config with ENIs make it seem that local routing should be sufficient. Does Lambda only support public endpoints for invocation?\n\nThanks.", 
            "subreddit": "aws", 
            "title": "Do Lambdas w/VPC configuration not communicate directly with local routing?", 
            "url": "https://www.reddit.com/r/aws/comments/72d4mm/do_lambdas_wvpc_configuration_not_communicate/"
        }, 
        {
            "author": "barnes80", 
            "created_utc": 1506351636.0, 
            "domain": "self.aws", 
            "id": "72cyq0", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 15, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72cyq0/aws_reinvent_replay_question/", 
            "score": 6, 
            "selftext": "I had a quick question for those who have been to AWS re:Invent before and gone to the re:play party. I am planning on traveling to the conference with my wife and I'm considering buying an extra guest pass for the re:play party so that we can both attend it. AWS wants $300 for it which seems steep to me. \n\nFor those who have gone, would you consider $300 for the event to be worth it? Is it open bar, include snacks, etc? Or do you then need to pay for drinks once you get in? \n\nAs an alternative we are considering just getting tickets to another show in the city instead. It is my understanding that there are major DJs playing in Vegas all the time at clubs within the different hotels. A quick look at prices it looks like tickets are < $80. The DJ and dancing is really the aspects we were looking for in the re:play party anyway so it may be a lot cheaper to just go elsewhere. \n\nEssentially, are there factors I am not considering that would make re:play worth the $300 we would need to spend to attend together? \n\nFeel free to plug other recommendations for things we should check out in Vegas during our time away from the conference! This will be my first time in the city. ", 
            "subreddit": "aws", 
            "title": "AWS re:Invent re:Play question", 
            "url": "https://www.reddit.com/r/aws/comments/72cyq0/aws_reinvent_replay_question/"
        }, 
        {
            "author": "KAJed", 
            "created_utc": 1506347373.0, 
            "domain": "self.aws", 
            "id": "72cj3k", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72cj3k/vpn_data_transfer_costs/", 
            "score": 1, 
            "selftext": "I'm looking in to using an AWS VPN as way to reduce data transwer costs between my remote network and Amazon.\n\nI was wondering if you pay for data-out costs from a VPC being used as VPN for same-region S3 transfers?\n\nTLDR: Does aws s3 cp s3://*** cost money when connected from VPN?", 
            "subreddit": "aws", 
            "title": "VPN Data Transfer Costs", 
            "url": "https://www.reddit.com/r/aws/comments/72cj3k/vpn_data_transfer_costs/"
        }, 
        {
            "author": "JonnyBravoII", 
            "created_utc": 1506343058.0, 
            "domain": "self.aws", 
            "id": "72c4zb", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72c4zb/question_on_configuring_workmail/", 
            "score": 1, 
            "selftext": "We have been using WorkMail for quite some time with no known issues.  We just received this message from someone.\n\n*Your email shows up as coming \"via amazonses.com\" and it does not get delivered to my inbox.  This is likely a misconfiguration of DKIM and/or SPF for your domain. *\n\nWhat does this mean and how do we fix it?  ", 
            "subreddit": "aws", 
            "title": "Question on configuring WorkMail", 
            "url": "https://www.reddit.com/r/aws/comments/72c4zb/question_on_configuring_workmail/"
        }, 
        {
            "author": "mdsparrow", 
            "created_utc": 1506336070.0, 
            "domain": "self.aws", 
            "id": "72blnc", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72blnc/aws_certification_exam_rescheduling/", 
            "score": 1, 
            "selftext": "How can I reschedule my AWS certification exam? Is there a cost associated?", 
            "subreddit": "aws", 
            "title": "AWS Certification exam rescheduling", 
            "url": "https://www.reddit.com/r/aws/comments/72blnc/aws_certification_exam_rescheduling/"
        }, 
        {
            "author": "NewToAWS", 
            "created_utc": 1506327407.0, 
            "domain": "self.aws", 
            "id": "72b2q6", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 17, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72b2q6/vpc_with_public_subnet_only/", 
            "score": 1, 
            "selftext": "I'm building a website; and launching it with my own money (so every penny matters).\n\nI was wondering; would it be okay to just use VPC with just the public subnet (along with security groups) so I don't have to pay for the NAT instance/gateway; or would that be a really big technical blunder from security point of view?\n\nPlease help; considering I am completely new to AWS/VPCs etc and also a bit short on money? Thanks a ton!", 
            "subreddit": "aws", 
            "title": "VPC with public subnet only", 
            "url": "https://www.reddit.com/r/aws/comments/72b2q6/vpc_with_public_subnet_only/"
        }, 
        {
            "author": "hnk1", 
            "created_utc": 1506323158.0, 
            "domain": "self.aws", 
            "id": "72atji", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 43, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72atji/new_aws_region/", 
            "score": 44, 
            "selftext": "New AWS region in Bahrain announced (officially).   https://aws.amazon.com/blogs/aws/in-the-works-aws-region-in-the-middle-east/?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+AmazonWebServicesBlog+%28Amazon+Web+Services+Blog%29\n\n/#awsSummitBahrain", 
            "subreddit": "aws", 
            "title": "New AWS region", 
            "url": "https://www.reddit.com/r/aws/comments/72atji/new_aws_region/"
        }, 
        {
            "author": "thatkauko", 
            "created_utc": 1506313030.0, 
            "domain": "self.aws", 
            "id": "72a5e7", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72a5e7/best_way_for_a_company_to_offer_developers_credit/", 
            "score": 1, 
            "selftext": "At my company we'd like to offer developers a way to hone their AWS skills by offering them some free AWS credit each month. It would be great if each developer could get 100$ of credit each month, and not have to worry about AWS bills. Unused credit should not collect over time; a developer should not have 1k$ in credit if he doesn't use AWS for 10 months, and my company should not pay 1k$ for that either.\n\nNow, I talk about *credit*, but it seems like AWS Credit is not really meant for a situation like this. In fact, I don't know if you can even buy AWS Credit?\n\nDoes someone know if consolidated billing would fit our use case? I imagine the way it works is, developers can register for an AWS account using any email (including personal), join our organisation, and then their bills would become a part of the consolidated bill? Is there a way to set a monthly limit on the bill, or include only some parts of the developers bill on the consolidated bill? Finally, if a developer leaves the company, we obviously want them to retain ownership of their stuff on AWS, though I don't see why this would be a problem. :)\n\nHopefully someone can help me out. There's quite a bit of information out there, but I'm really looking for more of an experience report than anything else. If AWS has any other features that could help us out, I'm happy to hear them out!", 
            "subreddit": "aws", 
            "title": "Best way for a company to offer developers credit for hobby projects?", 
            "url": "https://www.reddit.com/r/aws/comments/72a5e7/best_way_for_a_company_to_offer_developers_credit/"
        }, 
        {
            "author": "anonwipq", 
            "created_utc": 1506311617.0, 
            "domain": "hackernoon.com", 
            "id": "72a122", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72a122/mind_the_75gb_limit_on_aws_lambda_deployment/", 
            "score": 24, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Mind the 75GB limit on AWS Lambda deployment packages", 
            "url": "https://hackernoon.com/mind-the-75gb-limit-on-aws-lambda-deployment-packages-163b93c8eb72"
        }, 
        {
            "author": "konstantin_metz", 
            "created_utc": 1506308460.0, 
            "domain": "self.aws", 
            "id": "729rw7", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/729rw7/aws_and_other_cloud_providers/", 
            "score": 0, 
            "selftext": "Why is it that almost every company or service I use is hosted on AWS or uses some type of AWS product (Ex: CDN)? What about other providers like Google or Microsoft cloud? What makes AWS so much better than everyone else? I mean is it purely $? \n", 
            "subreddit": "aws", 
            "title": "AWS and other cloud providers", 
            "url": "https://www.reddit.com/r/aws/comments/729rw7/aws_and_other_cloud_providers/"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1506305215.0, 
            "domain": "self.aws", 
            "id": "729jfq", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/729jfq/spot_request_vs_network_interface/", 
            "score": 1, 
            "selftext": "i had a persistent spot request instance get terminated due to price.  something that i consider odd happened.  it had a network interface attached.  the network interface was re-attached when the instance was resumed, but the volume was not saved.  do i need to mark the volume to not be deleted to save it across bid price outages (at EBS cost for the duration, of course)?  also, the network interface had its IP address changed (on the ENI itself).  is there a way to keep it the same?", 
            "subreddit": "aws", 
            "title": "spot request vs network interface", 
            "url": "https://www.reddit.com/r/aws/comments/729jfq/spot_request_vs_network_interface/"
        }, 
        {
            "author": "1252947840", 
            "created_utc": 1506304864.0, 
            "domain": "self.aws", 
            "id": "729i9t", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/729i9t/best_practices_for_aws_accounts/", 
            "score": 4, 
            "selftext": "I have been searching around for the best implementation and the best practices for using AWS services. It seems like information are scattered around. Here are some that I know, please correct me if I'm wrong and hope everyone can contribute whatever they know:-\n\n\nBest practices:-\n\n* Fill in technical contact once you create account (super important as AWS will contact you for any maintenance or issues)\n\n* Enable Cloudtrail and save it to S3 buckets (at least)\n\n* Enable billing info access for IAM users (useful for segregating billing info access rights to specific user)\n\n* Use EBS encryption all the time (the overhead is way too small to be ignored)\n\n\n** my best practices means those services / settings that should be turn on by default", 
            "subreddit": "aws", 
            "title": "Best practices for AWS accounts", 
            "url": "https://www.reddit.com/r/aws/comments/729i9t/best_practices_for_aws_accounts/"
        }, 
        {
            "author": "SatoriSlu", 
            "created_utc": 1506299585.0, 
            "domain": "self.aws", 
            "id": "72915n", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/72915n/migrating_from_one_vpc_to_another/", 
            "score": 3, 
            "selftext": "Greetings community,\n\n\nI had two questions I was hoping to get some answers or guidance on. Our team is starting to take over the administration of our AWS infrastructure, however, the majority of our team is pretty new to AWS in general. The developers have been administering and building up this infrastructure and now we've been tasked with a pretty major undertaking.\n\n\nThat undertaking, is the migration of the entire contents of one VPC into another VPC. I honestly, don't know where to start. \n\n\nSo, with that said, I was hoping for some assistance.\n\n1) We want an easy way to get an overall picture of what is contained within the VPC we plan to move from. Essentially, we want to know everything that's in that VPC: all the ec2 instances, RDS instances, Security Groups, subnets, etc. Just so we don't miss anything and we know how everything is put together.\n\n\n2) The actual process of migration from one VPC to another. What are the best practices here? From what I can see, there isn't an easy method of transferring over instances, etc from one to another. What's the go to procedure?\n\n\nThank you so much for your time. \u00a0Any resources you can point me to to accomplish either of these tasks would be of great help.", 
            "subreddit": "aws", 
            "title": "Migrating from one VPC to another", 
            "url": "https://www.reddit.com/r/aws/comments/72915n/migrating_from_one_vpc_to_another/"
        }, 
        {
            "author": "AttentiveUnicorn", 
            "created_utc": 1506298096.0, 
            "domain": "self.aws", 
            "id": "728vr4", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/728vr4/s3_bucket_and_ec2_instance_pointing_to_same/", 
            "score": 2, 
            "selftext": "I'm unsure how to set this up in the best way (cost, simplicity and efficiency) and could do with some help.\n\nMy connected parts are: 1. Node.js app 2. CouchDb instance 3. Angular site\n\nCurrent set up is one EC2 instance with CouchDb installed and the node.js app running. Then I have an S3 bucket hosting the Angular site. My CNAME on the custom .com domain points to the S3 bucket and that part is working ok.\n\nI have some confusion around the EC2 portion. Can I have these still linked to my domain but on different ports? I want my website to be on port 80/443, CouchDb to be on 5984 and Node.js app to be on something like 8080. \n\n\n", 
            "subreddit": "aws", 
            "title": "S3 bucket and EC2 instance pointing to same domain name", 
            "url": "https://www.reddit.com/r/aws/comments/728vr4/s3_bucket_and_ec2_instance_pointing_to_same/"
        }, 
        {
            "author": "gergnz", 
            "created_utc": 1506294644.0, 
            "domain": "self.aws", 
            "id": "728k1k", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/728k1k/new_examiner_psi_having_difficulties/", 
            "score": 3, 
            "selftext": "I'm trying to book my PRO SA recertification EXAM and having a lot of difficulty. There are so few slots available in Sydney (and Nth Sydney/Parramatta). I'm finding it difficult to match up my travel with available slots. I don't remember this being an issue previously...\n\nRant on twitter: https://twitter.com/gergnz/status/912072878958321664\n\nThere was also some talk a few days back: https://www.reddit.com/r/aws/comments/70po1o/aws_beta_exam_certified_cloud_practitioner/dn5pv2f/", 
            "subreddit": "aws", 
            "title": "New Examiner (PSI) having difficulties?", 
            "url": "https://www.reddit.com/r/aws/comments/728k1k/new_examiner_psi_having_difficulties/"
        }, 
        {
            "author": "hairy-one", 
            "created_utc": 1506293258.0, 
            "domain": "self.aws", 
            "id": "728feh", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 17, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/728feh/should_i_use_aws_elasticsearch_or_should_i_mount/", 
            "score": 7, 
            "selftext": "That's pretty much it.\nI am mainly concern about paying AWS more than needed by mounting elasticsearch by myself.\n\nSo far i rather mounting it in AWS as it is as simple as clicking the next buttons and just filling the simple configuration onto it, but in the same way feeling stupid on having to pay for it if i could do it on a raw VPS.\n\nI appreciate any comments", 
            "subreddit": "aws", 
            "title": "Should i use AWS elasticsearch or should i mount my own VPS with elasticsearch service?", 
            "url": "https://www.reddit.com/r/aws/comments/728feh/should_i_use_aws_elasticsearch_or_should_i_mount/"
        }, 
        {
            "author": "Marquisk2", 
            "created_utc": 1506268837.0, 
            "domain": "self.aws", 
            "id": "725ugg", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/725ugg/aws_elastic_beanstalk_load_balancer_migration/", 
            "score": 10, 
            "selftext": "If I migrate my single instance to a load balancer will I lose any of my server configuration, files, db or anything at all?", 
            "subreddit": "aws", 
            "title": "AWS Elastic Beanstalk Load balancer Migration", 
            "url": "https://www.reddit.com/r/aws/comments/725ugg/aws_elastic_beanstalk_load_balancer_migration/"
        }, 
        {
            "author": "mstworg", 
            "created_utc": 1506237147.0, 
            "domain": "self.aws", 
            "id": "723qbc", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/723qbc/aws_intra_subnet_security/", 
            "score": 8, 
            "selftext": "I am testing out an architecture consists of two different firewalls and multiple subnets (Web, App) in the same VPC. The first tier firewall is public-facing and will protect the web, and the second tier firewall is for internal only and protect the App. I've setup the App subnet route table to point to the second tier firewall. However when testing traffic from Web to App I observed the traffic is going to App subnet directly without passing through the second tier. So far my way of controlling traffic from Web to App is by stating rules in Network ACL because there exists a default route 10.97.0.0/16 in every route table, which I believe that it is preventing traffic from going thru the second tier except for 0.0.0.0/0 traffic. Is there any way to let the inter-subnet traffic going through the firewall? \n ", 
            "subreddit": "aws", 
            "title": "aws intra subnet security", 
            "url": "https://www.reddit.com/r/aws/comments/723qbc/aws_intra_subnet_security/"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1506233473.0, 
            "domain": "self.aws", 
            "id": "723iw4", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/723iw4/how_to_access_chinese_regions/", 
            "score": 13, 
            "selftext": "AWS has a region running in PRC and another one announced.  what i do know is these are isolated in a certain business sense.  i don't the details of why, but i can guess there are perceived risks like security and rules of operating a business in China.\n\ni am wondering how i might be able to get access on my USA based CC or other means, and if usage requires the Chinese language (i can read a few languages but Asian languages are not among them) such as on business access and/or signup pages.  and would Chinese be needed for very basic levels of support?\n\ni am working on a project of a self-configuring VPN AMI i want to market.  once there is a 2nd region there, then there may well be customers there that might want to use it.  i would need access there to build the AMI and manage the databasw it uses.\n\nthere might be new rules i need to follow to be in compliance with Chinese laws.  for example, they will not want me, nor my VPN product to enable bypassing their wall.  i don't know what they have required of AWS to meet things like that.  i would also need to hire people to do web site translations and support in major Chinese languages.", 
            "subreddit": "aws", 
            "title": "How to access Chinese region(s)?", 
            "url": "https://www.reddit.com/r/aws/comments/723iw4/how_to_access_chinese_regions/"
        }, 
        {
            "author": "shajay123", 
            "created_utc": 1506222173.0, 
            "domain": "self.aws", 
            "id": "722r6o", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/722r6o/aws_create_aws_json_template_to_create_auto/", 
            "score": 1, 
            "selftext": "Hi Everyone, i am trying to create json template to create autoscaling group, so that i can spin up 2 instances out of it. \n\nI have created the autoscale group, but i do not know how to write the template for creating 2 EC2 instances from the autoscaling group. \n\nplease help me create the json template for the autoscale group and the 2 ec2 instances.\n\nThank you in Advance. ", 
            "subreddit": "aws", 
            "title": "AWS: create aws json template to create auto scaling group to create 2 EC2 instances", 
            "url": "https://www.reddit.com/r/aws/comments/722r6o/aws_create_aws_json_template_to_create_auto/"
        }, 
        {
            "author": "_Gl0rph_", 
            "created_utc": 1506187660.0, 
            "domain": "self.aws", 
            "id": "71zm4b", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71zm4b/aws_s3_static_website_sometimes_produces_dns/", 
            "score": 13, 
            "selftext": "My domain is registered through google domains, on which end i've configured to use Route53 NS servers. I'm using a cloudfront distribution with an ACM certificate for SSL, and i've made configured alias records for mydomain.com and www.mydomain.com to point towards the cloudfront distribution.\n\nAs far as I can tell, I've done everything correctly. Sometime I can access the website just fine (with https working) but other times the DNS won't resolve. Did I miss something obvious?", 
            "subreddit": "aws", 
            "title": "AWS S3 Static website sometimes produces \"DNS_PROBE_FINISHED_NXDOMAIN\" when accessed.", 
            "url": "https://www.reddit.com/r/aws/comments/71zm4b/aws_s3_static_website_sometimes_produces_dns/"
        }, 
        {
            "author": "zergUser1", 
            "created_utc": 1506183670.0, 
            "domain": "self.aws", 
            "id": "71z7lw", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71z7lw/api_gateway_is_there_anyway_to_map_method_body/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "API Gateway, is there anyway to map method body params to the integration query params?", 
            "url": "https://www.reddit.com/r/aws/comments/71z7lw/api_gateway_is_there_anyway_to_map_method_body/"
        }, 
        {
            "author": "ThingsAndStuff5", 
            "created_utc": 1506181617.0, 
            "domain": "self.aws", 
            "id": "71z047", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 28, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71z047/how_does_codecommit_compare_to_git_enterprise/", 
            "score": 26, 
            "selftext": "Currently we manage a self-hosted Github Enterprise install. We store .net/C# projects, javascript, powershell, json, and yaml. We use Bamboo, Puppet, and Ansible. \n\nLooking for alternatives. ", 
            "subreddit": "aws", 
            "title": "How does CodeCommit compare to Git Enterprise?", 
            "url": "https://www.reddit.com/r/aws/comments/71z047/how_does_codecommit_compare_to_git_enterprise/"
        }, 
        {
            "author": "learnjava", 
            "created_utc": 1506159229.0, 
            "domain": "self.aws", 
            "id": "71xd2y", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71xd2y/three_quick_questions_regarding_multiple_accounts/", 
            "score": 4, 
            "selftext": "three quick questions, maybe you can help me:\n\n* can I have multiple accounts in my name/for my address without any problems?\n* are prepaid credit cards allowed for AWS?\n* If not, how many accounts can I safely create with the same normal credit card?\n\nAll accounts would be private (no company) accounts and I would like to do it this way because I want to keep different things separated.\n\nThanks guys and girls, you are helping me a lot", 
            "subreddit": "aws", 
            "title": "three quick questions regarding multiple accounts", 
            "url": "https://www.reddit.com/r/aws/comments/71xd2y/three_quick_questions_regarding_multiple_accounts/"
        }, 
        {
            "author": "johnathanjones1998", 
            "created_utc": 1506144171.0, 
            "domain": "stackoverflow.com", 
            "id": "71whzr", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71whzr/please_help_ive_been_stuck_for_3_hours_on_this/", 
            "score": 6, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Please help: I've been stuck for 3 hours on this issue with AJAX, Cors, and S3 :/", 
            "url": "https://stackoverflow.com/questions/46376319/s3-ajax-cors-error"
        }, 
        {
            "author": "funkdr42", 
            "created_utc": 1506125722.0, 
            "domain": "self.aws", 
            "id": "71v2g6", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71v2g6/lambda_ecs_and_more_are_hipaa_eligible/", 
            "score": 19, 
            "selftext": "There are more HIPAA eligible services, including Lambda, Lambda@Edge, and EC2 Container Service (ECS): https://aws.amazon.com/compliance/services-in-scope/", 
            "subreddit": "aws", 
            "title": "Lambda, ECS and more are HIPAA eligible!", 
            "url": "https://www.reddit.com/r/aws/comments/71v2g6/lambda_ecs_and_more_are_hipaa_eligible/"
        }, 
        {
            "author": "mwarkentin", 
            "created_utc": 1506124167.0, 
            "domain": "aws.amazon.com", 
            "id": "71uxk1", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71uxk1/amazon_ecs_adds_support_for_adding_or_dropping/", 
            "score": 41, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Amazon ECS Adds Support for Adding or Dropping Linux Capabilities to Containers", 
            "url": "https://aws.amazon.com/about-aws/whats-new/2017/09/amazon-ecs-adds-support-for-adding-or-dropping-linux-capabilities-to-containers/"
        }, 
        {
            "author": "awsWordPressQuestion", 
            "created_utc": 1506115563.0, 
            "domain": "self.aws", 
            "id": "71u3zr", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71u3zr/moving_word_press_site_domain_to_aws_ec2/", 
            "score": 1, 
            "selftext": "I created a wordpress site with the premium membership and have a domain name for the site. After doing that I decided that I wanted to host it through amazon and set up an ec2 instance. I am not sure how word press was hosting it before so if anyone can fill me in on that as well that would be much appreciated. Anyways, I want to keep the page look the same and still have all the priveleges as I do on the site currently.\n\nI created the EC2 instance using bitmani (I am not sure if this is the way to do it) and set up an elastic IP. I can login to the wordpress site created by bitmani, but after that I am not sure how to set my current page to the elastic ip. Thanks for any help and sorry for a stupid question.", 
            "subreddit": "aws", 
            "title": "Moving Word Press site / domain to AWS EC2", 
            "url": "https://www.reddit.com/r/aws/comments/71u3zr/moving_word_press_site_domain_to_aws_ec2/"
        }, 
        {
            "author": "LE_POOR_MERIT", 
            "created_utc": 1506111989.0, 
            "domain": "self.aws", 
            "id": "71tqe9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71tqe9/i_just_want_to_use_lex_to_answer_questions_does/", 
            "score": 1, 
            "selftext": "Understanding that Lex is much more powerful, I just want to use it for an FAQ bot.  A question will be asked, and then answered.  I don't need a chain of events based on responses.  Is there an example out there of this simple usage?  I'm actually surprised that there is no blueprint for this.\n\nJust FYI, I was checking out Microsoft QnA, which does exactly what I'm looking for... but I was hoping to use this project as a first step into Lex.", 
            "subreddit": "aws", 
            "title": "I just want to use Lex to answer questions. Does anyone have a good example of this?", 
            "url": "https://www.reddit.com/r/aws/comments/71tqe9/i_just_want_to_use_lex_to_answer_questions_does/"
        }, 
        {
            "author": "craig081785", 
            "created_utc": 1506107635.0, 
            "domain": "citusdata.com", 
            "id": "71t9gw", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71t9gw/podyn_dynamodb_to_postgresql_replication_and/", 
            "score": 2, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Podyn: DynamoDB to PostgreSQL replication and migration tool", 
            "url": "https://www.citusdata.com/blog/2017/09/22/dynamodb-to-postgres-replication/"
        }, 
        {
            "author": "hitarth1605", 
            "created_utc": 1506104632.0, 
            "domain": "self.aws", 
            "id": "71sx5i", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71sx5i/how_to_access_s3_from_different_account_via_ec2/", 
            "score": 1, 
            "selftext": "Hello I am having 2 account a,b\nI have created s3 in account a\nAnd \nCreated ec2 in account b now I want to access that s3 by creating instance profile and adding role to it", 
            "subreddit": "aws", 
            "title": "how to access s3 from different account via ec2 instance profile", 
            "url": "https://www.reddit.com/r/aws/comments/71sx5i/how_to_access_s3_from_different_account_via_ec2/"
        }, 
        {
            "author": "back_to_the_homeland", 
            "created_utc": 1506100687.0, 
            "domain": "self.aws", 
            "id": "71sglk", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71sglk/i3_vs_r_ec2_instances_for_tableau/", 
            "score": 2, 
            "selftext": "Looking into upgrading our servers and I'm wondering if anyone has compared the i3.8 nvme volume performance vs something like an r4.8 instance with ebs attached. Storage has been a bit of an issue too because of some heavy dashboards but also interested in performance. \n\nSo, any stories/advice/data would be appreciated\n\nThanks!", 
            "subreddit": "aws", 
            "title": "i3 vs R EC2 Instances for Tableau?", 
            "url": "https://www.reddit.com/r/aws/comments/71sglk/i3_vs_r_ec2_instances_for_tableau/"
        }, 
        {
            "author": "snapperplug", 
            "created_utc": 1506097391.0, 
            "domain": "aws.amazon.com", 
            "id": "71s34z", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71s34z/nat_gateways_now_support_cloudwatch_metrics_and/", 
            "score": 13, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "NAT Gateways now support CloudWatch metrics and Resource Tagging", 
            "url": "https://aws.amazon.com/about-aws/whats-new/2017/09/amazon-vpc-nat-gateways-now-support-amazon-cloudwatch-monitoring-and-resource-tagging/"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1506095999.0, 
            "domain": "self.aws", 
            "id": "71rxd8", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71rxd8/selling_amazon_connect_with_custom_lex_chatbots/", 
            "score": 1, 
            "selftext": "I'm wondering if I'm able to offer a value added Amazon Connect service to my customers.  Is this possible?", 
            "subreddit": "aws", 
            "title": "Selling Amazon Connect with custom Lex chatbots?", 
            "url": "https://www.reddit.com/r/aws/comments/71rxd8/selling_amazon_connect_with_custom_lex_chatbots/"
        }, 
        {
            "author": "jackinthebox52", 
            "created_utc": 1506092130.0, 
            "domain": "self.aws", 
            "id": "71ri5q", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71ri5q/need_help_changing_ssh_port/", 
            "score": 0, 
            "selftext": "I'm currently at school and almost have my Ubuntu ec2 server set up but I need to ssh into it and I can't do it on the school wifi. I'm using terminal for ssh on my mac and I cannot use the in-browser ssh tool. They block all proxys that I've tried and I'm assuming they're just blocking port 22 so ssh times out. I looked it up but all I can find is how to change the port.. through an ssh session. Seeing as how I cannot connect through a command line, is there any way to modify the port it uses through the AWS dashboard? Thanks in advance \n\nUpdate: worked with a vpn ig they allow some vpns? lmao", 
            "subreddit": "aws", 
            "title": "Need help changing ssh port", 
            "url": "https://www.reddit.com/r/aws/comments/71ri5q/need_help_changing_ssh_port/"
        }, 
        {
            "author": "singham", 
            "created_utc": 1506088751.0, 
            "domain": "self.aws", 
            "id": "71r5cq", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71r5cq/is_the_following_setup_possible_with_aws_iam/", 
            "score": 1, 
            "selftext": "Basically, we need to have a setup where we can start EMR jobs but don't have access to S3 buckets which the EMR job will process.\n\nWe are developing algorithms for our client. The client have their own AWS environment where they store data, etc. We need to deploy algorithms in their environment which will process their data but we ourselves will not have access to their data only the EMR job will have it. \n\nIs it possible to set up roles / access keys in such a way that we are able to start EMR jobs in their environment. The access keys used would only have permission to start a job. But the EMR cluster itself will have different access keys which will have permission to access their S3 data and process it. ", 
            "subreddit": "aws", 
            "title": "Is the following setup possible with AWS IAM roles and policies?", 
            "url": "https://www.reddit.com/r/aws/comments/71r5cq/is_the_following_setup_possible_with_aws_iam/"
        }, 
        {
            "author": "ffxsam", 
            "created_utc": 1506088570.0, 
            "domain": "self.aws", 
            "id": "71r4pu", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 43, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71r4pu/what_diagramming_software_do_you_use_for/", 
            "score": 43, 
            "selftext": "I'm aware of LucidCharts and CloudCraft. I'm open to offline software too. I'd just like something that has the AWS icons built-in (or downloadable/usable). Thanks!", 
            "subreddit": "aws", 
            "title": "What diagramming software do you use for designing AWS-based solutions?", 
            "url": "https://www.reddit.com/r/aws/comments/71r4pu/what_diagramming_software_do_you_use_for/"
        }, 
        {
            "author": "simbit", 
            "created_utc": 1506063886.0, 
            "domain": "medium.com", 
            "id": "71pdfd", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71pdfd/simplified_user_management_for_aws/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Simplified User Management for AWS", 
            "url": "https://medium.com/@awlessCLI/simplified-user-management-for-aws-6f828ccab387"
        }, 
        {
            "author": "AdamMilenko", 
            "created_utc": 1506060512.0, 
            "domain": "mherman.org", 
            "id": "71p5ey", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71p5ey/tutorial_on_how_to_spin_up_ondemand_test/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Tutorial on how to spin up On-demand Test Environments with Amazon EC2 Container Service (ECS), Docker and Circle CI", 
            "url": "http://mherman.org/blog/2017/09/18/on-demand-test-environments-with-docker-and-aws-ecs/"
        }, 
        {
            "author": "ffxsam", 
            "created_utc": 1506057950.0, 
            "domain": "self.aws", 
            "id": "71oz6c", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71oz6c/kinesis_streams_charged_for_even_if_idle/", 
            "score": 5, 
            "selftext": "Two part question:\n\n1. If I have a Kinesis stream that just sits there all month, am I charged for it? ($0.015/shard/hr?)\n2. In practice, is one supposed to programmatically create streams as needed, and delete them as soon they're done? Or leave them up 24/7? (or probably depends on the application)", 
            "subreddit": "aws", 
            "title": "Kinesis Streams - charged for even if idle?", 
            "url": "https://www.reddit.com/r/aws/comments/71oz6c/kinesis_streams_charged_for_even_if_idle/"
        }, 
        {
            "author": "TheLegendOfCode", 
            "created_utc": 1506055015.0, 
            "domain": "self.aws", 
            "id": "71ord7", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71ord7/hosting_website_on_aws_lambda_and_api_gateway/", 
            "score": 9, 
            "selftext": "I was wondering if it would be possible somehow to use API gateway and AWS Lambda to host a website. I've seen thing about hosting web apps with Lambda, so I know it would be possible.  However, I can't find a good resource to do so.  Does anyone know about any good resources for that?  ", 
            "subreddit": "aws", 
            "title": "Hosting website on AWS Lambda and API Gateway?", 
            "url": "https://www.reddit.com/r/aws/comments/71ord7/hosting_website_on_aws_lambda_and_api_gateway/"
        }, 
        {
            "author": "kyle263611", 
            "created_utc": 1506054263.0, 
            "domain": "self.aws", 
            "id": "71op7d", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71op7d/any_help_with_importing_a_vm_into_aws/", 
            "score": 1, 
            "selftext": "Good Evening,\n\nI am attempting to upload a VM that was created on premise.\n\nIt is a Wireless controller that runs on top of Linux.  As I have to load it with a custom ISO, I can't use a basic Amazon EC2 instance.\n\nI have done the basic way using the new AWS CLI tools, but get the following:\n\"Unsupported configuration: Multiple etc directories found\"\n\nAs I don't have direct shell access to the VM, I have to assume that it has multiple etc directories, so it won't work.\n\nI then came across documentation from the manufacturer of the wireless controller that says it is 'supported' on AWS, and gave documentation.  First I had to go find version 1.7.5.1 of the ec2 tools and use old commands.  I also downgraded by version of java, but I still get the following issue:\n\nERROR: Unable to create signed manifest URL. Cannot access/create bucket: XXXXXXXXXXXXX : com.amazonaws.services.s3.model.AmazonS3Exception: Bad Request (Service: Amazon S3; Status Code: 400; Error Code: 400 Bad Request; Request ID: 8084CA843509XXXXX), S3 Extended Request ID: FJGpiP52Dnvw0GW9XXXXXXCNT94RlUcMZcwODqFroVac7LaTOtxmRAB75/nUXQIw45CE8laE=\n\n\nI have verified.. and verified, my access key and security key, but still don't understand why I can't get this vm loaded.  Please help with anything I may be missing.", 
            "subreddit": "aws", 
            "title": "Any help with importing a VM into AWS??", 
            "url": "https://www.reddit.com/r/aws/comments/71op7d/any_help_with_importing_a_vm_into_aws/"
        }, 
        {
            "author": "AtomicGrass", 
            "created_utc": 1506053659.0, 
            "domain": "self.aws", 
            "id": "71onig", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71onig/what_is_the_fastest_way_to_know_what_permissions/", 
            "score": 7, 
            "selftext": "You're creating a CloudFormation stack template, and you need to specify an IAM Role to do *X*. How do you know exactly what permissions the action will need?\n\nFor example, if trying to run **aws cloudformation deploy** in a CodeBuild job, how would you know which permissions to include in the policy document or the Role definition?", 
            "subreddit": "aws", 
            "title": "What is the fastest way to know what permissions an AWS CLI command will need?", 
            "url": "https://www.reddit.com/r/aws/comments/71onig/what_is_the_fastest_way_to_know_what_permissions/"
        }, 
        {
            "author": "mrhaleon", 
            "created_utc": 1506041511.0, 
            "domain": "self.aws", 
            "id": "71nl8p", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 43, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71nl8p/thoughts_on_transit_vpcs/", 
            "score": 18, 
            "selftext": "Back six months or so ago, transit VPCs were all the rage in some spaces, purporting to be a scalable way to easily manage inter-VPC (and inter-account) traffic, especially between regions. \n\nFast forward to today, and I'm hearing rumblings that AWS engineers and others are souring on the solution, due to inflexibility and, essentially, the ease with which some AWS customers have managed to break the solution. \n\nI was curious what users in this community thought about them. Are you using a transit VPC? Have you used one and abandoned it?", 
            "subreddit": "aws", 
            "title": "Thoughts on transit VPCs", 
            "url": "https://www.reddit.com/r/aws/comments/71nl8p/thoughts_on_transit_vpcs/"
        }, 
        {
            "author": "guppyF1", 
            "created_utc": 1506037592.0, 
            "domain": "medium.com", 
            "id": "71n7rh", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71n7rh/dynamodb_autoscaling_with_a_large_number_of/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "DynamoDB autoscaling with a large number of tables (with Slack notifications)", 
            "url": "https://medium.com/signiant-engineering/set-it-and-forget-it-a66914eacc02"
        }, 
        {
            "author": "phantom4466", 
            "created_utc": 1506032913.0, 
            "domain": "self.aws", 
            "id": "71mrgi", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "support", 
            "link_flair_text": "support query", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71mrgi/aws_company_or_personal_account/", 
            "score": 0, 
            "selftext": "I would like to setup an AWS account for some IT work. This is being done as an individual \"sole proprietorship\" though I plan on registering a business name to it in my county (assumed name).\n\nWhen signing up, I can choose a company or personal account. Which should I choose? It sounds like they're identical. I guess... is it okay to put a company name is not official yet... or alternately is it okay to use a personal account for for-profit business purposes.\n\nAnd I guess, either way can I convert later?\n\nThanks!", 
            "subreddit": "aws", 
            "title": "AWS Company or Personal Account", 
            "url": "https://www.reddit.com/r/aws/comments/71mrgi/aws_company_or_personal_account/"
        }, 
        {
            "author": "Ghanada", 
            "created_utc": 1506030652.0, 
            "domain": "aws.amazon.com", 
            "id": "71mj00", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71mj00/reset_your_aws_root_accounts_lost_mfa_device/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Reset Your AWS Root Account's Lost MFA Device Faster by Using the AWS Management Console | Amazon Web Services", 
            "url": "https://aws.amazon.com/blogs/security/reset-your-aws-root-accounts-lost-mfa-device-faster-by-using-the-aws-management-console/"
        }, 
        {
            "author": "Blahblahcomputer", 
            "created_utc": 1506025985.0, 
            "domain": "self.aws", 
            "id": "71m0js", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 18, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71m0js/is_it_just_me_or_does_aws_quicksight_kind_of_suck/", 
            "score": 29, 
            "selftext": "I have been trying to do serverless analytics with quicksight. Specifically, I've been trying to analyze AWS detailed billing report data. \n\nI can't specify a single hour in a filter, the filter list doesn't show 95% of the valid fields (have to type in manually, meaning you have to know the field you are looking for without seeing a list), and the default analysis suggestions are just silly.\n\nThe filter list issue is really a biggy. In fact both my main issues come down to weak filtering options. I have used powerpivot for analysis of AWS billing data for years and quicksight doesn't seem to have even a quarter of the capabilities I get with powerpivot.\n\nAnyone else had better experiences? Obviously serverless analysis with Athena and Quicksight would be awesome. I've used MS Power BI in the cloud a bit and it seems way better.\n\nThoughts? Thanks!", 
            "subreddit": "aws", 
            "title": "Is it just me, or does AWS Quicksight kind of suck?", 
            "url": "https://www.reddit.com/r/aws/comments/71m0js/is_it_just_me_or_does_aws_quicksight_kind_of_suck/"
        }, 
        {
            "author": "phpchap1981", 
            "created_utc": 1506025633.0, 
            "domain": "self.aws", 
            "id": "71lz5v", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71lz5v/applications_routing_based_on_url/", 
            "score": 3, 
            "selftext": "hi there, \n\nneed a bit of architecture advice. \n\nwhat i want to do is route traffic based the URL, for example: \n\n\"https://www.bar.com/\" goes to app 1 (PHP) on EC2 server 1 \n\"https://www.bar.com/a\" goes to app 2 (nodejs) EC2 server 2 \n\"https://www.bar.com/b\" goes to app 3 (python) EC2 server 3\n\nSo essentially the routing to application will be based on the URL segments. \n\nI'll be diving into cloudfront, ELB, route 53 and nginx to see if any of these can solve the problem, \n\nwould be interested in hearing if anyone else has come across a similar problem and how they solved it. ", 
            "subreddit": "aws", 
            "title": "Applications routing based on URL", 
            "url": "https://www.reddit.com/r/aws/comments/71lz5v/applications_routing_based_on_url/"
        }, 
        {
            "author": "oznt", 
            "created_utc": 1506025250.0, 
            "domain": "pypi.python.org", 
            "id": "71lxm4", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71lxm4/wolkenbrot_a_light_weight_to_create_and_manage/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "wolkenbrot A light weight to create and manage your EC2 images.", 
            "url": "https://pypi.python.org/pypi/wolkenbrot"
        }, 
        {
            "author": "_dwig_", 
            "created_utc": 1506020567.0, 
            "domain": "self.aws", 
            "id": "71le9x", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71le9x/deploying_to_ecs_in_a_microservice_architecture/", 
            "score": 6, 
            "selftext": "I have a single master repo containing a couple microservices (micro-1, micro-2).  I am currently setting up an environment in AWS to utilize ECS to distribute these microservices across a cluster.\n\nTo perform an application update, I will be using Travis + the [ecs-deploy](https://github.com/silinternational/ecs-deploy) script to initiate a blue/green deployment.\n\nMy question: If I just need to update micro-1, how do I detect and build a new image for **only** this service, rather than building and updating all services?", 
            "subreddit": "aws", 
            "title": "Deploying to ECS in a microservice architecture", 
            "url": "https://www.reddit.com/r/aws/comments/71le9x/deploying_to_ecs_in_a_microservice_architecture/"
        }, 
        {
            "author": "NotSure2505", 
            "created_utc": 1506020507.0, 
            "domain": "linkedin.com", 
            "id": "71le0e", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71le0e/the_aws_shared_responsibility_model_explained_in/", 
            "score": 45, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "The AWS Shared Responsibility Model explained in song", 
            "url": "https://www.linkedin.com/feed/update/urn:li:activity:6316321786921390080"
        }, 
        {
            "author": "pookietastic", 
            "created_utc": 1506019089.0, 
            "domain": "self.aws", 
            "id": "71l827", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71l827/need_some_help_rearchitecting/", 
            "score": 8, 
            "selftext": "I have some Lambda functions timing out. I could increase the timeouts, but this issue has me thinking that I might be using Lambdas all wrong to begin with. So I need some guidance. I\u2019m relatively new to AWS, but here\u2019s what I\u2019ve got going on:\n\n1. An iOS app calls Lambda function \u2018A\u2019 directly, using the AWS iOS SDK (no API Gateway here).\n2. Lambda function \u2018A\u2019 hits our MySQL database and does an insert. Function \u2018A\u2019 then calls Lambda function \u2018B\u2019.\n3. Lambda function \u2018B\u2019 hits two different third-party API\u2019s and inserts each resulting transaction into our database. It then calls Lambda function \u2018C\u2019.\n4. Lambda function \u2018C\u2019 connects to an email service, sends an email, and returns.\n5. Lambdas \u2018B\u2019 and \u2018A\u2019 return, and the iOS app continues on.\n\nThe entire backend is serverless at the moment, and I\u2019d like to keep it that way if possible. All the Lambda code is in Python, fwiw.\n\nI\u2019m wondering if I should be architecting this differently. It\u2019s critical that the third-party API bits in step 3 both succeed, but it\u2019s NOT really important that they succeed right away or even in order. I\u2019m really not sure which route to take in AWS land. I have a feeling I need to investigate SQS next. The first answer [here](https://www.quora.com/Where-should-I-use-the-Amazon-SQS-service) sounds like a similar use case.", 
            "subreddit": "aws", 
            "title": "Need some help re-architecting", 
            "url": "https://www.reddit.com/r/aws/comments/71l827/need_some_help_rearchitecting/"
        }, 
        {
            "author": "ascalabro", 
            "created_utc": 1506014345.0, 
            "domain": "self.aws", 
            "id": "71knmp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71knmp/assigning_multiple_elastic_ip_addresses_to_one_elb/", 
            "score": 2, 
            "selftext": "We have an ELB attached to an ASG. In the ASG, there are EC2 instance(s). The ASG automatically deploys new instances as needed, depending on the load. The web server(s) hosts multiple websites, and these are served by Apache. \n\nThe issue we have ran into is that we need each website to have it's own unique WAN IP address (for SEO reasons). Is it possible to have multiple Elastic IP addresses point to this one ELB? How is it done?  I've only seen Elastic IP being attached to EC2 instances, not ELB instances", 
            "subreddit": "aws", 
            "title": "assigning multiple Elastic IP addresses to one ELB", 
            "url": "https://www.reddit.com/r/aws/comments/71knmp/assigning_multiple_elastic_ip_addresses_to_one_elb/"
        }, 
        {
            "author": "silviadoomra", 
            "created_utc": 1506012874.0, 
            "domain": "aws.amazon.com", 
            "id": "71khdx", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71khdx/using_aws_database_migration_service_and_amazon/", 
            "score": 10, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Using AWS Database Migration Service and Amazon Athena to Replicate and Run Ad Hoc Queries on a SQL Server Database", 
            "url": "https://aws.amazon.com/blogs/database/using-aws-database-migration-service-and-amazon-athena-to-replicate-and-run-ad-hoc-queries-on-a-sql-server-database/"
        }, 
        {
            "author": "oldoverholt", 
            "created_utc": 1506011765.0, 
            "domain": "self.aws", 
            "id": "71kcrz", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71kcrz/virtual_private_gateway_route_selection_w/", 
            "score": 6, 
            "selftext": "So I have two VPN connections configured, both static routing. VPN 1 has a static route to 10.0.0.0/16, VPN 2 has a static route to 10.0.1.0/24 (so they overlap). Routing table entries for my subnets have routes to both subnets, both pointing to my Virtual Private Gateway. When traffic to 10.0.1.0/24 hits the VPG, will it select the tunnel for VPN 2 because it's more specific?", 
            "subreddit": "aws", 
            "title": "Virtual Private Gateway route selection w/ multiple VPNs", 
            "url": "https://www.reddit.com/r/aws/comments/71kcrz/virtual_private_gateway_route_selection_w/"
        }, 
        {
            "author": "briziomusic", 
            "created_utc": 1506008811.0, 
            "domain": "self.aws", 
            "id": "71k09k", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71k09k/how_to_spin_a_task_based_on_sqs_queue/", 
            "score": 11, 
            "selftext": "Hi guys. I have an ecs service that publish messages to an sns topic with a sqs queue subscribed. \n \nAnother ecs service is responsible for processing that messages. In general this last ecs service does not has any running task. \n\nI want to spin one or more tasks as soon as possibile when some messages will be pushed in the queue\n\nI have created a cloudwatch alarm that autoscale the service with one minute of period but is not so fast\n\nI know I can subscribe a lambda to the sns topic that autoscale the ecs service but I want to know if there are other solutions. Is this the right approach?\n\nCan I use cloudwatch events for that? \n\nThanks", 
            "subreddit": "aws", 
            "title": "How to spin a task based on sqs queue", 
            "url": "https://www.reddit.com/r/aws/comments/71k09k/how_to_spin_a_task_based_on_sqs_queue/"
        }, 
        {
            "author": "Yiyio", 
            "created_utc": 1506007797.0, 
            "domain": "self.aws", 
            "id": "71jw63", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71jw63/networking_fundamentals/", 
            "score": 4, 
            "selftext": "Hi,\n\nRecently we have started to move our databases and some servers to AWS, and I am a bit lost with the whole networking thing (VPN, NAT, subnets, etc) I basically have no background, I have been working as a Data Engineer but usually a sys admin/devlops was always setting up things for me).\n\nI was wondering if anyone has a good resource or some links that will help me understand properly things like VPCs, or when to use private/public subnets, for example. ", 
            "subreddit": "aws", 
            "title": "Networking fundamentals?", 
            "url": "https://www.reddit.com/r/aws/comments/71jw63/networking_fundamentals/"
        }, 
        {
            "author": "ChatLag", 
            "created_utc": 1506007310.0, 
            "domain": "self.aws", 
            "id": "71ju6d", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71ju6d/cognito_we_want_the_sign_up_fields_to_be_only/", 
            "score": 4, 
            "selftext": "Here is my forum post: https://forums.aws.amazon.com/thread.jspa?messageID=805856&#805856\n\nBasically I'm using a user pool made through mobile hub through my app, but I only want users to give us their phone number and password to sign up for an account, but I can't seem to edit the UI on the front end when using the android SDK stuff.\n\nWould appreciate any insight/help", 
            "subreddit": "aws", 
            "title": "Cognito - We want the sign up fields to be only phone number and password", 
            "url": "https://www.reddit.com/r/aws/comments/71ju6d/cognito_we_want_the_sign_up_fields_to_be_only/"
        }, 
        {
            "author": "just_looking_around", 
            "created_utc": 1506006108.0, 
            "domain": "self.aws", 
            "id": "71jp50", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71jp50/powershell_script_fails/", 
            "score": 5, 
            "selftext": "I have a powershell script I've been writing to automate the creation of an EC2 instance. When I copy and paste each command into my powershell window it works fine. When I run my ps1 script, it fails. Specifically what fails is the userdata isn't received by the VM. There are no errors spit out, and all variables check out through the script. I just can't figure out why the individual commands in a script work fine, but running a ps1 file fails.", 
            "subreddit": "aws", 
            "title": "PowerShell script fails", 
            "url": "https://www.reddit.com/r/aws/comments/71jp50/powershell_script_fails/"
        }, 
        {
            "author": "Naweze", 
            "created_utc": 1506005775.0, 
            "domain": "self.aws", 
            "id": "71jnqs", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 20, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71jnqs/how_much_money_can_be_saved_with_awss_persecond/", 
            "score": 22, 
            "selftext": "Looking forward to your actual savings in your organizations with calculations.", 
            "subreddit": "aws", 
            "title": "How much money can be saved with AWS's per-second billing for EC2 instances?", 
            "url": "https://www.reddit.com/r/aws/comments/71jnqs/how_much_money_can_be_saved_with_awss_persecond/"
        }, 
        {
            "author": "dghah", 
            "created_utc": 1506005549.0, 
            "domain": "self.aws", 
            "id": "71jmuh", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 33, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71jmuh/tips_for_moving_25tb_out_of_s3_and_into_efsebs/", 
            "score": 26, 
            "selftext": "Hi folks,\n\nAn AWS snowball is going to dump a bunch of compressed data needed for some enterprise migration tasks into an S3 bucket shortly ... \n\nThe people who need this data need it on a POSIX filesystem and they can't really give me good details on how much space the'll need when it's uncompressed so I'm leaning towards extracting it into an AWS EFS share for simplicity. \n\nI've done a lot of high-scale/high-velocity data movement work before but never with this use case -- out of S3 and into EFS ... looking for performance optimization tips from people who've done this before.\n\nSome basic questions ...\n\n- Is EFS likely to be the bottleneck? Should I not even bother to try to launch one of the larger instance types for the data copy that support 25gbps ENA nics? Am I better off just using one step down and one of the instances that just has Enhanced Networking and standard 10gbps bandwidth? \n\n- Any preferred tools for capable, threaded, multipart-supporting S3 transfer clients that work well on big Linux boxes. The last time I was in this position we had to write custom java clients to handle some KMS-crypto edge cases.  I don't have a KMS issue this time around so I'm interested in the current state of the art when it comes to large scale S3 transfer tools that run on linux\n\nAny other tips or war stories about multi-terabyte extraction from S3 into a VPC (EBS on EC2 ) or just AWS EFS would be appreciated. \n\nThanks!\n\n", 
            "subreddit": "aws", 
            "title": "Tips for moving ~25TB out of S3 and into EFS/EBS ?", 
            "url": "https://www.reddit.com/r/aws/comments/71jmuh/tips_for_moving_25tb_out_of_s3_and_into_efsebs/"
        }, 
        {
            "author": "AusIV", 
            "created_utc": 1506002346.0, 
            "domain": "self.aws", 
            "id": "71jakj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71jakj/autoscaling_groups_dead_mans_switch/", 
            "score": 16, 
            "selftext": "Autoscaling groups have three kinda of health checks; EC2 level checks, which Amazon manages to determine general instance health; ebs health checks, where the load balancer evaluates the availability of the service it is load balancing; and custom health checks, where instances report their own health.\n\nI have a scenario where instances that handle a backend task (taking messages from queues, not fronted by a load balancer) may become unhealthy. When this happens, the EC2 health checks are fine, and the scripts I would use to self-report may be unable to run.\n\nWhat I'd like is to have my instances check in periodically, and if they miss a couple of check ins they should be marked as unhealthy. From what I can tell, this isn't a readily available feature.\n\nI was thinking about setting up a script where the instances would send a timestamp to a dynamodb table once a minute. A lambda function would run periodically, and any instances that hadn't reported in within a given period would be marked as unhealthy.\n\nIt seems easy enough to do, but I'm wondering if there's a more standard or official way to approach this issue. ", 
            "subreddit": "aws", 
            "title": "Autoscaling groups dead man's switch", 
            "url": "https://www.reddit.com/r/aws/comments/71jakj/autoscaling_groups_dead_mans_switch/"
        }, 
        {
            "author": "aklosk", 
            "created_utc": 1505989508.0, 
            "domain": "self.aws", 
            "id": "71i7l2", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71i7l2/really_need_help_understanding_incl_ec2_charges/", 
            "score": 11, 
            "selftext": "If AMI says that it'll cost \"$0.03 to $5.67/hr incl EC2 charges + other AWS usage fees\" does that change when you run On-Demand vs. on a reserved Instance?\n\nFor example, a SUSE Enterprise AMI says an r3.8xLarge EC2 says it costs $2.76 but should be inclusive of the $2.66 On-Demand EC2 Cost I'd otherwise be paying.\n\nWhat happens if I buy a Reserved Instance there is no EC2 cost.\n\nI can't find any documentation on software costs that say they are \"Incl of EC2\" if there is a RI available.\n\nhttps://aws.amazon.com/marketplace/pp/B007NLV4R2?ref=cns_srchrow\n\n\n", 
            "subreddit": "aws", 
            "title": "Really need help understanding \"incl EC2 charges\".", 
            "url": "https://www.reddit.com/r/aws/comments/71i7l2/really_need_help_understanding_incl_ec2_charges/"
        }, 
        {
            "author": "PhoenixHouou", 
            "created_utc": 1505976141.0, 
            "domain": "self.aws", 
            "id": "71hdrl", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71hdrl/making_a_reddit_api_call_for_alexa/", 
            "score": 6, 
            "selftext": "I'm trying to make a skill that reads off the titles of subreddits, which i know how to do in python using praw, but i had to do  pip install praw for that to work. How would i install praw in a way that aws lambda would be able to import it?", 
            "subreddit": "aws", 
            "title": "Making a reddit API call for Alexa", 
            "url": "https://www.reddit.com/r/aws/comments/71hdrl/making_a_reddit_api_call_for_alexa/"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1505969581.0, 
            "domain": "self.aws", 
            "id": "71gx37", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 15, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71gx37/detecting_running_in_an_ec2_instance_linux/", 
            "score": 7, 
            "selftext": "i am looking for a good, reliable, way for a shell script (like provided in userdata, or run by other means) to detect that it is running in an EC2 instance.  this needs to work under _any_ well known Linux distribution (Amazon Linux, Centos, Debian, Redhat, Slackware, Ubuntu).  it's a plus if it works under BSD.  it also must indicate _false_ or _negative_ under other know cloud or cloud-like provider, VPS providers, virtual machines, local machines, etc., running any of the same OSes.  it's a plus if it works in Lightsail.  it must work in bash and Bourne shell,  it's a plus if it, or something else, can work in other shells, or another language commonly available like Python or Perl.\n\nby detecting it might choose to do different things in EC2 vs elsewhere.  it's more a plus the fewer lines of code it needs.  1 line in ideal.  10 lines sucks.", 
            "subreddit": "aws", 
            "title": "Detecting running in an EC2 instance (Linux)", 
            "url": "https://www.reddit.com/r/aws/comments/71gx37/detecting_running_in_an_ec2_instance_linux/"
        }, 
        {
            "author": "jramz_dc", 
            "created_utc": 1505924423.0, 
            "domain": "self.aws", 
            "id": "71c6nu", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 27, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71c6nu/alternatives_to_efs_for_windows/", 
            "score": 10, 
            "selftext": "I have an application for which I need to make highly available shared storage available. If this thing was running on Linux, I would just mount all the nodes to the same EFS endpoint, and my job would be done. Unfortunately, this stupid thing only runs on Windows. I have considered things like ObjectiveFS with an S3 back-end, but the asynchronous nature of S3 concerns me. I've also previously had some experience with setting up a Linux-based iSCSI target running Pacemaker/Corosync with DRBD as a block-level node-to-node sync tool to simulate HA NAS for Windows, but I'd really prefer to not go down that road again... it was literally the worst and darkest few weeks of my life, but that might just be because it was happening on RHEL6.\n\nI have done some research on all the possible alternatives, but have come to the listed conclusions in each case:\n\n1. Windows Failover Cluster + File Server Role - requires shared storage\n2. Windows Failover Cluster + Scale-out File Server Role - requires shared storage\n3. Windows 2016 Stretch Cluster - requires shared storage\n4. DFS-R Share - No single access endpoint for multiple clients; no way to automatically fail over in the event of the loss of an endpoint\n\nThe only solution that I can come up with that doesn't involve repeating that iSCSI target nonsense is deploying Samba on Linux and stapling EFS to those nodes as the file share... Has anyone tried that? Will it even work? Has this been sorted out by anyone?\n\nReally appreciate your insights here. Thank you in advance.\n\n\n\n ", 
            "subreddit": "aws", 
            "title": "Alternatives to EFS for Windows", 
            "url": "https://www.reddit.com/r/aws/comments/71c6nu/alternatives_to_efs_for_windows/"
        }, 
        {
            "author": "releasewhat", 
            "created_utc": 1505917321.0, 
            "domain": "self.aws", 
            "id": "71bdvr", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 28, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71bdvr/how_to_handle_2fa_on_company_aws_account/", 
            "score": 10, 
            "selftext": "Everyone says \"be sure to add 2FA to your root account\" and that is easy enough to do on your own personal account where it is just you accessing it, but in an environment such as a company AWS account how are you best adding 2FA to it?\n\n&nbsp;\n\nMy concern is sure it is easy to download Google Authenticator to a managers phone, but what if they leave the company, lose their phone? I thought maybe using a Yubikey but from my search it doesn't seem Yubikey's are all that supported in AWS. Since I would rather not tie the 2FA code to just one person's phone what other ways would best be used? \n", 
            "subreddit": "aws", 
            "title": "How to handle 2FA on company AWS account?", 
            "url": "https://www.reddit.com/r/aws/comments/71bdvr/how_to_handle_2fa_on_company_aws_account/"
        }, 
        {
            "author": "virtualjj", 
            "created_utc": 1505912953.0, 
            "domain": "self.aws", 
            "id": "71ay1o", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71ay1o/no_more_50_promotional_credit_for_partner_webinars/", 
            "score": 3, 
            "selftext": "I noticed that the partner webinar site doesn't mention the $50 promotional credit anymore. I also haven't received any credits for webinars I attended at the end of August. Has this gone the way of the dodo?", 
            "subreddit": "aws", 
            "title": "No more $50 promotional credit for partner webinars?", 
            "url": "https://www.reddit.com/r/aws/comments/71ay1o/no_more_50_promotional_credit_for_partner_webinars/"
        }, 
        {
            "author": "-SPOF", 
            "created_utc": 1505912877.0, 
            "domain": "aws.amazon.com", 
            "id": "71axrs", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 17, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71axrs/stop_resume_workloads_on_ec2_spot_instances/", 
            "score": 41, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Stop & Resume Workloads on EC2 Spot Instances", 
            "url": "https://aws.amazon.com/ru/blogs/aws/new-stop-resume-workloads-on-ec2-spot-instances/"
        }, 
        {
            "author": "Naweze", 
            "created_utc": 1505912548.0, 
            "domain": "github.com", 
            "id": "71awm0", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71awm0/aws_mobile_react_native_starter_app_serverless/", 
            "score": 11, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "AWS Mobile React Native Starter App - Serverless Pet Tracker", 
            "url": "https://github.com/awslabs/aws-mobile-react-native-starter"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1505887275.0, 
            "domain": "self.aws", 
            "id": "71953b", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/71953b/reaching_endpoints_from_private_subnet/", 
            "score": 10, 
            "selftext": "is there some way, like how metadata at 169.254.169.254 is accessed, to access the endpoints of various services, or some tunnel or gateway to an endpoint, from an instance _without_ a public ipv4 address?  if not, IMHO, this would be nice to have in perhaps some 169.254.X.X addresses so that a public ipv4 address would not be needed to access service APIs.", 
            "subreddit": "aws", 
            "title": "reaching endpoints from private subnet", 
            "url": "https://www.reddit.com/r/aws/comments/71953b/reaching_endpoints_from_private_subnet/"
        }, 
        {
            "author": "AbhimanyuGrover", 
            "created_utc": 1505880732.0, 
            "domain": "self.aws", 
            "id": "718n3y", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/718n3y/how_is_container_repositorys_storage_billed/", 
            "score": 13, 
            "selftext": "I've been thinking about the ECR's billing, do you know how the storage space of repositories are billed. Is it\n\na) billed for every version of image contained in repository. So if I have 1 image with 10 versions of the image of 500MB each, will I be billed for storage of 500*10 = 5000 MB?\n\nor \n\nb) billed per unique layer contained in the image regardless of the \n version/tag. For example:\nSay I have 2 common layers in my image, 100M + 400M\nThen this model will bill for only 500M as long as a new tag doesn't introduce new layer.\n\nNot sure if this makes sense, will be happy to clarify if needed.", 
            "subreddit": "aws", 
            "title": "How is container repository's storage billed?", 
            "url": "https://www.reddit.com/r/aws/comments/718n3y/how_is_container_repositorys_storage_billed/"
        }, 
        {
            "author": "adudeguyman", 
            "created_utc": 1505868929.0, 
            "domain": "self.aws", 
            "id": "717ka1", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/717ka1/i_use_aws_primarily_for_a_3tb_photo_backup_using/", 
            "score": 16, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "I use AWS primarily for a 3TB photo backup using S3 Browser. Is my data just as safe & secure in Glacier as it is in S3 as Standard Infrequence Access? It's is a lot cheaper & I'm not concerned about 3-5 hours delay in restoring the files if I need them. I really just want to have a reliable backup.", 
            "url": "https://www.reddit.com/r/aws/comments/717ka1/i_use_aws_primarily_for_a_3tb_photo_backup_using/"
        }, 
        {
            "author": "jeffbarr", 
            "created_utc": 1505865872.0, 
            "domain": "self.aws", 
            "id": "7179kv", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 27, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/7179kv/reinvent_discount_code_inside/", 
            "score": 23, 
            "selftext": "You can use code **JOINME@REINVENT17** to register for re:Invent 2017 at the special price of $1699 while supplies last. \n\nSee you in Vegas!", 
            "subreddit": "aws", 
            "title": "re:Invent Discount Code Inside...", 
            "url": "https://www.reddit.com/r/aws/comments/7179kv/reinvent_discount_code_inside/"
        }, 
        {
            "author": "longhuman", 
            "created_utc": 1505864801.0, 
            "domain": "self.aws", 
            "id": "7175vd", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/7175vd/aws_reinvent_any_benefit_to_taking_the_exams/", 
            "score": 6, 
            "selftext": "if you register for exams at the conference, any special benefit?  More/easier re-takes?  I'm debating if it is worth it, since time spent on exams means less time spent on other things at the conference, like sessions and labs, etc", 
            "subreddit": "aws", 
            "title": "aws re:invent -- any benefit to taking the exams there versus before/after at home?", 
            "url": "https://www.reddit.com/r/aws/comments/7175vd/aws_reinvent_any_benefit_to_taking_the_exams/"
        }, 
        {
            "author": "richardisworking", 
            "created_utc": 1505860861.0, 
            "domain": "self.aws", 
            "id": "716rja", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/716rja/load_testing_a_website_hosted_by_aws/", 
            "score": 1, 
            "selftext": "Is it any problem if I perform a load test on a website using AWS resources (ec2, elastic beanstalk, etc..)?\n\nI hadn't thought twice of it but someone brought it up that it might be against their terms. I'm just trying to simulate the same load of https requests we would get during our peak season. I'm usually the one who submits the penetration testing requests and I don't ever remember seeing any warnings about doing a load test. I could submit another request just to be safe but I haven't been able to find the source IPs for the load testing service I'm using (visual studio online). I don't see why it would be a big deal, and we've already done it before, but I don't want to cause any issues. ", 
            "subreddit": "aws", 
            "title": "Load Testing a website hosted by AWS?", 
            "url": "https://www.reddit.com/r/aws/comments/716rja/load_testing_a_website_hosted_by_aws/"
        }, 
        {
            "author": "lihatiski", 
            "created_utc": 1505856750.0, 
            "domain": "aws.amazon.com", 
            "id": "716be1", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/716be1/ec2_spot_instances_are_now_stoppable_and_resumable/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "EC2 Spot instances are now stoppable and resumable", 
            "url": "https://aws.amazon.com/blogs/aws/new-stop-resume-workloads-on-ec2-spot-instances/"
        }, 
        {
            "author": "MrFancyPant", 
            "created_utc": 1505853534.0, 
            "domain": "self.aws", 
            "id": "715y5i", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/715y5i/should_i_get_a_rds_database/", 
            "score": 2, 
            "selftext": "Hello, I just want to preface this with that I'm very new to this. So if anything doesn't make sense please let me know.\n\nMy company is thinking of changing our hosting service from Media Temple to AWS.\n\nWe're thinking of getting a EC2 instance with CentOS 7 w/ LAMP configuration and connecting Cpanel/WHM on it.\n\nWhat we are planning to do with the instance is host our clients websites and ask them to pay a monthly fee for hosting their website and supplying them with hosting supports as well.\n\nWith that said, I'm not sure if we should even bother getting RDS. IIRC Cpanel comes with its own database.\nAlso with us using Cpanel it seem like there's no reason in using many of the services that AWS has since Cpanel provide some services that are similar.\n\nWould it make sense to set up an Elastic Beanstalk for this situation?\n\nIs there a better solution?\n\nThanks in advance", 
            "subreddit": "aws", 
            "title": "Should I Get a RDS Database?", 
            "url": "https://www.reddit.com/r/aws/comments/715y5i/should_i_get_a_rds_database/"
        }, 
        {
            "author": "Steineee", 
            "created_utc": 1505847893.0, 
            "domain": "self.aws", 
            "id": "715a23", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/715a23/noob_here_how_do_i_copy_file_from_aws_bucket_to/", 
            "score": 1, 
            "selftext": "My goal is to copy s3://imdb-datasets/documents/v1/current/title.basics.tsv.gz to my local Windows PC. I've signed up for an account and gotten my access key + secret key. My classmate and I have both tried to install and use multiple AWS command clients to get the data without success. We installed s3cmd through pip for python3.6 and 2.7. Executing ```python s3cmd --configure```\n\nboth return error \n\n```C:\\ProgramData\\Anaconda3\\python.exe: can't open file 's3cmd': [Errno 2] No such file or directory``` \n\npip freeze shows the module is definitely there. I may just need a really dumbed-down guide to do this, because 3 hours of reading online guides have not helped. \n\nI do have S3Express installed, but there is no guide on how to copy a file to a local machine for it.", 
            "subreddit": "aws", 
            "title": "Noob here: How do I copy file from AWS bucket to local PC?", 
            "url": "https://www.reddit.com/r/aws/comments/715a23/noob_here_how_do_i_copy_file_from_aws_bucket_to/"
        }, 
        {
            "author": "Mattymatt79", 
            "created_utc": 1505841252.0, 
            "domain": "self.aws", 
            "id": "714gvd", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/714gvd/sharepoint_2013_in_aws/", 
            "score": 1, 
            "selftext": "Good afternoon,\n\nWe currently have running in AWS a SharePoint 2013 farm with a SQL database back end. Works great. Does what we want.\n\nI do have some questions and hopefully get a few ideas here on how to maybe make it better.\n\nCurrently we have an A deployment which is production a B which is a backup and a staging server, where we put new deployments on to test.\n\nUsually how this works when we get a new deployment, we take A database and manually migrate it to B and Stage.\nThe reason is, my customer wants the ability to automatically go back to a working copy if things go awry and the SP deployment goes wrong.\n\nI can\u2019t think of a way to automate this process either through SQL or through AWS without a way of doing a manual database migration. What we have works, but it\u2019s time consuming and very clunky, and doesn\u2019t seem to be best practices.\n\nCan someone possibly give me some ideas that I\u2019m not seeing?", 
            "subreddit": "aws", 
            "title": "SharePoint 2013 in AWS.", 
            "url": "https://www.reddit.com/r/aws/comments/714gvd/sharepoint_2013_in_aws/"
        }, 
        {
            "author": "awsgeek", 
            "created_utc": 1505841184.0, 
            "domain": "awsgeek.com", 
            "id": "714gk6", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/714gk6/a_quick_summary_of_some_of_the_really_cool_things/", 
            "score": 4, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "A quick summary of some of the really cool things you can do with Amazon Rekognition, part of the AWS AI family.", 
            "url": "http://www.awsgeek.com/posts/amazon-rekognition-exploration/"
        }, 
        {
            "author": "ducminh1712", 
            "created_utc": 1505839236.0, 
            "domain": "self.aws", 
            "id": "714874", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/714874/aws_credentials_file_and_apache_tomcat_8/", 
            "score": 2, 
            "selftext": "As the title says, I'm struggling to make my Spring Boot app which was packaged to a war file and deployed to a webapps folder of Tomcat 8 on an EC2 instance. However, it seems like the app cannot read credential information on credentials file. I tried to put it in a .aws folder and place the folder in /home/ec2-user/, / and even in Tomcat root folder. I also tried to export environment variables to setenv.sh at Tomcat folder as some guides said but nothing worked.\n\nMy EC2 is running redhat though", 
            "subreddit": "aws", 
            "title": "AWS credentials file and Apache Tomcat 8", 
            "url": "https://www.reddit.com/r/aws/comments/714874/aws_credentials_file_and_apache_tomcat_8/"
        }, 
        {
            "author": "cchelios5", 
            "created_utc": 1505837726.0, 
            "domain": "self.aws", 
            "id": "7141xa", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/7141xa/email_alert_on_instance_creation/", 
            "score": 7, 
            "selftext": "Hello all, \nI am wondering if there is a simple way to get an email alert on instance creation. I have looking into cloudtrail to store logs and then using sns to email that a log is stored but I dont understand how to filter the logs that its storing. I really just want to know when new instances are created. Not sure if there is another way about going about this but I would think this is something others would request. Any help would be appreciated. \n", 
            "subreddit": "aws", 
            "title": "Email Alert on Instance creation", 
            "url": "https://www.reddit.com/r/aws/comments/7141xa/email_alert_on_instance_creation/"
        }, 
        {
            "author": "pushthepramalot", 
            "created_utc": 1505836020.0, 
            "domain": "aws.amazon.com", 
            "id": "713uoq", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/713uoq/service_linked_roles/", 
            "score": 5, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "service linked roles", 
            "url": "https://aws.amazon.com/blogs/security/introducing-an-easier-way-to-delegate-permissions-to-aws-services-service-linked-roles/"
        }, 
        {
            "author": "guppyF1", 
            "created_utc": 1505834303.0, 
            "domain": "self.aws", 
            "id": "713nlj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/713nlj/helpful_tools_for_dynamodb_autoscaling/", 
            "score": 10, 
            "selftext": "We've got a lot of DynamoDB tables (close to 300) and until recently, we'd been using our own home-grown Dynamo throughput auto-scaler.  With DynamoDB autoscaling going GA recently, it was time to move to native \"for free\" autoscaling of tables.  As such, we've put together some tools that helped with this (and the on-going monitoring of table autoscaling) that others may find helpful:\n\n[Autoscale enabler](https://github.com/Signiant/dynamodb-autoscale-enabler) - bash script that uses the CLI to enable autoscaling on batches of tables\n\n[Autoscale lambda enabler](https://github.com/Signiant/dynamodb-autoscale-lambda-enable) - Lambda function that will turn on autoscaling on a new table being created\n\n[Autoscale notify slack](https://github.com/Signiant/dynamodb-autoscaling-to-slack) - Notifies a slack channel when a table or index is autoscaled up or down.\n\n\nThe lambda functions and events are all packaged in Cloudformation so easy to install and configure.\n\nEnjoy!", 
            "subreddit": "aws", 
            "title": "Helpful tools for DynamoDB autoscaling", 
            "url": "https://www.reddit.com/r/aws/comments/713nlj/helpful_tools_for_dynamodb_autoscaling/"
        }, 
        {
            "author": "DonLaFontainesGhost", 
            "created_utc": 1505827855.0, 
            "domain": "self.aws", 
            "id": "712z4a", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/712z4a/my_stupid_ec2_question/", 
            "score": 8, 
            "selftext": "This is the one thing I can never keep straight about EC2 instances, and if there's a graphic that explains it I will be ecstatic:\n\nGiven an EC2 instance, attached storage, and S3 storage, what goes away when, and when am I billed for each? \n\nI grew up on VMWare & Hyper-V, so when I shut down a virtual machine, nothing \"goes away\", but EC2 lessons are always plastered with warnings about lost data on termination using a blizzards of different ways of describing \"memory\" or \"storage\" with no clear indication of which is what. \n\nIf I've overlooked something obvious, I appreciate the help", 
            "subreddit": "aws", 
            "title": "My stupid EC2 question...", 
            "url": "https://www.reddit.com/r/aws/comments/712z4a/my_stupid_ec2_question/"
        }, 
        {
            "author": "Naweze", 
            "created_utc": 1505825547.0, 
            "domain": "techcrunch.com", 
            "id": "712r5w", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 15, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/712r5w/aws_announces_persecond_billing_for_ec2_instances/", 
            "score": 107, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "AWS announces per-second billing for EC2 instances", 
            "url": "https://techcrunch.com/2017/09/18/aws-announces-per-second-billing-for-ec2-instances/"
        }, 
        {
            "author": "Hebrilith", 
            "created_utc": 1505814614.0, 
            "domain": "self.aws", 
            "id": "711wnj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/711wnj/new_relic_query_language_nrql_for_aws_learning/", 
            "score": 1, 
            "selftext": "Hi all,\n\nBarring the documentation on the New Relic site which covers the basics of NRQL and command documentation, are there any resources for learning NRQL specifically for AWS (up to an advanced level)?", 
            "subreddit": "aws", 
            "title": "New Relic Query Language (NRQL) for AWS learning resources", 
            "url": "https://www.reddit.com/r/aws/comments/711wnj/new_relic_query_language_nrql_for_aws_learning/"
        }, 
        {
            "author": "gooblagoobla", 
            "created_utc": 1505795748.0, 
            "domain": "virtuesecurity.com", 
            "id": "710nmy", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/710nmy/aws_s3_pentesting_extension_for_burpsuite_proxy/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "AWS S3 pentesting extension for Burpsuite proxy", 
            "url": "https://www.virtuesecurity.com/blog/aws-penetration-testing-s3-buckets/"
        }, 
        {
            "author": "curtishttp", 
            "created_utc": 1505782739.0, 
            "domain": "self.aws", 
            "id": "70zgyi", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70zgyi/ec2_connect_with_workspaces_through_vpc/", 
            "score": 1, 
            "selftext": "I hope this is the right place to ask this. I created a ec2 server 2016 as a dc and  a worspacee windows 10. I want to join the workspace to the domin. Any idea how to do this?", 
            "subreddit": "aws", 
            "title": "ec2 connect with workspaces through VPC", 
            "url": "https://www.reddit.com/r/aws/comments/70zgyi/ec2_connect_with_workspaces_through_vpc/"
        }, 
        {
            "author": "username0304", 
            "created_utc": 1505781272.0, 
            "domain": "self.aws", 
            "id": "70zbpl", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70zbpl/is_it_possible_to_route_traffic_to_a_mongodb/", 
            "score": 1, 
            "selftext": "I have a mongodb server running collecting data on a windows 10 workspace. I'd like to be able to connect to that database externally from my own IP. I can't figure out how to port forward/route traffic to the internal IP/port for mongodb when connecting over a public IP. Is this possible?", 
            "subreddit": "aws", 
            "title": "Is it possible to route traffic to a mongodb internal IP address on a Windows 10 workspace?", 
            "url": "https://www.reddit.com/r/aws/comments/70zbpl/is_it_possible_to_route_traffic_to_a_mongodb/"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1505776326.0, 
            "domain": "self.aws", 
            "id": "70yts5", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70yts5/how_unlikely_would_a_client_allow_outbound_port/", 
            "score": 1, 
            "selftext": "So I'm working on building a Kinesis solution (either Streams or Firehose, not yet decided) for a client site.  A \"connector\" has to be installed on a particular server because the app running on it only makes it's API available on THAT server.  So, my \"connector\" will interrogate the app's API to get what will essentially be \"Activity\" data.  I need to then take that data and push it out to Kinesis.  But I was thinking this would require punching an outbound hole in their firewall.  So, I got to thinking I might need to provide an optional component to be installed outside the DMZ that the app server component can \"talk to\" to forward the Kinesis data out to the AWS cloud.  But, I'm not sure how that would work.  Since that part wouldn't be AWS Kinesis, how can I \"forward\" the Kinesis data from the app server to the DMZ component and then out to AWS?  ", 
            "subreddit": "aws", 
            "title": "How unlikely would a client allow outbound port 80/443 traffic from a server behind a DMZ? Question related to a Kinesis solution.", 
            "url": "https://www.reddit.com/r/aws/comments/70yts5/how_unlikely_would_a_client_allow_outbound_port/"
        }, 
        {
            "author": "Yogi_DMT", 
            "created_utc": 1505771310.0, 
            "domain": "self.aws", 
            "id": "70yazi", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70yazi/possible_to_run_plain_java_nonweb_app_on_aws/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Possible to run plain Java non-web app on AWS?", 
            "url": "https://www.reddit.com/r/aws/comments/70yazi/possible_to_run_plain_java_nonweb_app_on_aws/"
        }, 
        {
            "author": "speckz", 
            "created_utc": 1505770114.0, 
            "domain": "codeburst.io", 
            "id": "70y67m", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "article", 
            "link_flair_text": "article", 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70y67m/the_time_i_got_drunk_on_s3_and_what_i_learned/", 
            "score": 4, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "The Time I Got Drunk On S3 And What I Learned", 
            "url": "https://codeburst.io/the-time-i-got-drunk-on-s3-and-what-i-learned-ab45f0d8881d"
        }, 
        {
            "author": "blitzcat", 
            "created_utc": 1505767534.0, 
            "domain": "self.aws", 
            "id": "70xvkr", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70xvkr/athena_upgrade_partitions_boned/", 
            "score": 5, 
            "selftext": "We have been using Athena for a while, doing schema changes with:\n\n * drop <Table>\n * create <Table>\n * msck repair table (all partitions come back)\n\nSometime since Friday, \"msck repair table\" changed. It will detect partitions, but immediately calling \"show partitions <table>\" will be empty, IE no partitions at all. These are manual partitions btw. \n\nAnyone else seeing this?\n I don't see anything on the aws big data blog or changes in the documentation.\n\n\n", 
            "subreddit": "aws", 
            "title": "Athena upgrade= partitions boned?", 
            "url": "https://www.reddit.com/r/aws/comments/70xvkr/athena_upgrade_partitions_boned/"
        }, 
        {
            "author": "andretheseal", 
            "created_utc": 1505767318.0, 
            "domain": "self.aws", 
            "id": "70xupw", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 15, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70xupw/having_trouble_forcing_https_with_eb/", 
            "score": 5, 
            "selftext": "Hey,\n\nSo I've been setting up my auto scaling environment for the better part of last week and managed ot get everything right apart from forcing all incoming connections to HTTPS.\n\nI've got the certificate installed and the site renders without any issues over HTTPS only it's available over regular HTTP which I can't have.\n\nBeen searching on Google for hours now for a proper Apache config file I can paste to my .ebextensions folder but everything I've tried so far from the AWS forums or Stackoverflow gives me either a TOO_MANY_REDIRECTS error or does absolutely nothing after deploying.\n\nI'm quite new to the entire AWS ecosystem at this scale and I could really use some help with someone more experienced with EB and Apache!\n\nThanks!", 
            "subreddit": "aws", 
            "title": "Having trouble forcing HTTPS with EB", 
            "url": "https://www.reddit.com/r/aws/comments/70xupw/having_trouble_forcing_https_with_eb/"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1505767283.0, 
            "domain": "self.aws", 
            "id": "70xul8", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 14, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70xul8/kinesis_vs_firehose/", 
            "score": 5, 
            "selftext": "From what I can tell, the main difference between the two is that Firehose doesn't require building the consumer processes as it instead just dumps the data into the final destination for you, such as S3.  Is that correct?  So it sounds like if you need to do custom stuff before the data storage Kinesis is the better choice?  With Kinesis, can I have multiple consumers working off the same data?  Or is once some piece of data \"worked\" on, does it disappear and is not available to any other consumers?", 
            "subreddit": "aws", 
            "title": "Kinesis vs Firehose?", 
            "url": "https://www.reddit.com/r/aws/comments/70xul8/kinesis_vs_firehose/"
        }, 
        {
            "author": "toskp10", 
            "created_utc": 1505766753.0, 
            "domain": "self.aws", 
            "id": "70xsfc", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70xsfc/problems_with_aws_s3_sync/", 
            "score": 3, 
            "selftext": "I'm having some problems with the command-line tool for aws. It mostly works well, but there are a lot of errors. My internet connection is a bit unreliable, but not to this extent. In 18 hours, there were 1100 successful uploads and 120 failed uploads. And the errors varied:\n\n    [SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:661)\n    Could not connect to the endpoint URL\n    ('Connection aborted.', error(101, 'Network is unreachable'))\n    Max retries exceeded with url:\n    ('The write operation timed out',)\n    ('Connection aborted.', error(104, 'Connection reset by peer'))\n\nThe problem is the same on both my Linux and Windows machine, which to me suggests it's probably not a misconfigured client. The messages do point to a networking problem, but my internet access is ok otherwise. My ISP says they are not doing any traffic-shaping that could be to blame. Any thoughts on how to track down the error? I'm just using the\n\n    aws s3 sync <source> <destination>\n\ncommand, and seeing as most of the files upload, it can't be entirely wrong.\n\nThe other problem I have is that when I try to set a cron job to run the command, nothing happens. I know I have my cron syntax correct, as I added a similar dummy command that did work:\n\n    27 12 * * * echo \"test\" >> /home/user/aws.log\n\nBut when I added the aws s3 sync command (that only mostly works), nothing happens. Nothing uploaded and no errors. \n\n* Edited for formatting", 
            "subreddit": "aws", 
            "title": "Problems with aws s3 sync", 
            "url": "https://www.reddit.com/r/aws/comments/70xsfc/problems_with_aws_s3_sync/"
        }, 
        {
            "author": "VWEmissionSoftware", 
            "created_utc": 1505764334.0, 
            "domain": "self.aws", 
            "id": "70xias", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70xias/alternatives_to_copying_ebs_snapshots_across/", 
            "score": 2, 
            "selftext": "I currently have a script running automated EBS snapshots and cross region copying on a hourly basis but its starting to become a huge cost. Unfortunately, the hour restraint is needed for DR purposes. I've been looking to see if there are any alternatives to managing a cross region back up but a lot of the 3rd party solutions are simply running the copy snapshot API in the background. Does anyone have any advice or experience with a 3rd party tool that can do multi region backups that would lower my current cost?", 
            "subreddit": "aws", 
            "title": "Alternatives to copying EBS Snapshots across regions to reduce cost?", 
            "url": "https://www.reddit.com/r/aws/comments/70xias/alternatives_to_copying_ebs_snapshots_across/"
        }, 
        {
            "author": "martip07", 
            "created_utc": 1505757172.0, 
            "domain": "self.aws", 
            "id": "70woel", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70woel/questions_about_alb/", 
            "score": 2, 
            "selftext": "Hi guys,\n\nI have this simple question, does Internal ALB charge for Bandwidth? \n\nThank you,", 
            "subreddit": "aws", 
            "title": "Questions about ALB", 
            "url": "https://www.reddit.com/r/aws/comments/70woel/questions_about_alb/"
        }, 
        {
            "author": "-casper-", 
            "created_utc": 1505755799.0, 
            "domain": "jackrothrock.com", 
            "id": "70wjiv", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70wjiv/a_to_z_with_amazon_s3/", 
            "score": 5, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "A to Z with Amazon S3", 
            "url": "https://jackrothrock.com/a-to-z-with-amazon-s3/"
        }, 
        {
            "author": "jeffbarr", 
            "created_utc": 1505755312.0, 
            "domain": "aws.amazon.com", 
            "id": "70wi9e", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 49, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70wi9e/persecond_billing_for_ec2_instances_and_ebs/", 
            "score": 197, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Per-Second Billing for EC2 Instances and EBS Volumes", 
            "url": "https://aws.amazon.com/blogs/aws/new-per-second-billing-for-ec2-instances-and-ebs-volumes/"
        }, 
        {
            "author": "Tazer79", 
            "created_utc": 1505753388.0, 
            "domain": "self.aws", 
            "id": "70wafo", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70wafo/quick_poll_of_user_disciplines/", 
            "score": 5, 
            "selftext": "Just curious on what most people's roles are around here. I'm a systems engineer and work for a company that has zero cloud experience and developers who don't know how DNS works. So, this has been an uphill battle for me for sure. \n\nSometimes I see comments posted that are \"Just write your infrastructure as code\" and that is so far away from where I am at, and even my peers wouldn't know where to start with that, whereas I can see a developer being able to do that, but having difficulty understanding some of the datacenter like concepts. \n\nSo really I'm just generally wondering if most people here are full-stack types that manage everything end-to-end, if they are devs who have systems guys manage the cloud resources and network, if they are systems guys who are generating resources for developers who have no input into the cloud environment? \n\nI would generally fall under that last category. ", 
            "subreddit": "aws", 
            "title": "Quick Poll of user disciplines", 
            "url": "https://www.reddit.com/r/aws/comments/70wafo/quick_poll_of_user_disciplines/"
        }, 
        {
            "author": "silviadoomra", 
            "created_utc": 1505750938.0, 
            "domain": "aws.amazon.com", 
            "id": "70w0gi", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70w0gi/categorizing_and_prioritizing_a_largescale_move/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Categorizing and Prioritizing a Large-Scale Move to an Open Source Database", 
            "url": "https://aws.amazon.com/blogs/database/categorizing-and-prioritizing-a-large-scale-move-to-an-open-source-database/"
        }, 
        {
            "author": "Dasweb", 
            "created_utc": 1505749941.0, 
            "domain": "self.aws", 
            "id": "70vw84", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70vw84/using_lex_to_allow_a_user_to_signup_for_a_mailing/", 
            "score": 1, 
            "selftext": "Is it currently possible to have lex let a user give an email and be added to an opt-in newsletter?\n", 
            "subreddit": "aws", 
            "title": "Using Lex to allow a user to signup for a mailing list?", 
            "url": "https://www.reddit.com/r/aws/comments/70vw84/using_lex_to_allow_a_user_to_signup_for_a_mailing/"
        }, 
        {
            "author": "dru2691", 
            "created_utc": 1505745378.0, 
            "domain": "self.aws", 
            "id": "70ve5e", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70ve5e/disablesuspend_cloudwatch_alarm_actions/", 
            "score": 1, 
            "selftext": "**SOLVED BELOW**\n\nI did some searching and didn't find anything related to our problem, both here and elsewhere. \n\nFYI, we are utilizing AWS CLI (latest version) on Windows.\n\nI ran the aws cli command: **aws cloudwatch disable-alarm-actions --alarm-names \"alarm name\"**\n\nThe command was ran both manually and via script to test.  I was returned to the command line prompt with no output each time the command is ran (which seems to be the expected result when successful if I read correctly).  I assumed the actions were disabled for each alarm since there was no output.\n\nHowever, we ended up getting an email from one of the alerts that we supposedly disabled the actions for this weekend.  \n\nAfter some further testing, if I run **aws cloudwatch disable-alarm-actions --alarm-names \"non-existent-alarm-name\"**, then I get the same result as above (returned to the command prompt without output).\n\nAm I missing something? Does anyone have experience with disabling alarms/actions temporarily?  It was for weekend maintenance where we knew alerts would be firing off.\n\n", 
            "subreddit": "aws", 
            "title": "Disable/Suspend Cloudwatch Alarm Actions", 
            "url": "https://www.reddit.com/r/aws/comments/70ve5e/disablesuspend_cloudwatch_alarm_actions/"
        }, 
        {
            "author": "dabbad00", 
            "created_utc": 1505740244.0, 
            "domain": "blog.thinkst.com", 
            "id": "70uvxq", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70uvxq/canarytoken_free_tool_to_make_fake_access_keys/", 
            "score": 25, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Canarytoken: Free tool to make \"fake\" access keys that alert when used", 
            "url": "http://blog.thinkst.com/2017/09/canarytokens-new-member-aws-api-key.html"
        }, 
        {
            "author": "vSanjo", 
            "created_utc": 1505738828.0, 
            "domain": "self.aws", 
            "id": "70urfa", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70urfa/forwarding_route53_emails_to_google_apps/", 
            "score": 1, 
            "selftext": "I'm trying to forward my emails from two domains I own in Route53. I've done one which is set up with a Google Apps account, but I'd also like to forward emails from another, separate email into that Google Apps email.\n\nThe first email works great after sorting the MX Records, but I can't seem to forward emails received in the other email to my main Google Apps even after 'adding the domain' within Google Apps. \n\nIs this something on AWS' side or is it something in Google Apps? Is it even possible?\n\nThanks guys! ", 
            "subreddit": "aws", 
            "title": "Forwarding Route53 emails to Google Apps", 
            "url": "https://www.reddit.com/r/aws/comments/70urfa/forwarding_route53_emails_to_google_apps/"
        }, 
        {
            "author": "TooFatToAim", 
            "created_utc": 1505707768.0, 
            "domain": "self.aws", 
            "id": "70smb9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70smb9/need_help_on_account_billing/", 
            "score": 3, 
            "selftext": "So i forgot my account details and it's been charging me every month. Is it possible to find out which account is associated with my credit card? ", 
            "subreddit": "aws", 
            "title": "Need help on account billing", 
            "url": "https://www.reddit.com/r/aws/comments/70smb9/need_help_on_account_billing/"
        }, 
        {
            "author": "stock_daddy", 
            "created_utc": 1505705737.0, 
            "domain": "self.aws", 
            "id": "70sgb2", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70sgb2/aws_certification_account/", 
            "score": 0, 
            "selftext": "Does any one else have a problem accessing their AWS Certification Account? Every time I try to access it, I get ( Link Your Existing Webassessor Account ) which I have already done. I try to link it again, but I get an error message saying ( Your AWS Training account has already been linked with a Certification account.). I already contacted the help desk but no reply yet. ", 
            "subreddit": "aws", 
            "title": "AWS Certification Account", 
            "url": "https://www.reddit.com/r/aws/comments/70sgb2/aws_certification_account/"
        }, 
        {
            "author": "chrisv25", 
            "created_utc": 1505692821.0, 
            "domain": "self.aws", 
            "id": "70r9q1", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 16, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70r9q1/python_3_on_aws/", 
            "score": 0, 
            "selftext": "Hello,\n\nA little background on me before we get to the question in the title. I am a mid career network engineer looking to transition over to an AWS professional. I am currently taking a semester of both python and linux. They are both very new to me as I have spent the last 20 years on the cisco cli. Once I feel a little more comfortable with them, I am going to move forward studying AWS.\n\nSo, as I learn these bedrock devops skills, I want to integrate as much AWS learning as I can. To that end, as I complete projects in my python class, I would like to host them on AWS.\n\nI found a guide that shows you how to host python on AWS but it specificities python 2 and my class is based on python 3. \n\nWhat do I have to do differently as I follow this guide to make sure that my app works?\n\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-django.html\n\nThanks!", 
            "subreddit": "aws", 
            "title": "Python 3 on AWS?", 
            "url": "https://www.reddit.com/r/aws/comments/70r9q1/python_3_on_aws/"
        }, 
        {
            "author": "Ganellon", 
            "created_utc": 1505676826.0, 
            "domain": "self.aws", 
            "id": "70po1o", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 48, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70po1o/aws_beta_exam_certified_cloud_practitioner/", 
            "score": 28, 
            "selftext": "While scheduling one of my upcoming exams through PSI (the new exam partner), I noticed that there is a new beta exam on the available schedule.\n\nThe title is \"AWS Certified Cloud Practitioner Beta Exam\" and is available for scheduling between now and October 3rd. Initially, there was a practice exam, but that has since been removed (at least from my dashboard).\n\nI'm unable to locate any information about this exam, or where it fits within the AWS certification landscape (i.e., is it beyond professional level, somewhere between associate and professional?).\n\nDoes anyone else have any information? Anyone else planning to take the beta?", 
            "subreddit": "aws", 
            "title": "AWS Beta Exam -- Certified Cloud Practitioner", 
            "url": "https://www.reddit.com/r/aws/comments/70po1o/aws_beta_exam_certified_cloud_practitioner/"
        }, 
        {
            "author": "nikhilb_it", 
            "created_utc": 1505670012.0, 
            "domain": "techcrunch.com", 
            "id": "70oy3n", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 18, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70oy3n/aws_now_offers_a_virtual_machine_with_over_4tb_of/", 
            "score": 67, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "AWS now offers a virtual machine with over 4TB of memory", 
            "url": "https://techcrunch.com/2017/09/14/aws-now-offers-a-virtual-machine-with-over-4tb-of-memory/"
        }, 
        {
            "author": "wembleyhoo", 
            "created_utc": 1505669893.0, 
            "domain": "self.aws", 
            "id": "70oxm9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70oxm9/how_to_setup_domain_email_on_aws/", 
            "score": 0, 
            "selftext": "Would love some pointer on how to setup an employee email on aws. E.x john@mydomain.com where user can send and receive email from a customer.  I came from a cPanel background where you can create an new email in a few clicks. I just sign up an aws account and launch an Linux  ec2 instance. Looking forward for any recommendations.  \n\n\n\n- A beginner", 
            "subreddit": "aws", 
            "title": "How to setup domain email on aws ?", 
            "url": "https://www.reddit.com/r/aws/comments/70oxm9/how_to_setup_domain_email_on_aws/"
        }, 
        {
            "author": "vasileios13", 
            "created_utc": 1505656774.0, 
            "domain": "self.aws", 
            "id": "70nm85", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 19, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70nm85/httpbased_ssh_in_aws_ec2_instance/", 
            "score": 12, 
            "selftext": "In Google Compute Cloud I have the option to SSH to an instance through my browser, which is very handy when I'm in a public Wi-Fi (e.g. airport) that blocks port 22. The AWS console has an option to launch a Java SSH client which doesn't work as well, so currently I'm falling back to first log-in to a Google Cloud instance and from there log-in to an AWS instance, which is impractical if I want to connect to many instances. Is there any better HTTP-based SSH client for EC2 instanceS?", 
            "subreddit": "aws", 
            "title": "HTTP-based SSH in AWS EC2 instance?", 
            "url": "https://www.reddit.com/r/aws/comments/70nm85/httpbased_ssh_in_aws_ec2_instance/"
        }, 
        {
            "author": "ac07682", 
            "created_utc": 1505641219.0, 
            "domain": "self.aws", 
            "id": "70mlsj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70mlsj/rails_ec2_instance_not_using_rds/", 
            "score": 1, 
            "selftext": "I have a web app running on an EC2 instance, but I was expecting it to use the RDS I set up to store its tables.  Is that how it works?  I'm very new to this, but when I explore the RDS using pgAdmin there are no tables.", 
            "subreddit": "aws", 
            "title": "Rails EC2 Instance not using RDS", 
            "url": "https://www.reddit.com/r/aws/comments/70mlsj/rails_ec2_instance_not_using_rds/"
        }, 
        {
            "author": "himynameisthor", 
            "created_utc": 1505589959.0, 
            "domain": "self.aws", 
            "id": "70iude", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70iude/can_aws_config_rules_be_set_to_ignore_specific/", 
            "score": 5, 
            "selftext": "I'm using the prebuilt AWS Config rules to verify S3 buckets have logging and versioning enabled. I'd like to exclude some buckets that _shouldn't_ have logging and versioning enabled, like log buckets themselves, or ephemeral `serverlessdeployment` buckets and the like.\n\nAny idea how I can prevent those resources from showing as NON_COMPLIANT?", 
            "subreddit": "aws", 
            "title": "Can AWS Config Rules be set to ignore specific ARNs?", 
            "url": "https://www.reddit.com/r/aws/comments/70iude/can_aws_config_rules_be_set_to_ignore_specific/"
        }, 
        {
            "author": "idotdot", 
            "created_utc": 1505589911.0, 
            "domain": "self.aws", 
            "id": "70iu6p", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70iu6p/how_to_store_logs_from_an_external_api_gateway/", 
            "score": 3, 
            "selftext": "I need to send log of each  call from a third party  api gateway to aws. \n\nThe options I'm considering  are \n\nA. Store logs s3 but that doesn't allow much analysis and ease of access.\n\nB. Store logs as Json in dynamodb and send via api call  from third party api gateway to the aws api gateway to lambda to dynamo db. \n\nI don't think cloudwatch will work.\n\nAny tips ? Google's stack driver looks like it may work but prefer sticking to aws.\n\n", 
            "subreddit": "aws", 
            "title": "How to store logs from an external api gateway into aws ?", 
            "url": "https://www.reddit.com/r/aws/comments/70iu6p/how_to_store_logs_from_an_external_api_gateway/"
        }, 
        {
            "author": "puemos", 
            "created_utc": 1505589088.0, 
            "domain": "github.com", 
            "id": "70irek", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70irek/an_aws_lambda_function_to_clean_ecr_automatically/", 
            "score": 11, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "An AWS Lambda Function to clean ecr automatically", 
            "url": "https://github.com/puemos/aws-lambda-ecr-cleaner"
        }, 
        {
            "author": "sovietmudkipz", 
            "created_utc": 1505578452.0, 
            "domain": "self.aws", 
            "id": "70hqby", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 21, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70hqby/is_it_safe_to_expose_aws_arns_in_a_public_git_repo/", 
            "score": 30, 
            "selftext": "I couldn't find anywhere where it explicit says \"don't!\" or \"do!\" ... so ...\n\nIs it safe to expose AWS ARNs in a public git repo?\n\nFull context: I want to publish my cloudformation YAML in a public git repo, but I'm not quite sure this is safe.  I know how to write the file in some template lang and abstract the identifying information away, if I have to!  Since I'm still very much a noob at AWS, I can't _quite_ tell what the threat model for an attacker possessing an ARN.\n\nThanks!\n\nP.S. I found many examples on github search of aws ARNs in public repos.  That said, I choose not to interpret that as an explicit \"do\" because I'm sure there are many examples of public repos with private, sensitive information out there.  Blah blah follow friends blah blah off bridge, and all that. C:", 
            "subreddit": "aws", 
            "title": "Is it safe to expose AWS ARNs in a public git repo?", 
            "url": "https://www.reddit.com/r/aws/comments/70hqby/is_it_safe_to_expose_aws_arns_in_a_public_git_repo/"
        }, 
        {
            "author": "Antrikshy", 
            "created_utc": 1505577790.0, 
            "domain": "michaelburge.us", 
            "id": "70hnyx", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "article", 
            "link_flair_text": "article", 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70hnyx/injecting_a_chess_engine_into_amazon_redshift/", 
            "score": 10, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Injecting a Chess Engine into Amazon Redshift", 
            "url": "http://www.michaelburge.us/2017/09/10/injecting-shellcode-to-speed-up-amazon-redshift.html"
        }, 
        {
            "author": "Bb415bm", 
            "created_utc": 1505574521.0, 
            "domain": "self.aws", 
            "id": "70hcze", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70hcze/lambda_for_largish_python_code/", 
            "score": 8, 
            "selftext": "Hello,\n\nMy lambda code requires numpy and scipy, which makes it too large (>50mo).\nWhat are my options (aws prefered but others are also of interest)?\n(Docker setups would also work if fast).\n\nThanks,\nB", 
            "subreddit": "aws", 
            "title": "Lambda for largish python code", 
            "url": "https://www.reddit.com/r/aws/comments/70hcze/lambda_for_largish_python_code/"
        }, 
        {
            "author": "reclamo_de_equipaje", 
            "created_utc": 1505573082.0, 
            "domain": "self.aws", 
            "id": "70h8fa", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70h8fa/recommendations_for_parking_elbs/", 
            "score": 11, 
            "selftext": "We recently started rolling out the ability to stop idle EC2 instances as a basic cost-saving measure.  Some of the instances can be off for weeks or months at a time.  These instances may also be fronted by an Elastic Load Balancer.  While the instances are offline, we still incur a cost for the load balancer.  Has anyone solved the dilemma for how to effectively snapshot a config and terminate the ELB?  And, a seamless way to restore the config when the stopped instances need to come back online?  The ELBs aren't expensive but it's unrecoverable costs and AWS Support hasn't been able to provide any clear guidance.  They tell us that our elb's are under-utilized but can't give us any further advice on how we can better manage these incidences.", 
            "subreddit": "aws", 
            "title": "Recommendations for \"parking\" ELBs", 
            "url": "https://www.reddit.com/r/aws/comments/70h8fa/recommendations_for_parking_elbs/"
        }, 
        {
            "author": "cdtoad", 
            "created_utc": 1505567749.0, 
            "domain": "medium.com", 
            "id": "70gtjd", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70gtjd/scaling_on_aws_a_primer_aws_startup_collection/", 
            "score": 36, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Scaling on AWS: A Primer - AWS Startup Collection", 
            "url": "https://medium.com/aws-activate-startup-blog/scaling-on-aws-part-1-a-primer-dbf1276ded5a"
        }, 
        {
            "author": "eagerclimber", 
            "created_utc": 1505552038.0, 
            "domain": "self.aws", 
            "id": "70fweo", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70fweo/types_of_businesses_on_aws_most_sensitive_to/", 
            "score": 8, 
            "selftext": "Hey folks, would really appreciate your help with a little brainstorming exercise. Trying to figure out which AWS (or more generally speaking public cloud) tenants are most sensitive to latency. So far we've thought of online gaming (aka rage if you've got a big lag) and live communications like videoconferencing software.\nAny other ideas? Thanks!", 
            "subreddit": "aws", 
            "title": "Types of businesses on AWS most sensitive to latency?", 
            "url": "https://www.reddit.com/r/aws/comments/70fweo/types_of_businesses_on_aws_most_sensitive_to/"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1505545048.0, 
            "domain": "self.aws", 
            "id": "70fjlw", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70fjlw/sctp_and_aws/", 
            "score": 0, 
            "selftext": "what is AWS's position in regard to the [SCTP](https://en.wikipedia.org/wiki/Stream_Control_Transmission_Protocol) transport layer protocol?", 
            "subreddit": "aws", 
            "title": "SCTP and AWS", 
            "url": "https://www.reddit.com/r/aws/comments/70fjlw/sctp_and_aws/"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1505544509.0, 
            "domain": "self.aws", 
            "id": "70fii6", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70fii6/transferring_buckets_between_accounts/", 
            "score": 7, 
            "selftext": "i have several buckets that i would like to transfer between accounts.  there are two reasons i want to avoid the delete and re-create method.  1. to avoid the chance of someone else getting the bucket name.  2. to avoid having to download and re-upload all that data.\n\nis there a way AWS can do this (change the owner of the buckets without deleting them) for me?\n\nthis would be a nice feature add:  resource transfer\n\non a resource send page enter a resource ID and other account number and optional password.  the send will be pending for 72 hours.  other actions available: cancel a send.  a limit on number of pending sends will exist, at least 10 per sender account.\n\non a resource receive page select the pending resource, its password if applied by sender, and select where the resource is to be placed _if_ it can be put in more than one place.\n\nresource transfer receives are limited by existing limits on number and types the receiving account is limited for.  some possible resources:  S3 buckets (same region). IPv6 /56 blocks (same region), snapshots, volumes, instances, elastic IPs, and just about anything else that can stand alone.  EBS AMIs go with their snapshot and count as one.  also, forum user names.", 
            "subreddit": "aws", 
            "title": "transferring buckets between accounts", 
            "url": "https://www.reddit.com/r/aws/comments/70fii6/transferring_buckets_between_accounts/"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1505537394.0, 
            "domain": "self.aws", 
            "id": "70f2sp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70f2sp/specifying_s3_origin_in_cf/", 
            "score": 2, 
            "selftext": "i read this in [this](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html) CF documentation:\n\n> If the bucket is configured as a website, enter the Amazon S3 static website hosting endpoint for your bucket; do not select the bucket name from the list in the Origin Domain Name field.\n\nwhy do they tell us to do this?  what differences would i get between a bucket configured as a website and a bucket _not_ configured as a website?  i am wondering which way might be better for my needs ... whether to configure new buckets as websites _or not_ ... or whether to _un_ configure the _is a webite_ state for an existing website bucket _or not_.", 
            "subreddit": "aws", 
            "title": "specifying S3 origin in CF", 
            "url": "https://www.reddit.com/r/aws/comments/70f2sp/specifying_s3_origin_in_cf/"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1505533376.0, 
            "domain": "self.aws", 
            "id": "70esm9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70esm9/redirecting_http_to_https_on_cf/", 
            "score": 3, 
            "selftext": "i want to use CF with HTTPS.   i also want to redirect all HTTP requests to HTTPS with the remainder of the URL staying the same.  does CF provide that for me?  i read that CF can do HTTP to my origin for HTTPS requests.  that would mean my origin server would get both HTTPS and HTTP requests as HTTP (if it even gets the HTTP requests at all).  i want to do this from S3 for my apex domain as well as most of my subdomains (not many).  i want to redirect all clients to HTTPS even for static content on S3.\n\nalso, are there any issues CF has with S3 as an origin especially with HTTPS and/or IPv6?\n\nmy domains are on Route53.", 
            "subreddit": "aws", 
            "title": "redirecting HTTP to HTTPS on CF", 
            "url": "https://www.reddit.com/r/aws/comments/70esm9/redirecting_http_to_https_on_cf/"
        }, 
        {
            "author": "wyumez", 
            "created_utc": 1505525322.0, 
            "domain": "self.aws", 
            "id": "70e6ot", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70e6ot/l2tp_with_server_2012_on_ec2/", 
            "score": 1, 
            "selftext": "So, I setup pptp and it worked, but I'm having issues with l2tp.  I read here: https://forums.aws.amazon.com/thread.jspa?messageID=311000&#311000 that l2tp won't work.  The information is a bit dated and it said GRE wouldn't work, but I got pptp to work so... not sure how accurate it is.  ", 
            "subreddit": "aws", 
            "title": "l2tp with server 2012 on ec2", 
            "url": "https://www.reddit.com/r/aws/comments/70e6ot/l2tp_with_server_2012_on_ec2/"
        }, 
        {
            "author": "diffcalculus", 
            "created_utc": 1505517344.0, 
            "domain": "self.aws", 
            "id": "70dih4", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 23, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70dih4/do_you_charge_overhead_to_clients/", 
            "score": 14, 
            "selftext": "For those of you who host servers for clients, do you charge an overhead? If so, do you have a general % you use?\n\nFor example, I'm going to host a simple Network monitoring dashboard on a T2 Micro. Yearly cost for a Micro in my region, as of right now, is $69 all up front.\n\nWould you charge $79? 10%?\n\nThanks for any guidance!\n\n&nbsp;\n\n*Edit*\n\nFor the situation I was asking for, it was simple hosting:\n \nIt's to host a Unifi Cloud Key host (Ubiquiti networking gear).\n \nI'm already charging for any actual network maintenance, so this question was more to do with how much for just hosting the thing. I have a few WordPress only clients that are non-profit and I volunteer to host their site. I'm paying one of them out of my own pocket.\n \nBut I'm expanding my business. I foresee several clients that I'd simply host their environment and charge separately for services.\n \nI already have a couple of well paying web applications that I charge separately for. These apps are rather large so they have a large price tag along with it, therefore, I can roll in hosting fees. But in this case, it's for just hosting the software", 
            "subreddit": "aws", 
            "title": "Do you charge overhead to clients?", 
            "url": "https://www.reddit.com/r/aws/comments/70dih4/do_you_charge_overhead_to_clients/"
        }, 
        {
            "author": "spoiltForChoice", 
            "created_utc": 1505512204.0, 
            "domain": "self.aws", 
            "id": "70d0v0", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70d0v0/aws_elasticsearch/", 
            "score": 6, 
            "selftext": "Just looking to get impressions with someone who has taken them; beyond the reviews of the course, that is.\nI am not new to AWS, at work I heavily use S3, EC2, EMR and use ElasticSearch for indexing purposes. I was wondering if there is a good resource which can walk me through these steps. The closest I've come across is the https://linuxacademy.com/amazon-web-services/training/course/name/aws-certified-big-data -- it encompasses all these areas well although there is lack of depth. I am also concerned if it is not for the intermediate developer.\nI know there are good AWS courses in acloudguru, udemy but am looking for courses tailored towards for some much needed velocity in day-to-day tasks.", 
            "subreddit": "aws", 
            "title": "AWS + Elasticsearch", 
            "url": "https://www.reddit.com/r/aws/comments/70d0v0/aws_elasticsearch/"
        }, 
        {
            "author": "NISMO1968", 
            "created_utc": 1505508484.0, 
            "domain": "techcrunch.com", 
            "id": "70cnjh", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "article", 
            "link_flair_text": "article", 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70cnjh/why_dropbox_decided_to_drop_aws_and_build_its_own/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Why Dropbox decided to drop AWS and build its own infrastructure and network", 
            "url": "https://techcrunch.com/2017/09/15/why-dropbox-decided-to-drop-aws-and-build-its-own-infrastructure-and-network/"
        }, 
        {
            "author": "patton191", 
            "created_utc": 1505507749.0, 
            "domain": "self.aws", 
            "id": "70cklp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70cklp/form_990_on_aws_s3_platform_sortable/", 
            "score": 1, 
            "selftext": "Hi everyone, I'm a bit out of my wheelhouse.  I have zero programming experience and am trying to manipulate the Form 990 data out of Amazon's AWS platform.  \nIn the thread I have copied below there are some great suggestions and they help but for my use they are sub-optimal.  \n\nI'm trying to be able to search a random city when I like and see what non-profits are there, their assets, their accounting firm, and their board of directors.\n\nAll of this data is buried in each individual 990 but it is not easily sortable from what I can see.\n\nSo where I am at a loss is how to manipulate (and export) this data.  \n\nIs my best bet to try to get it in to Microsoft Access?\n\nSomeone in the thread mentioned exporting as a JSON and using Jq?  This sounds like it may be somewhat advanced as I have never used Jq.\n\nhttps://www.reddit.com/r/aws/comments/4p772f/how_the_heck_do_i_view_the_990_documents_on/#bottom-comments\n\nAny help is greatly appreciated.  As I said I am a bit in over my head.", 
            "subreddit": "aws", 
            "title": "Form 990 on AWS S3 platform - Sortable", 
            "url": "https://www.reddit.com/r/aws/comments/70cklp/form_990_on_aws_s3_platform_sortable/"
        }, 
        {
            "author": "kingsloi", 
            "created_utc": 1505506768.0, 
            "domain": "self.aws", 
            "id": "70cgt7", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 25, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70cgt7/we_host_200_sites_subdomains_of_other_sites_only/", 
            "score": 22, 
            "selftext": "Hey, \n\nPlease excuse the long title. I'm in a difficult situation, and could desperately use some advice. \n\nThe company I work for partner with other companies, and we host a subdomain off of their root domain. We have forms on our sites, and up until this point, haven't had a problem. SEO is huge for us. We started to get emails from Google Webmaster tools about because our sites being served over HTTP and not HTTPS, and as of Oct 2017, Chrome will show an ugly message about entering info over non-secure connection, and seeing as most of our traffic is from Chrome, it's a huge problem for us. \n\nI'm relatively new to DevOps, but have being doing smaller site DevOps for years, but this has really caught me off guard.\n\nWe have our sites on all of the 4 EC2 instances attached to 1 ELB, we also have a HAProxy setup, and I believe it's a 50/50 split between traffic between our HAProxy and our ELB. (Older clients are HAProxy, newer clients are ELB AFAIK). \n\nWe host our assets on S3, and have considered implementing CloudFront for our static assets for speed/costs. \n\nThe first thing we thought of was asking our clients to point to our ELB, and handle the SSL termination on the ELB. But then we read that AWS ELBs doesn't support SNI, so we can't use that. Then comes the complication of the SSL certificates! We've used LetsEncrypt for other small sites and have really enjoyed the ease, and obviously the costs, but because our ELB doesn't support SNI, we can't use that. Then we circled back to the HAProxy, which I'm hoping may be our saviour, but not 100% sure.\n\nCan anyone chime in and offer any advice on how to overcome getting our sites secure?\n\nAny advice is much appreciated!\n\n", 
            "subreddit": "aws", 
            "title": "We host 200+ sites (subdomains of other sites only), over an ELB, attached to 4 EC2 instances. Best way to implement SSL over all sites?", 
            "url": "https://www.reddit.com/r/aws/comments/70cgt7/we_host_200_sites_subdomains_of_other_sites_only/"
        }, 
        {
            "author": "jearkrishna", 
            "created_utc": 1505502554.0, 
            "domain": "self.aws", 
            "id": "70c0mg", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70c0mg/restrict_users_to_use_roles_created_by_me/", 
            "score": 1, 
            "selftext": "We are implementing role based access to S3,ECR,AWS code build etc. Please tell me how i should restrict other IAM users to use those roles created by me. ", 
            "subreddit": "aws", 
            "title": "Restrict users to use roles created by me", 
            "url": "https://www.reddit.com/r/aws/comments/70c0mg/restrict_users_to_use_roles_created_by_me/"
        }, 
        {
            "author": "yohghoj", 
            "created_utc": 1505500702.0, 
            "domain": "self.aws", 
            "id": "70bth3", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 16, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70bth3/avoiding_ec2_resource_wastage_with_batch/", 
            "score": 5, 
            "selftext": "Hi,\n\nRelatively new to using EC2 & Batch. I have a system where I have some jobs that I occasionally need to process. They take about 20 minutes tops. I'd like to make sure that I'm not running EC2 instances when I don't need to be. \n\nI set up my batch job such that Minimum vCPUs = 0, but it seems like once my job is finished, EC2 still shows the instance as running. Is it possible to configure Batch such that it shuts down EC2 machine when the queue is empty?", 
            "subreddit": "aws", 
            "title": "Avoiding EC2 resource wastage with Batch", 
            "url": "https://www.reddit.com/r/aws/comments/70bth3/avoiding_ec2_resource_wastage_with_batch/"
        }, 
        {
            "author": "discordianfish", 
            "created_utc": 1505496159.0, 
            "domain": "pub.latency.at", 
            "id": "70bb6j", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70bb6j/latencyat_public_prometheus_performance_metrics/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Latency.at: Public Prometheus Performance Metrics of Cloud providers", 
            "url": "https://pub.latency.at/"
        }, 
        {
            "author": "bshu64", 
            "created_utc": 1505484785.0, 
            "domain": "self.aws", 
            "id": "70a2zf", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 15, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70a2zf/when_deploying_an_application_to_the_cloud_do_you/", 
            "score": 9, 
            "selftext": "I'm looking for feedback from developers on an established product team that has a CI/CD setup. Do you deploy locally first and then deploy to the cloud, or do you skip the local part and just always deploy straight to the cloud?", 
            "subreddit": "aws", 
            "title": "When deploying an application to the cloud, do you: A) Deploy locally, then deploy to the cloud B) Deploy straight to the cloud", 
            "url": "https://www.reddit.com/r/aws/comments/70a2zf/when_deploying_an_application_to_the_cloud_do_you/"
        }, 
        {
            "author": "dentonate", 
            "created_utc": 1505482597.0, 
            "domain": "self.aws", 
            "id": "709v7t", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/709v7t/rds_snapshot_without_data/", 
            "score": 3, 
            "selftext": "Hey there,\n\nI am currently revisiting how my company handles data. We are currently running automated snapshots of our RDS instances every night. We are continuously adjusting the table architecture in our DB (tables, rows, columns). We frequently build out other environments (QA, sandbox, dev) and when setting up a new DB, we either need to boot from a snapshot and wipe all tables except a few key tables or build the new DB from scratch. My desire is to be able to take a snapshot like we are already doing but to also take a snapshot of just the DB architecture (no data). Is there a way to do this automatically or is it better to just run a query once a new DB is created based off of a snapshot?\n\nTIA", 
            "subreddit": "aws", 
            "title": "RDS Snapshot without data", 
            "url": "https://www.reddit.com/r/aws/comments/709v7t/rds_snapshot_without_data/"
        }, 
        {
            "author": "oschannel", 
            "created_utc": 1505472096.0, 
            "domain": "self.aws", 
            "id": "70910o", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70910o/did_everyone_here_knew_that_you_can_get_900_gb_of/", 
            "score": 18, 
            "selftext": "Until now, I used to think AWS gives 30 GB of free storage space in AWS free tier and after you exceed 30 GB you are charged on per GB basis. However, recently I created around 10 EC2 instances in my AWS free tier account which consumed approx 100 GB on EBS but I was not charged for the extra 70 GB. This was the day I figured that you get 30GB x 30 days. This way you can use 30 GB of EBS storage every day or 60 GB for 15 days in a 30 days month or 100 GB for 9 days or even 900 GB for 1 day. All you have to make sure is the [DAYS x GB] value does not exceed 900 GB in a 30 day month.\n\nI think a lot less people are aware about this.\n", 
            "subreddit": "aws", 
            "title": "Did everyone here knew that you can get 900 GB of free EBS storage for a day in free tier", 
            "url": "https://www.reddit.com/r/aws/comments/70910o/did_everyone_here_knew_that_you_can_get_900_gb_of/"
        }, 
        {
            "author": "doydoy", 
            "created_utc": 1505470458.0, 
            "domain": "self.aws", 
            "id": "708x6s", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/708x6s/how_to_move_an_image_between_ecs_repositories/", 
            "score": 4, 
            "selftext": "Currently, our build pipeline results in a docker image being build and pushed to a dev ECS repo. This repo has a massive turnover of images as all our branches and successful builds push images here. This means we have an automated cleanup script that looks at old images and removes them. Developers also have access to go and delete images if they feel one has been pushed with such a fundamental flaw to it that it should not be used by other devs/QA. \n\nTo prevent any accidental deletion of images being used by production environments, we move images from this dev repo to another repo in another AWS account. Currently, I do this from a VM on my local machine - simply pull, tag and push to the new repo. I'm sure you can all agree, this is horrible - but it works and a solution was required about 5 hours before I was asked to look at it.  \n\nIs there a way I could easily move this process into the AWS world, and have it semi automated? I don't want to simply stand up an ec2 instance and run the commands there. I have considered a Jenkins job that is manually triggered, accepting a parameter of image name - is anyone else doing anything similar at the moment?\nOnly certain images need to be moved, so I don't want/need a solution that moves all images of the master branch (although it might come to that). ", 
            "subreddit": "aws", 
            "title": "How to move an image between ECS repositories?", 
            "url": "https://www.reddit.com/r/aws/comments/708x6s/how_to_move_an_image_between_ecs_repositories/"
        }, 
        {
            "author": "paclema", 
            "created_utc": 1505468167.0, 
            "domain": "self.aws", 
            "id": "708s6q", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/708s6q/cognito_equivalent_in_china_to_get_certificates/", 
            "score": 7, 
            "selftext": "We are developing a Web App based in angularjs deployed in a S3 Bucket of AWS. We want to use the aws-sdk for javascript so we can access to Amazon services such as AWS IoT or DynamoDB tables directly in the front end. For this reason, we need a service like Cognito that it will generate specific certificates to each user of our web app.\n\n Due to lack of AWS Services in China region, where Cognito is not offered yet, we found that could be an option to deploy a TVM instance (Token Vending machine) as equivalent service of Cognito, to grant access to every user of the Web App. TVM is an old service that contains an SDB (Simple Data Base) service to store the users on the EC2 instance where the TVM is deployed. \n\nThe problem that we want to solve is to replace this old SDB database to another DynamoDB instance that we can control from the outside of the EC2 instance of the TVM.\nWith this scenario, we will be able to give more attributes to each user\u2019s table or connect this database with other Management apps.\n\nHad someone to deal with something similar like this? Would this solution be the best and secure one?\n\nThank you in advance!\n", 
            "subreddit": "aws", 
            "title": "Cognito equivalent in China to get certificates to use aws-sdk for javascript in the front-end web app ??", 
            "url": "https://www.reddit.com/r/aws/comments/708s6q/cognito_equivalent_in_china_to_get_certificates/"
        }, 
        {
            "author": "flitsmasterfred", 
            "created_utc": 1505467827.0, 
            "domain": "self.aws", 
            "id": "708rfg", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/708rfg/how_to_decrease_the_storage_size_of_a_production/", 
            "score": 6, 
            "selftext": "We got a bunch of database instances on RDS that waste money on a ton of empty storage space. So we'd like to reduce this but RDS doesn't allow to downsize storage space, only increase (why?)\n\nWhat I read on the internet says we'll have to create a new instance with reduced storage from a snapshot. Not a big deal except it would mean we have big time gap between the snapshot of the old instance and the time the new one is ready and the application restarts on it. \n\nWhat is the best way to minimize downtime or data loss?", 
            "subreddit": "aws", 
            "title": "How to decrease the storage size of a production AWS RDS Postgres instance without downtime?", 
            "url": "https://www.reddit.com/r/aws/comments/708rfg/how_to_decrease_the_storage_size_of_a_production/"
        }, 
        {
            "author": "statefulDodger", 
            "created_utc": 1505439707.0, 
            "domain": "github.com", 
            "id": "706snt", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/706snt/debug_a_running_lambda_function_with_chrome_dev/", 
            "score": 13, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Debug a running lambda function with Chrome Dev Tools", 
            "url": "https://github.com/trek10inc/aws-lambda-debugger"
        }, 
        {
            "author": "dabbad00", 
            "created_utc": 1505436111.0, 
            "domain": "medium.com", 
            "id": "706gu0", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/706gu0/responding_to_typical_breaches_on_aws/", 
            "score": 7, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Responding to typical breaches on AWS", 
            "url": "https://medium.com/@magoo/responding-to-typical-breaches-on-aws-28d6fe4071d0"
        }, 
        {
            "author": "solidav", 
            "created_utc": 1505432317.0, 
            "domain": "aws.amazon.com", 
            "id": "7063i0", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/7063i0/aws_partner_webinar_series_september_october_2017/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "AWS Partner Webinar Series - September & October 2017", 
            "url": "https://aws.amazon.com/blogs/aws/aws-partner-webinar-series-september-october-2017/"
        }, 
        {
            "author": "silviadoomra", 
            "created_utc": 1505428125.0, 
            "domain": "aws.amazon.com", 
            "id": "705p0v", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/705p0v/monitoring_amazon_aurora_audit_events_with_amazon/", 
            "score": 2, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Monitoring Amazon Aurora Audit Events with Amazon CloudWatch", 
            "url": "https://aws.amazon.com/blogs/database/monitoring-amazon-aurora-audit-events-with-amazon-cloudwatch/"
        }, 
        {
            "author": "mogsun", 
            "created_utc": 1505426944.0, 
            "domain": "self.aws", 
            "id": "705kuk", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/705kuk/cicd_pipeline_help/", 
            "score": 1, 
            "selftext": "Hi there, just wondering if anyone would have any advice on CI/CD pipelines into AWS.\n\nI am quite new to this particular area and currently need to deploy 3 nodejs based apps onto AWS in an automated, infrastructure as code manner.\n\nCurrently looking at the following.\n\nGithub > CircleCi > Docker cloud > AWS ??? Profit \n\nThe parts I'm not sure on here are the infrastructure as code, i.e what tool would work best with this type of setup. The ones I've heard of are Chef, Puppet, Terraform and cloud formation. However in my mind surely Terraform would suffice as I don't need to install anything extra onto the instance as it's all in the docker container? And where would Terraform fit into the CI/CD pipeline?\n\nSay for example the config supplied in Terraform was to change would I want to go about redeploying everything? Or to just run Terraform manually beforehand? Some sort of teardown process?\n\nAnd if possible, if anyone has advice on deploying dockerized meteor apps onto AWS, is this the best method to go about it? (Only one of the 3 is a meteor app) \n\nAny help would be greatly appreciated, thanks ", 
            "subreddit": "aws", 
            "title": "CI/CD pipeline help", 
            "url": "https://www.reddit.com/r/aws/comments/705kuk/cicd_pipeline_help/"
        }, 
        {
            "author": "Blahblahcomputer", 
            "created_utc": 1505423856.0, 
            "domain": "self.aws", 
            "id": "7059ir", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/7059ir/aws_stacksets_add_and_remove_accounts_from/", 
            "score": 2, 
            "selftext": "Hi, not sure if anyone is using stacksets much, but I went all in on the puppies for a new environment I built out. Now we need to add some more accounts, and I can't seem to figure out how to add additional accounts as targets for an existing stackset.\n\nI've been deploying against a list of account IDs, the correlary question would be, if I deploy against an OU in AWS Organizations, then add a new account to said OU, does the stackset automatically extend to deploy to the new account? I kind of assume not...\n\nSeems like there may be some maturity issues here, but it's so damn convenient I'll deal with multiple stackset occurences for different groups of accounts if that's the only way to handle.\n\nEdit: I put in the title add and remove, but I actually do know how to delete a specific stack in one account/region pair, so never mind on that one.\n\nThanks!", 
            "subreddit": "aws", 
            "title": "AWS Stacksets - add and remove accounts from existing stackset?", 
            "url": "https://www.reddit.com/r/aws/comments/7059ir/aws_stacksets_add_and_remove_accounts_from/"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1505422846.0, 
            "domain": "self.aws", 
            "id": "7055lm", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/7055lm/best_way_to_store_hierarchical_structure_in_aws/", 
            "score": 1, 
            "selftext": "I have a need to store a hierarchical structure in AWS which can be returned by a call to API Gateway.  For all intents and purposes it's your standard folder structure.\n\nQuery performance would have to be fast and lowest cost.  Following query options are required:\n\n1) Given a path I want to return all children. \n\n2) Given a path I want to return all children and their grandchildren as json.\n\n3)  Given a path I want to return all children and their grandchildren as a flattened out list (with path separators of course) of objects.\n\nAt the same time the structure can and will change potentially often, but update performance of the structure is not AS critical as the read performance, if any sacrifice can be made for cost.\n\nIs that any serverless way of pulling this off?", 
            "subreddit": "aws", 
            "title": "Best way to store hierarchical structure in AWS?", 
            "url": "https://www.reddit.com/r/aws/comments/7055lm/best_way_to_store_hierarchical_structure_in_aws/"
        }, 
        {
            "author": "jemath", 
            "created_utc": 1505421369.0, 
            "domain": "self.aws", 
            "id": "704zwf", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/704zwf/what_would_the_process_of_implementing_a_solution/", 
            "score": 1, 
            "selftext": "I've been getting a few alerts pushing Amazon AI. As someone working in a small business, I am trying to wrap my head around this and evaluate if it is something that we can make use of. In generalized terms, how might a company make use of the service? Would you plug in some large dataset, set some global rules/config, and then feed it case-by-case input?\n\nAs a relatively generic example that would apply to every business, could I connect Amazon AI to my CRM, and then ask it, \"who should I call first?\"", 
            "subreddit": "aws", 
            "title": "What would the process of implementing a solution based on Amazon AI look like?", 
            "url": "https://www.reddit.com/r/aws/comments/704zwf/what_would_the_process_of_implementing_a_solution/"
        }, 
        {
            "author": "corganmurray", 
            "created_utc": 1505419045.0, 
            "domain": "self.aws", 
            "id": "704qhp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/704qhp/using_cloudflare_for_their_waf_and_ddos/", 
            "score": 2, 
            "selftext": "Hey guys, I manage an app that runs on a dozen-ish EC2 instances behind an ELB, and I've been patiently waiting for WAF & Shield to show up in the Montreal region, but my company is getting sick of waiting and looking to explore some alternatives. Does anyone have any experience (or a modern guide for) sticking an existing, working app, behind a service like CloudFlare, or know of any other alternatives I could look at to achieve this functionality?", 
            "subreddit": "aws", 
            "title": "Using Cloudflare for their WAF and DDOS protection because WAF & Shield aren't available in my region -- does that seem reasonable? Any suggestions?", 
            "url": "https://www.reddit.com/r/aws/comments/704qhp/using_cloudflare_for_their_waf_and_ddos/"
        }, 
        {
            "author": "SathedIT", 
            "created_utc": 1505418766.0, 
            "domain": "self.aws", 
            "id": "704pdi", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "support", 
            "link_flair_text": "support query", 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/704pdi/deleting_stack_also_deletes_volume_created_in/", 
            "score": 1, 
            "selftext": "I've got two stacks. The first stack creates an `EC2::Volume` and outputs the volume ID. The second stack spins up an Opsworks instance that contains an `Opsworks::Volume` resource that references the volume from the first stack. However, deleting the Opsworks stack, is also deleting the volume that was created in my first stack. See my code snippets below.\n\nIn my first stack, I create the volume like so:\n\n    Resources:\n        EbsVolume:\n        Properties:\n            AutoEnableIO: !Ref 'EbsAutoEnableIO'\n            AvailabilityZone: !ImportValue\n                Fn::Sub: ${CFVPC}-privateaz01\n            Encrypted: !If [hasKmsKeyARN, 'true', 'false']\n            Iops: !If [volumeTypeIsNotIo1, !Ref 'EbsIops', !Ref 'AWS::NoValue']\n            KmsKeyId: !If [hasKmsKeyARN, !ImportValue {'Fn::Sub': '${KmsKeyARN}-dbkmskey'},\n                !Ref 'AWS::NoValue']\n            Size: !Ref 'EbsVolumeSize'\n            SnapshotId: !If [hasEbsSnapshotId, !Ref 'EbsSnapshotId', !Ref 'AWS::NoValue']\n            VolumeType: !Ref 'EbsVolumeType'\n        Type: AWS::EC2::Volume\n\nAnd in my second stack, I have:\n\n    OpsworksVolume:\n        DeletionPolicy: Retain\n        Properties:\n            Ec2VolumeId: !ImportValue\n                Fn::Sub: ${VolumeId}-volumeid\n            MountPoint: /mnt/vol1\n            Name: !Join ['-', [xva, !Ref 'environment', !Ref 'uniqueid', ebs]]\n            StackId: !ImportValue\n                Fn::Sub: ${CFOpsworksStack}-opsworkStack\n        Type: AWS::OpsWorks::Volume\n\nand:\n\n    opsworksInstance:\n        Properties:\n            Architecture: x86_64\n            AutoScalingType: !Ref 'AWS::NoValue'\n            AvailabilityZone: !ImportValue\n                Fn::Sub: ${CFVPC}-publicaz01\n            Hostname: gitea\n            InstanceType: !Ref 'instanceSize'\n            LayerIds:\n                - !Ref 'opsworksLayer'\n            Os: !Ref 'OS'\n            SshKeyName: !Ref 'SSHKey'\n            StackId: !ImportValue\n                Fn::Sub: ${CFOpsworksStack}-opsworksStack\n            SubnetId: !ImportValue\n                Fn::Sub: ${CFVPC}-publicsubnet01\n            Volumes:\n                - !Ref 'OpsworksVolume'\n        Type: AWS::OpsWorks::Instance\n\nI thought for sure that by adding the DeletionPolicy attribute to the Opsworks::Volume resource that it would prevent it from being deleted, but that doesn't seem to be the case. Even though I was pretty sure it wouldn't work, I tried adding it to the EC2::Volume in the first stack, but that failed as well. \n\nIs there a way to prevent this type of behavior?", 
            "subreddit": "aws", 
            "title": "Deleting stack also deletes volume created in another stack.", 
            "url": "https://www.reddit.com/r/aws/comments/704pdi/deleting_stack_also_deletes_volume_created_in/"
        }, 
        {
            "author": "bpadair31", 
            "created_utc": 1505417427.0, 
            "domain": "status.aws.amazon.com", 
            "id": "704jtg", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/704jtg/s3_having_issues_in_useast1/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "S3 having issues in US-EAST-1", 
            "url": "http://status.aws.amazon.com"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1505417041.0, 
            "domain": "self.aws", 
            "id": "704iga", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/704iga/any_good_saas_billing_solutionsplatforms_out/", 
            "score": 2, 
            "selftext": "I was initially going to go with FastSpring as they seemed to have the best combination of features, support and pricing. However, one BIG hang up has been the lack of SNI support so I can't get them to integrate into API Gateway just yet, which is odd considering that from my understanding, they are themselves using AWS as their platform.  They have been supposedly working on SNI support for over a year now.  Each time I ask them they say they are working on it.\n\nHaving said that, what are some of the alternatives out there that are start up friendly with their prices?  For example, pay as you go, no up front monthly commitments?  I also need a platform that is flexible and allows me to specify either fixed or variable or a combination of the two each month to charge the customer's credit card?\n\nI thought about rolling my own by getting my own merchant account, but I'm concerned about chargebacks and fraud, something these third party billing solutions seem to offer protection for as part of their value added fees.\n\nAny recommendations would be appreciated.", 
            "subreddit": "aws", 
            "title": "Any good SaaS billing solutions/platforms out there that are pay as you go to get started?", 
            "url": "https://www.reddit.com/r/aws/comments/704iga/any_good_saas_billing_solutionsplatforms_out/"
        }, 
        {
            "author": "wackdroid", 
            "created_utc": 1505415294.0, 
            "domain": "self.aws", 
            "id": "704bx4", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 103, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/704bx4/s3_down/", 
            "score": 87, 
            "selftext": "Anyone else experiencing this?\n\n\n    s3cmd ls s3://my_bucket/\n    WARNING: Retrying failed request: /?delimiter=/\n    WARNING: 503 (SlowDown): Please reduce your request rate.\n    WARNING: Waiting 3 sec...\n    WARNING: Retrying failed request: /?delimiter=/\n    WARNING: 503 (SlowDown): Please reduce your request rate.\n    WARNING: Waiting 6 sec...\n    WARNING: Retrying failed request: /?delimiter=/\n    WARNING: 503 (SlowDown): Please reduce your request rate.\n    WARNING: Waiting 9 sec...\n    WARNING: Retrying failed request: /?delimiter=/\n\n\nEdit: It's back up here\n", 
            "subreddit": "aws", 
            "title": "S3 Down", 
            "url": "https://www.reddit.com/r/aws/comments/704bx4/s3_down/"
        }, 
        {
            "author": "btsteve1", 
            "created_utc": 1505411193.0, 
            "domain": "self.aws", 
            "id": "703vr7", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/703vr7/is_there_a_way_in_cloudformation_to_make_iam/", 
            "score": 1, 
            "selftext": "I have a bunch of cloud formation templates that have conditional resources in them for alerting. Only the prod stacks get these resources created. I need my IAM policy I am creating in the stack to reflect those conditional resources. So far I am not finding a way to do this. I have tried using Condition: in a separate policy document and it seems to ignore it.", 
            "subreddit": "aws", 
            "title": "Is there a way in Cloudformation to make IAM policies use conditional Resources.", 
            "url": "https://www.reddit.com/r/aws/comments/703vr7/is_there_a_way_in_cloudformation_to_make_iam/"
        }, 
        {
            "author": "wyumez", 
            "created_utc": 1505409912.0, 
            "domain": "self.aws", 
            "id": "703qn9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/703qn9/unable_to_ping_private_ip_after_pptp_vpn/", 
            "score": 1, 
            "selftext": "I am connected to my server 2012 network via VPN, but I can't ping any internal devices such as the private IP listed in the top right.  Anyone know of a setting I'm missing?  I had difficulties with setting up the VPN, but realized I forgot to enable to ports in AWS security groups.  Any help would be great!", 
            "subreddit": "aws", 
            "title": "Unable to ping private IP after PPTP VPN", 
            "url": "https://www.reddit.com/r/aws/comments/703qn9/unable_to_ping_private_ip_after_pptp_vpn/"
        }, 
        {
            "author": "ydereky", 
            "created_utc": 1505409218.0, 
            "domain": "aws.amazon.com", 
            "id": "703nur", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/703nur/get_started_with_deep_learning_using_the_aws_deep/", 
            "score": 2, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Get Started with Deep Learning Using the AWS Deep Learning AMI | Amazon Web Services", 
            "url": "https://aws.amazon.com/blogs/ai/get-started-with-deep-learning-using-the-aws-deep-learning-ami/"
        }, 
        {
            "author": "Rome_Leader", 
            "created_utc": 1505403947.0, 
            "domain": "self.aws", 
            "id": "70326a", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70326a/how_do_you_generalize_bulk_security_group/", 
            "score": 5, 
            "selftext": "My organization has moved towards Cloud Forming a lot of infrastructure. However, we still struggle with security groups and how to effectively maintain them.\n\nHaving a template to generate security groups introduces a lot of problems. The template becomes thousands of lines long, and very difficult to maintain. If someone does launch a group by hand, any subsequent updates to the template will not recognize the change and cause a big (and possibly dangerous) headache. There's also the inconvenience of the Group Name being prefixed with the template name and a UUID snippet, making it hard in certain views to see which group is which.\n\nOverall, I don't think templating security groups is the best solution, and it feels like there must be a better way to deploy and manage SGs on a large scale. Does anyone have any suggestions on how to go about this?", 
            "subreddit": "aws", 
            "title": "How do you generalize bulk security group deployment and maintenance?", 
            "url": "https://www.reddit.com/r/aws/comments/70326a/how_do_you_generalize_bulk_security_group/"
        }, 
        {
            "author": "Lord_Zero", 
            "created_utc": 1505403410.0, 
            "domain": "tberra.com", 
            "id": "702zzk", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/702zzk/use_cognito_to_secure_you_lambda_driven_api/", 
            "score": 4, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Use Cognito to secure you Lambda driven API", 
            "url": "https://tberra.com/aws/amazon/meta/2017/09/14/cognito-and-lambda/"
        }, 
        {
            "author": "Alkanes123", 
            "created_utc": 1505401891.0, 
            "domain": "self.aws", 
            "id": "702u6z", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/702u6z/cname_request_counts_for_elb/", 
            "score": 5, 
            "selftext": "We have a bunch of CNAME records pointing to our ELB, is it possible to get request counts based on CNAME?\n\nSorry if this is the wrong place to ask this question. ", 
            "subreddit": "aws", 
            "title": "CNAME request counts for ELB", 
            "url": "https://www.reddit.com/r/aws/comments/702u6z/cname_request_counts_for_elb/"
        }, 
        {
            "author": "teamphy6", 
            "created_utc": 1505399443.0, 
            "domain": "self.aws", 
            "id": "702kwa", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/702kwa/whats_the_proper_way_to_query_cost_allocation_tags/", 
            "score": 7, 
            "selftext": "I'm developing a billing subsystem that needs to combine coarse cost allocation tags as well as finer grained usage events that I get from a stream.  I have the fine grained stuff working, now is there an API for querying my custom cost allocation tags (for instance if a department has dedicated resources, they get their own tag value)", 
            "subreddit": "aws", 
            "title": "What's the proper way to query cost allocation tags?", 
            "url": "https://www.reddit.com/r/aws/comments/702kwa/whats_the_proper_way_to_query_cost_allocation_tags/"
        }, 
        {
            "author": "Arrev", 
            "created_utc": 1505390981.0, 
            "domain": "self.aws", 
            "id": "701srz", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/701srz/test_environment_on_s3/", 
            "score": 5, 
            "selftext": "Hi all,  \n\nI spun up a simple, static site on S3. Trying to find the best way to create a test/dev environment. I'd like it to be inaccessible to the public/Google. It's a really simple site, so when I'm ready to push updates from the test/dev environment to prod, I'm fine with just copying the files over to my production bucket and invalidating in cloudfront - I don't need anything automated for that aspect. \n\n**Couple of ideas.**\n\n* Setup a test. subdomain, and only allow my IP address to access. I can figure out the subdomain piece, I've had to setup others - it's the restricting access piece that I can 't figure out. Not sure if there's just a bucket policy that I can use.\n\n* Toss the files into a bucket, and just use the aws-created URL. The URL would probably be complicated enough to keep the general public out unless they really went looking, but not sure if Google crawls these?\n\nAny help would be very much appreciated!\n\nNote: I'm not super technical. I know enough to put the site together, and was able to get it up on S3, configure the DNS and the caching with the help of tutorials, but that's really it so I'm looking for a relatively simple solution if there is such a thing.\n\nThanks!\n\n", 
            "subreddit": "aws", 
            "title": "Test environment on S3?", 
            "url": "https://www.reddit.com/r/aws/comments/701srz/test_environment_on_s3/"
        }, 
        {
            "author": "NeoShico", 
            "created_utc": 1505388832.0, 
            "domain": "self.aws", 
            "id": "701mqv", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 14, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/701mqv/anyone_know_how_to_get_aws_credits/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Anyone know how to get AWS credits?", 
            "url": "https://www.reddit.com/r/aws/comments/701mqv/anyone_know_how_to_get_aws_credits/"
        }, 
        {
            "author": "the_unsackable", 
            "created_utc": 1505384137.0, 
            "domain": "self.aws", 
            "id": "701bcj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/701bcj/information_on_aws_for_starters/", 
            "score": 4, 
            "selftext": "Hi folks, \nI work for IT company, mainly in Production application support and Telecom CRM as domain.\nCurrently working with basic knowledge in Oracle & Unix but none of programming or coding language.\nLooking to move into AWS, Can you help me on how do I approach for the same.\n\nfrom web, One of the pre-requiste for AWS is Java language, how true is this and would it be show-stopper if I am not conversant with it.\nPlease suggest. \nThanks in Advance to you all.", 
            "subreddit": "aws", 
            "title": "Information on AWS for starters", 
            "url": "https://www.reddit.com/r/aws/comments/701bcj/information_on_aws_for_starters/"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1505362681.0, 
            "domain": "self.aws", 
            "id": "6zzzic", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zzzic/kinesis_firehose_s3_athena_then_what/", 
            "score": 5, 
            "selftext": "I'm building a system to ingest log files from various system and then do different things with that data on AWS.  \n\nSo far, I've got the following solution in mind:\n\n1) On premise \"connector\" that uses the SDK to push data up to AWS via Firehose\n\n2) Data from Firehose stored in S3\n\n3) Athena used to query data from S3\n\n4) Create a sort of data warehouse whereby I use the results of Athena to create a denormalized copy of the data, somewhere, to be queried potentially often.  Read performance is more important than write performance.\n\nFor 4), I'm not clear where this data would ultimately reside.  Would DynamoDB make sense?  I'm really trying to go the full \"serverless\" route here and not have to provision database servers or even manage RDS instances. \n\nMy assumption here is that Athena is not cost effective or really built for frequent queries and I instead have to use some other means for this part.", 
            "subreddit": "aws", 
            "title": "Kinesis Firehose -> S3 -> Athena, then what?", 
            "url": "https://www.reddit.com/r/aws/comments/6zzzic/kinesis_firehose_s3_athena_then_what/"
        }, 
        {
            "author": "wyumez", 
            "created_utc": 1505348189.0, 
            "domain": "self.aws", 
            "id": "6zyq1a", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zyq1a/shared_folder_mapped_to_drive_letter_to_local_pc/", 
            "score": 2, 
            "selftext": "Hello, \n\nI have been trying to figure this out for hours: how can I get my shared folder onto a local PC?  I tried VPN the normal way (remote access manager) but I can't connect to my EC2 windows server 2012 r2 instance.  Any help would be greatly appreciated.  Thank you!", 
            "subreddit": "aws", 
            "title": "Shared folder (mapped to drive letter) to local PC", 
            "url": "https://www.reddit.com/r/aws/comments/6zyq1a/shared_folder_mapped_to_drive_letter_to_local_pc/"
        }, 
        {
            "author": "turtleattacks", 
            "created_utc": 1505338145.0, 
            "domain": "self.aws", 
            "id": "6zxptb", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zxptb/need_to_screen_mirrorcast_not_sure_if_ec2_is_the/", 
            "score": 0, 
            "selftext": "Hi guys, \n\nI would like my multiple users to type a specific address in their browser and be able to see the screen on my EC2 instance. \n\nI would like to do this because I would like an EC2 instance to run a live dashboard. \n\nCan someone please tell me what would be the best service to run in order to achieve this? \n\n", 
            "subreddit": "aws", 
            "title": "Need to screen mirror/cast... not sure if EC2 is the right solution", 
            "url": "https://www.reddit.com/r/aws/comments/6zxptb/need_to_screen_mirrorcast_not_sure_if_ec2_is_the/"
        }, 
        {
            "author": "velebak", 
            "created_utc": 1505332907.0, 
            "domain": "self.aws", 
            "id": "6zx4yw", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zx4yw/best_practices_initiating_an_emr_spark_job_from_a/", 
            "score": 1, 
            "selftext": "Looking to automate some Spark jobs that are initiated from a Lambda.  In short, I have a need to kick off a Spark job based on an API request.  I thought Lambda would be best, but I'm missing some concepts of how you initiate Spark.  I could be going about this the wrong way, so looking for some guidance.  TIA!", 
            "subreddit": "aws", 
            "title": "Best Practices: Initiating an EMR Spark Job from a Lambda?", 
            "url": "https://www.reddit.com/r/aws/comments/6zx4yw/best_practices_initiating_an_emr_spark_job_from_a/"
        }, 
        {
            "author": "loki77", 
            "created_utc": 1505331789.0, 
            "domain": "medium.com", 
            "id": "6zx0h8", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zx0h8/debugging_iam_permissions_with_cloudtrail_remind/", 
            "score": 8, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Debugging IAM permissions with CloudTrail - Remind Engineering", 
            "url": "https://medium.com/@RemindEng/debugging-iam-permissions-with-cloudtrail-b73f34038f3"
        }, 
        {
            "author": "WillNowHalt", 
            "created_utc": 1505330492.0, 
            "domain": "docs.aws.amazon.com", 
            "id": "6zwv7k", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zwv7k/aws_certificate_manager_support_for_caa_dns/", 
            "score": 23, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "AWS Certificate Manager support for CAA DNS records", 
            "url": "https://docs.aws.amazon.com/acm/latest/userguide/setup-caa.html"
        }, 
        {
            "author": "psdilip", 
            "created_utc": 1505329989.0, 
            "domain": "self.aws", 
            "id": "6zwt7n", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zwt7n/boto3_put_items_in_the_dynamodb/", 
            "score": 1, 
            "selftext": "Hey guys, another help if possible. Thanks in advance! Here is my simple code here, I am trying to put items to my database using boto3 library: for some reason i'm getting a **AttributeError: 'DynamoDB' object has no attribute 'Table'** I don't understand how to fix this\n\n     import boto3\n     import csv\n\n\n     dynamodb = boto3.client('dynamodb')\n     table = dynamodb.Table('test')\n\n     table.put_item(\n\n     Item={\n        'name': 'test123'\n     }\n     )", 
            "subreddit": "aws", 
            "title": "Boto3, Put_Items in the DynamoDB", 
            "url": "https://www.reddit.com/r/aws/comments/6zwt7n/boto3_put_items_in_the_dynamodb/"
        }, 
        {
            "author": "waitrewindthat", 
            "created_utc": 1505328527.0, 
            "domain": "info.redlock.io", 
            "id": "6zwnbl", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zwnbl/security_automation_and_orchestration_for_aws/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Security Automation and Orchestration for AWS Webinar", 
            "url": "https://info.redlock.io/aws-security-automation-orchestration-webinar?utm_campaign=Webinar%20-%201709%20Avantgarde&utm_content=60053048&utm_medium=social&utm_source=twitter"
        }, 
        {
            "author": "jearkrishna", 
            "created_utc": 1505327949.0, 
            "domain": "self.aws", 
            "id": "6zwku9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zwku9/docker_on_awscodebuild/", 
            "score": 1, 
            "selftext": "I would like to know how to achieve this using aws code build:\n1) auto bootstrap with chef server. Is it possible bootstrap aws code build container ?\n2) after 1, during chef cookbook run aws code build, it pulls image from ecr and spin up a container\n3) apply some configurations on top of container and push image to ecr.\n\nI am trying to understand how to achieve this ? which aws codebuild image i should take ? buildspec.yml format etc.\n\nplease help", 
            "subreddit": "aws", 
            "title": "Docker on awscodebuild", 
            "url": "https://www.reddit.com/r/aws/comments/6zwku9/docker_on_awscodebuild/"
        }, 
        {
            "author": "FinallyAFreeMind", 
            "created_utc": 1505327355.0, 
            "domain": "self.aws", 
            "id": "6zwidy", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zwidy/elasticsearch_service_access_policies/", 
            "score": 2, 
            "selftext": "I'm having trouble finding information on this that says explicitly that this *won't* work.\n\nIf I have an IAM user that will be accessing ElasticSearch programmatically; can I leave the ElasticSearch Service Access Policy blank - and then just give that user access to ESS through the IAM Console?\n\nEverything seems to make me thing that I can't do that - and I must explicitly give access via the access policy *inside* of ESS.\n\nIt seems with IAM roles; I can achieve this - but unsure on with users.\n\nTrying to test this now (Takes 10 minutes every time for ESS to process changes) - so I'll report back unless someone beats me to it; but would like to have this post as a reference for later.", 
            "subreddit": "aws", 
            "title": "ElasticSearch Service Access Policies", 
            "url": "https://www.reddit.com/r/aws/comments/6zwidy/elasticsearch_service_access_policies/"
        }, 
        {
            "author": "Micocrates", 
            "created_utc": 1505325683.0, 
            "domain": "self.aws", 
            "id": "6zwbdt", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zwbdt/how_do_i_embed_a_file_and_access_it_using_net/", 
            "score": 1, 
            "selftext": "I added a folder and file to my project. I set the file to embedded resource in the build actions. It shows up as embed in the csproj file . Im just stuck on how to actually access the file. I've tried Assembly GetManifest etc and that has not seemed to work. Any help would be appreciated, thanks.", 
            "subreddit": "aws", 
            "title": "How do I embed a file and access it using .net core Visual Studio Lambda", 
            "url": "https://www.reddit.com/r/aws/comments/6zwbdt/how_do_i_embed_a_file_and_access_it_using_net/"
        }, 
        {
            "author": "YouWantWhatByWhen", 
            "created_utc": 1505325379.0, 
            "domain": "self.aws", 
            "id": "6zwa1w", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zwa1w/how_to_impose_absurdly_tight_resource_and/", 
            "score": 2, 
            "selftext": "I know everyone (including me) always complains about low resource limits getting in their way, but now I have the opposite problem. I work in an AWS shop and we're hiring for our operations team. We typically assign some homework to our prospective candidates. In the past we've had them work out a problem in Puppet, but Puppet comprises a much smaller part of our job nowadays. So I'd like to give them an AWS problem.\n\nBut this leads to the problem of payment. I don't want to ask our candidates to register for a paid account just to complete the interview process. IWBNI there were a totally free, no credit card required tier of AWS in which we could ask our candidates to do the homework, but that doesn't exist. That leaves us creating an account for them, and while my company woud be happy to foot the bill for the candidate completing the homework, we don't want them to mine bitcoin on our dime.\n\nHas anyone here ever tried to run an AWS account with very tight resource limits, i.e. much lower than Amazon's laughably low initial limits? If so, how did it go? I'd especially like to know if anyone had AWS support set this up only to find that they *didn't* impose the limits you wanted.\n\nThanks in advance.", 
            "subreddit": "aws", 
            "title": "How to impose absurdly tight resource and spending limits on an AWS account?", 
            "url": "https://www.reddit.com/r/aws/comments/6zwa1w/how_to_impose_absurdly_tight_resource_and/"
        }, 
        {
            "author": "menge101work", 
            "created_utc": 1505324093.0, 
            "domain": "self.aws", 
            "id": "6zw4tp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zw4tp/reinvent_ticket_return_or_transfer/", 
            "score": 1, 
            "selftext": "Does any one know the process for returning or transferring a Re:Invent ticket?\n\nDoes it exist?", 
            "subreddit": "aws", 
            "title": "Re:Invent ticket return or transfer", 
            "url": "https://www.reddit.com/r/aws/comments/6zw4tp/reinvent_ticket_return_or_transfer/"
        }, 
        {
            "author": "largeavian", 
            "created_utc": 1505318637.0, 
            "domain": "self.aws", 
            "id": "6zvieo", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zvieo/aws_and_visual_studio/", 
            "score": 4, 
            "selftext": "I'm trying to make a simple GUI interface to start and stop my instance. \n\nI've done something like this in Powershell using the AWS CLI commands, but I'd like to be able to create a gui that allows me to do this (and other things) but not sure the best way to do it. \n\nI'm not sure the best route to go. I've done a powershell form that I think looks good, but would like to make it easier for a user to run and hopefully in an exe where I can code creds in without someone able to look at the PS script for the information. \n\nAny thoughts would be appreciated. ", 
            "subreddit": "aws", 
            "title": "AWS and Visual Studio", 
            "url": "https://www.reddit.com/r/aws/comments/6zvieo/aws_and_visual_studio/"
        }, 
        {
            "author": "silviadoomra", 
            "created_utc": 1505316272.0, 
            "domain": "aws.amazon.com", 
            "id": "6zv8yp", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zv8yp/integrating_teradata_with_amazon_redshift_using/", 
            "score": 2, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Integrating Teradata with Amazon Redshift Using the AWS Schema Conversion Tool", 
            "url": "https://aws.amazon.com/blogs/database/integrating-teradata-with-amazon-redshift-using-the-aws-schema-conversion-tool/"
        }, 
        {
            "author": "Dancing_Hispanic_Cat", 
            "created_utc": 1505312589.0, 
            "domain": "self.aws", 
            "id": "6zuuqq", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zuuqq/resources_for_learning_how_to_create_json/", 
            "score": 2, 
            "selftext": "I'm rather experienced in regards to C# application development but in regards to AWS JSON templates I feel pretty out of touch. What sort of resources can I use to better familiarize myself with creating a template.  \n&nbsp;  \n  Are there default templates?   \n&nbsp;  \n  If you were to create one from scratch or modifying a template, what's your development process like?  \n&nbsp;  \n  Any recommendations on quality resources that helped you learn/understand JSON?", 
            "subreddit": "aws", 
            "title": "Resources for learning how to create JSON Templates", 
            "url": "https://www.reddit.com/r/aws/comments/6zuuqq/resources_for_learning_how_to_create_json/"
        }, 
        {
            "author": "speckz", 
            "created_utc": 1505311351.0, 
            "domain": "aws.amazon.com", 
            "id": "6zupud", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zupud/amazon_route_53_announces_support_for_dns_query/", 
            "score": 27, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Amazon Route 53 Announces Support For DNS Query Logging", 
            "url": "https://aws.amazon.com/about-aws/whats-new/2017/09/amazon-route-53-announces-support-for-dns-query-logging/"
        }, 
        {
            "author": "awsgeek", 
            "created_utc": 1505306435.0, 
            "domain": "i.redd.it", 
            "id": "6zu9if", 
            "is_reddit_media_domain": true, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 20, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zu9if/keeping_pace_with_aws_can_be_excitingchallenging/", 
            "score": 117, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Keeping pace with AWS can be exciting/challenging, made time this week to experiment with the AWS Web Application Firewall", 
            "url": "https://i.redd.it/3bs4s33dbnlz.jpg"
        }, 
        {
            "author": "craig1f", 
            "created_utc": 1505302682.0, 
            "domain": "self.aws", 
            "id": "6ztyxw", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ztyxw/has_cloudwatch_awslogs_broken_for_anyone_else/", 
            "score": 1, 
            "selftext": "I'm running into an issue where awslogs fails to install on step two: \"downloading the latest bits\". When I dig into the python script, it looks like the problem is that this file doesn't exist: /var/awslogs/bin/aws\n\nThis has started happening on all branches of my project, suggesting that the problem is on the AWS-side, and not my side. \n\nIs anyone else having this problem? Does anyone know what to do?", 
            "subreddit": "aws", 
            "title": "Has CloudWatch awslogs broken for anyone else?", 
            "url": "https://www.reddit.com/r/aws/comments/6ztyxw/has_cloudwatch_awslogs_broken_for_anyone_else/"
        }, 
        {
            "author": "mansonitefirefox", 
            "created_utc": 1505281608.0, 
            "domain": "self.aws", 
            "id": "6zsp1q", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zsp1q/enabling_cf_signed_cookies_via_serverless/", 
            "score": 0, 
            "selftext": "Looking for some documentation or examples on how to activate and configure the \"Restrict Viewer Access\" (by enabling signed cookies) section of the Behaviours of a Cloudfront Distribution via Serverless.\n\nIt would appear from the documentation that this configuration isn't available in CloudFormation, which is giving me little hope that Serverless can pull it off, but I could be wrong.", 
            "subreddit": "aws", 
            "title": "Enabling CF signed cookies via Serverless", 
            "url": "https://www.reddit.com/r/aws/comments/6zsp1q/enabling_cf_signed_cookies_via_serverless/"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1505276906.0, 
            "domain": "self.aws", 
            "id": "6zsd7b", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zsd7b/vpn_between_regions/", 
            "score": 3, 
            "selftext": "what do you do in advance of setting up a VPN between two default subnets in different regions that already have the same IP address range (172.31.0.0/24) when there are already many instances running in each that need to securely communicate with instances in the other subnet?", 
            "subreddit": "aws", 
            "title": "VPN between regions", 
            "url": "https://www.reddit.com/r/aws/comments/6zsd7b/vpn_between_regions/"
        }, 
        {
            "author": "brutalgash", 
            "created_utc": 1505274985.0, 
            "domain": "self.aws", 
            "id": "6zs7nf", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zs7nf/https_connection_to_ec2_hosted_wordpress_instance/", 
            "score": 0, 
            "selftext": "Hello,\n\nI am really struggling to get https working with my EC2 hosted wordpress instance. Here's what I've done so far.\n\n- Created new EC2 instance. Installed Wordpress, Apache, PHP and MySql. Configured all services as per this article http://coenraets.org/blog/2012/01/setting-up-wordpress-on-amazon-ec2-in-5-minutes/\n\nI CAN access my wordpress site via HTTP. Can also access the instance directly via SSH.\n\n- Purchased domain name (Crazy Domains) and pointed to it using Route53.\n- Created SSL Certificate using AWS Certificate Manager\n- Create Elastic Load Balancer, added ACM generated SSL certificate to ELB.\n- Set ELB security group to allow all incoming traffic\n- Set EC2 security group to allow http and https traffic from ELB security group.\n\nWhen I attempt to access my site via https, I receive a 408 timeout. Chrome shows that the site has a valid HTTPS certificate, however the actual site content does not load. Just a white screen.\n\nI have searched through many support articles in an attempt to fix this. I have TRIPLE checked all my security groups to ensure HTTPS traffic is allowed through the ELB down to the EC2 instance.\n\nAny help would be very much appreciated. Thanks.", 
            "subreddit": "aws", 
            "title": "HTTPS connection to EC2 hosted Wordpress instance is failing", 
            "url": "https://www.reddit.com/r/aws/comments/6zs7nf/https_connection_to_ec2_hosted_wordpress_instance/"
        }, 
        {
            "author": "Peep__Hole", 
            "created_utc": 1505269730.0, 
            "domain": "self.aws", 
            "id": "6zrsaw", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zrsaw/is_kms_good_for_storing_a_symmetric_encryption_key/", 
            "score": 1, 
            "selftext": "I still can't figure out the use case for kms. Is KMS good for storing a key that i can then get at a later time on the client side to encrypt a text?", 
            "subreddit": "aws", 
            "title": "Is KMS good for storing a symmetric encryption key?", 
            "url": "https://www.reddit.com/r/aws/comments/6zrsaw/is_kms_good_for_storing_a_symmetric_encryption_key/"
        }, 
        {
            "author": "spdcbr", 
            "created_utc": 1505267520.0, 
            "domain": "self.aws", 
            "id": "6zrlal", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zrlal/whats_a_good_starting_point_to_understand_aws/", 
            "score": 2, 
            "selftext": "I will be working on a project that will involve use of AWS, more specifically - S3, Elastic Beanstalk, Lambda, EC2, DynamoDB, APi Gateway,etc and I'm not really sure where to start at.\n\nI've see some of the youtube videos by the Amazon channel, but they don't have much depth.\n\nI'm looking to understanding the concepts and be able to use them well enough to build projects using AWS.\n\nAny suggestions?", 
            "subreddit": "aws", 
            "title": "What's a good starting point to understand AWS?", 
            "url": "https://www.reddit.com/r/aws/comments/6zrlal/whats_a_good_starting_point_to_understand_aws/"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1505261925.0, 
            "domain": "self.aws", 
            "id": "6zr2sq", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zr2sq/impressive_performance_with_t2_micro_as_compared/", 
            "score": 3, 
            "selftext": "So I've been playing around with the free tier T2 Micro instances and I gotta say, the performance is surprisingly good for such a low end machine.  Much more so then a comparable Azure VM.  AND, this is with a 'heavy\" Windows Server installed on them.  Through RDP, the AWS instances are much more responsive than Azure.  Anyone else notice this?  Does AWS just have better VM technology?", 
            "subreddit": "aws", 
            "title": "Impressive performance with T2 Micro as compared to comparable Azure VM", 
            "url": "https://www.reddit.com/r/aws/comments/6zr2sq/impressive_performance_with_t2_micro_as_compared/"
        }, 
        {
            "author": "ahemcrayon", 
            "created_utc": 1505245417.0, 
            "domain": "pages.awscloud.com", 
            "id": "6zpd26", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zpd26/25_aws_credit/", 
            "score": 12, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "$25 AWS Credit", 
            "url": "https://pages.awscloud.com/17awsdevday.html"
        }, 
        {
            "author": "psdilip", 
            "created_utc": 1505240761.0, 
            "domain": "self.aws", 
            "id": "6zoui1", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zoui1/boto3_iam_policies/", 
            "score": 2, 
            "selftext": "Hi all. I need your quick help if possible. I'm trying to create a IAM policy using boto3 python. I'm getting an error saying that Policy document should be type 'basestring' instead of 'dict'. Any solutions?\n\n> response = client.create_policy(\n>                 PolicyName = 'test-policy',\n>                 PolicyDocument = {\"Version\": \"2012-10-17\", \n>                 \"Statement\": [ ..... ]  } )", 
            "subreddit": "aws", 
            "title": "Boto3 IAM Policies", 
            "url": "https://www.reddit.com/r/aws/comments/6zoui1/boto3_iam_policies/"
        }, 
        {
            "author": "Blahblahcomputer", 
            "created_utc": 1505233230.0, 
            "domain": "self.aws", 
            "id": "6zo12r", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zo12r/aws_governance_concepts_and_best_practices/", 
            "score": 3, 
            "selftext": "IT governance in general is complex. Cloud governance is even more so because the whole point of cloud is to give up some level of control to developers. That means instead of a small handful of trusted admins performing every action, a wide range of individuals in many different roles may have self service capabilities in the environment.\n\nI've seen a lot of different models for maintaining governance over IT environments, and they all share the common denominator of being complex and difficult to really understand. I like a nice, simple view. Governance is meant to ensure things are cheap, easy to manage, and secure. Management (or operations management) is making sure things are working the way you want, while governance is making sure that things are easy to manage. Security management is making sure you keep private what should be private, while governance is making sure that it is an attainable goal. Cost management is controlling and reducing spend, while governance is making sure that people follow rules that make cost management achievable. I've never seen it expressed quite that way, but I hope you find that way of looking at it useful. Note how each splits management, which I am defining as the actions a team takes daily to make things work the desired way, from governance, where a set of rules is defined and enforced to make management possible and efficient.\n\nI will split this discussion into three parts, make it easy, make it cheap, and make it secure. These three are highly related, overly complex environments (failure to make it easy) are very difficult to secure or reduce spend in for example. This insight especially applies to multi-cloud environments, where an enterprise might have 2 major public clouds they are using, with multiple PaaS services each, in addition to a couple of virtualization platforms, disparate automation / private cloud stacks, etc... Finding the right mix of choice and control is hard. Clearly defining your governance goals makes it a lot easier.\n\nFirst, to make managing an environment easy we need to reduce complexity. Some of the simple examples of where complexity creeps in are OS options, networking configurations, and authentication mechanisms allowed. For OS options it is best to limit the choices to a handful of approved standards across the business and make it very difficult to seek an exemption. Then take that option and bake a single standard way of deploying that OS. We get deep into a rabbit hole here quickly of pre-baked images vs. deploying components at provisioning time but regardless of how you approach this problem you want to define a single standard and stick with it. Next is consideration of networking configurations. In a previous article I talked about multi-account strategies for AWS and part of that strategy is how it relates to your networking topology. The biggest single thing you can do for networking governance is to have an IPAM used across your cloud environments. This stores information about what networks are in which environments and used for what purpose. This information becomes invaluable for managing the environments. Finally for authentication, one of the biggest issues with managing multiple clouds and different environments is managing credentials. Having a governance standard that defines a single identity provider per class of user (I.E. one for employees, one for customers, one for IoT devices, etc...) makes management a lot easier. These are but some examples of reducing complexity by defining standards as part of your governance regime. The next step as with all of these is ensuring compliance. This can be achieved through the use of either cloud native tools like AWS Config or a third party SIEM.\n\nThe next high level governance goal I'd like to discuss is making it cheap. This is a very rich area for discussion that could (and probably will) have it's own blog post. Some basic guidelines are essential from day one. One example includes limiting the types (sizes) of instances (or servers) that can be created by end users. Both AWS and Azure have a lot of options, but due to the way that cost controls work in both clouds, limiting users to a handful (4 or 5) options makes cost management drastically more effective. Another place you can cut costs is by defining and enforcing what a dev environment actually is. Do you need a high availability deployment of a database for dev? Probably not, same with high performance clusters that are better suited to pre-prod/QA where load test occurs. Maybe everyone insists they need Oracle enterprise edition, but they probably don't, and could get by just fine with AWS Aurora which would save money. This plays into the same themes as the previous section around making it simple, we want to reduce choice intelligently, without stifling innovation. One thing that is very important is tagging all your resources to make cost allocation easier (this is very much a governance goal!). Another thing that will help is creating a standard for how to express the business value of a project. Make that model so it includes things like opportunity cost if another platform was used which would cost more development time, and the value of specific features of common platforms to the specific project and how they influence the business value of the project. Yes it can be difficult, but it lets you make informed decisions about what to allow, where and when to allow it, and why, based on what's best for the business.\n\nFinally, we get to the third high level governance goal, make it secure. This is where I'd like to draw on the previous two sections to draw out some important ideas. Governance always prioritizes simplicity, visibility, and compliance. These are especially important to securing multiple environments. We want to take a two-pronged approach. We want to intelligently limit peoples options at the front end so that obeying the rules is the easy option. You also want to have visibility on whom is doing what so we can ensure people are making compliant decisions. If we go back through nearly every point made in the previous two paragraphs it is possible to draw a corollary to how that governance goal improves our ability to secure the environment. A simple example includes how limiting our OS standards makes it easier to patch, harden, and monitor activity on those operating systems. Standardizing identity providers and having a standard view of network information allow you to more easily understand the who and where of actions being taken. Reducing the deployment options in dev for cost control purposes also reduces the types of acceptable events you expect to see in your SIEM (security incident and event management) solution which drastically simplifies your security engineers work. By making the environment simpler and easier to understand for an engineer or architect, the entire security discussion becomes far easier to have.\n\nWhile there are a ton of specific examples I could hit at this point, I think it's best to close here. By thinking of governance as the act of defining and enforcing policies and standards that make management easier, you can really focus at the front end on creating the right balance between choice and simplicity. One word of warning, don't let the perfect be the enemy of the good here. There will be valid exceptions to the rule, and defining how to determine when an exception is warranted is a very important piece of your governance strategy.\n\nI hope you found this useful, and I wish you the best of luck in making your cloud experience easier, cheaper, and more secure!", 
            "subreddit": "aws", 
            "title": "AWS Governance Concepts and Best Practices", 
            "url": "https://www.reddit.com/r/aws/comments/6zo12r/aws_governance_concepts_and_best_practices/"
        }, 
        {
            "author": "ydereky", 
            "created_utc": 1505232808.0, 
            "domain": "aws.amazon.com", 
            "id": "6znzbg", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6znzbg/unite_realtime_and_batch_analytics_using_the_big/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Unite Real-Time and Batch Analytics Using the Big Data Lambda Architecture, Without Servers!", 
            "url": "https://aws.amazon.com/blogs/big-data/unite-real-time-and-batch-analytics-using-the-big-data-lambda-architecture-without-servers/"
        }, 
        {
            "author": "azatoth", 
            "created_utc": 1505232787.0, 
            "domain": "self.aws", 
            "id": "6znz7p", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6znz7p/\u03bb_nodejs_8/", 
            "score": 3, 
            "selftext": "As Beanstalk supports Node.js 8 [since July 21](https://aws.amazon.com/about-aws/whats-new/2017/07/aws-elastic-beanstalk-now-supports-go-1-8-and-node-js-version-8/) I do wonder if we'll have to wait until [March](https://aws.amazon.com/about-aws/whats-new/2017/03/aws-lambda-supports-node-js-6-10/)/[April](https://aws.amazon.com/about-aws/whats-new/2016/04/aws-lambda-supports-node-js-4-3/) for them to offer Node.js 8 for \u03bb", 
            "subreddit": "aws", 
            "title": "\u03bb + Node.js 8", 
            "url": "https://www.reddit.com/r/aws/comments/6znz7p/\u03bb_nodejs_8/"
        }, 
        {
            "author": "Tridente", 
            "created_utc": 1505231716.0, 
            "domain": "reddit.com", 
            "id": "6znuqd", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6znuqd/any_aws_partners_want_to_contribute_their/", 
            "score": 9, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Any AWS partners want to contribute their thoughts on the Rackspace + Datapipe deal?", 
            "url": "https://www.reddit.com/r/awspartners/comments/6znugw/what_is_the_sentiment_on_the_rackspace_datapipe/"
        }, 
        {
            "author": "tucho77", 
            "created_utc": 1505226579.0, 
            "domain": "self.aws", 
            "id": "6znatu", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6znatu/migrating_firebase_to_aws_possible/", 
            "score": 3, 
            "selftext": "I have a Web App developed in node+angular hosted in firebase. Is it possible to migrate to amazon somehow simply and without losing data?", 
            "subreddit": "aws", 
            "title": "Migrating Firebase to AWS, possible?", 
            "url": "https://www.reddit.com/r/aws/comments/6znatu/migrating_firebase_to_aws_possible/"
        }, 
        {
            "author": "JoeShmoe999", 
            "created_utc": 1505221180.0, 
            "domain": "self.aws", 
            "id": "6zms5y", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zms5y/ecs_security_isolation/", 
            "score": 2, 
            "selftext": "Im very new to ECS so can i ask a few questions, esp around how AWS handles multiple container images on one EC2 instance\n\nSo assume we write a task definition that defines one or multiple containers. As i understand it, all containers defined in one ECS task are deployed onto the same instance. Even if the cluster has many instances all containers defined in a single task are located on the same EC2 instance.\n\nSo how do the containers on the one image connect? How are they isolated? Do they share the same EC2 IP addresses, security groups, EBS volumes etc? Do they support EBS encryption ?", 
            "subreddit": "aws", 
            "title": "ECS Security / Isolation", 
            "url": "https://www.reddit.com/r/aws/comments/6zms5y/ecs_security_isolation/"
        }, 
        {
            "author": "w3llus", 
            "created_utc": 1505214608.0, 
            "domain": "self.aws", 
            "id": "6zm9qi", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zm9qi/lambda_job_running_but_ebs_and_amis_not_removing/", 
            "score": 1, 
            "selftext": "Hi all\n\nI have 2 lambda scripts on a cron job, one to create snaps, the other to delete them\nCreate:\nhttps://pastebin.com/PG0myjKp\n\nDelete:\nhttps://pastebin.com/qhuavA8p\n\nThe create snapshot and AMI's is working without issues. But today checking the count of snaps in EC2, i have noticed there were 1200 (typically should be 400 odd.  These scripts had been working flawlessly for months previously\n\nThe delete lambda script works on a retention period of 7 days per instance and the associated EBS volumes.  I cannot for the life of me find out what is causing the script not to work.\n\nIs anyone able to help debug where i have gone wrong?\n\nThanks\nNick", 
            "subreddit": "aws", 
            "title": "Lambda job running but EBS and AMI's not removing even though jobs are successful", 
            "url": "https://www.reddit.com/r/aws/comments/6zm9qi/lambda_job_running_but_ebs_and_amis_not_removing/"
        }, 
        {
            "author": "VIDGuide", 
            "created_utc": 1505211761.0, 
            "domain": "self.aws", 
            "id": "6zm3b2", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zm3b2/aws_connect_webrtc_connection_problems/", 
            "score": 1, 
            "selftext": "I get:\nBrowser unable to establish media channel with turn:13.210.2.244:3478?\ntransport=udp turn:13.210.2.205:3478?transport=udp\n\nNo matter what I do, I can't get past this. Firewall has no port blocking rules, not seeing any blocked traffic. \n\nFirewall is Sophos UTM, and using chrome on MacOS. Any ideas where to start?", 
            "subreddit": "aws", 
            "title": "AWS Connect: WebRTC connection problems", 
            "url": "https://www.reddit.com/r/aws/comments/6zm3b2/aws_connect_webrtc_connection_problems/"
        }, 
        {
            "author": "kmbd", 
            "created_utc": 1505208203.0, 
            "domain": "self.aws", 
            "id": "6zlvla", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zlvla/eli5_what_is_this_new_networkloadbalancers_benefit/", 
            "score": 13, 
            "selftext": "I roughly went through the AWS' doc: https://aws.amazon.com/blogs/aws/new-network-load-balancer-effortless-scaling-to-millions-of-requests-per-second/\n\nbut, for most part, it went over my head. Can some please give me a noob-friendly version? What possible boost we can get from the feature?\n\nFor the context, we use around 30 ec2 instances, some of them serve as ELB-fied application servers (mostly TCP traffic). Some of the rest act as WebRTC hosts serving around 100 Mbps (mostly UDP) traffic.", 
            "subreddit": "aws", 
            "title": "ELI5: What is this new network-load-balancer's benefit ?", 
            "url": "https://www.reddit.com/r/aws/comments/6zlvla/eli5_what_is_this_new_networkloadbalancers_benefit/"
        }, 
        {
            "author": "1252947840", 
            "created_utc": 1505200529.0, 
            "domain": "self.aws", 
            "id": "6zlfpl", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zlfpl/clean_up_account/", 
            "score": 3, 
            "selftext": "Does anyone know is there any way we can clean up an account?\nResources I want to remove basically is everything that has been provisioned. (S3, EC2, Lambda, everything)\n\nI've tried search and saw the boto3 python script but that only clean up certain resources. Other than just delete an account, there's no way I can remove all the resources directly?", 
            "subreddit": "aws", 
            "title": "Clean up account", 
            "url": "https://www.reddit.com/r/aws/comments/6zlfpl/clean_up_account/"
        }, 
        {
            "author": "solidav", 
            "created_utc": 1505196468.0, 
            "domain": "pages.awscloud.com", 
            "id": "6zl6ao", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zl6ao/sap_on_aws_how_uct_is_experiencing_better/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "SAP on AWS: How UCT is Experiencing Better Performance on AWS While Saving 60% in Infrastructure Costs", 
            "url": "https://pages.awscloud.com/migration-mactores-sept2017.html"
        }, 
        {
            "author": "jeffbarr", 
            "created_utc": 1505180093.0, 
            "domain": "self.aws", 
            "id": "6zjvgx", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 14, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zjvgx/back_in_a_week/", 
            "score": 95, 
            "selftext": "Hi all, I had some sinus/nasal surgery last Friday and i am supposed to take things really easy for a week or two (i actually managed to get a \"No email. No blogging. \" prescription from my surgeon). Given that my colleagues lurk here and have threatened to have my wife take my phone away if I do too much posting,  I'll do my best to relax and to start thinking about the long climb to re:Invent this week.", 
            "subreddit": "aws", 
            "title": "Back in a Week", 
            "url": "https://www.reddit.com/r/aws/comments/6zjvgx/back_in_a_week/"
        }, 
        {
            "author": "hhh02000", 
            "created_utc": 1505166111.0, 
            "domain": "self.aws", 
            "id": "6zijai", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zijai/migrating_nexusartifactory_to_aws/", 
            "score": 5, 
            "selftext": "I need to move a Nexus & Artifactory repos to AWS and I'm trying to figure out the best way to do this. Are there any tools/services that you guys recommend? ", 
            "subreddit": "aws", 
            "title": "Migrating Nexus/Artifactory to AWS", 
            "url": "https://www.reddit.com/r/aws/comments/6zijai/migrating_nexusartifactory_to_aws/"
        }, 
        {
            "author": "jon1228", 
            "created_utc": 1505152913.0, 
            "domain": "self.aws", 
            "id": "6zh3o4", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zh3o4/searching_through_s3_for_pii/", 
            "score": 4, 
            "selftext": "Hey all - does anyone have a good method for searching for data within S3 for information within objects, or any suggestions for how it could be done? I have some clients that are concerned that there may be sensitive information that they've inadvertently stored within S3. I know Macie has some of this functionality, but is there an open source tool of some sort just to do an initial scan to see if this is an issue?", 
            "subreddit": "aws", 
            "title": "Searching through S3 for PII", 
            "url": "https://www.reddit.com/r/aws/comments/6zh3o4/searching_through_s3_for_pii/"
        }, 
        {
            "author": "speckz", 
            "created_utc": 1505149284.0, 
            "domain": "linuxacademy.com", 
            "id": "6zgpcb", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "article", 
            "link_flair_text": "article", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zgpcb/troubleshooting_ec2_connectivity_issues/", 
            "score": 8, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Troubleshooting EC2 Connectivity Issues", 
            "url": "https://linuxacademy.com/blog/amazon-web-services-2/troubleshooting-ec2-connectivity-issues/"
        }, 
        {
            "author": "silviadoomra", 
            "created_utc": 1505146064.0, 
            "domain": "aws.amazon.com", 
            "id": "6zgcq3", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zgcq3/how_to_use_ssl_with_the_aws_schema_conversion/", 
            "score": 5, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "How to Use SSL with the AWS Schema Conversion Tool Data Extractors", 
            "url": "https://aws.amazon.com/blogs/database/how-to-use-ssl-with-the-aws-schema-conversion-tool-data-extractors/"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1505145886.0, 
            "domain": "self.aws", 
            "id": "6zgc14", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 23, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zgc14/is_the_20_exam_guru_worth_it_for_the_solutions/", 
            "score": 18, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Is the $20 Exam Guru worth it for the solutions architect exam?", 
            "url": "https://www.reddit.com/r/aws/comments/6zgc14/is_the_20_exam_guru_worth_it_for_the_solutions/"
        }, 
        {
            "author": "Oscady", 
            "created_utc": 1505139662.0, 
            "domain": "self.aws", 
            "id": "6zfoj8", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zfoj8/issue_setting_up_lambda_with_api_gateway/", 
            "score": 7, 
            "selftext": "I have been trying to set up an api to access twitter data from AWS Lambda and can't get past authentication. I'm being given the following error message when testing my code and hoping someone here can help..\n\n{\n  \"errorMessage\": \"Cannot find module 'sshpk'\",\n  \"errorType\": \"Error\",\n  \"stackTrace\": [\n    \"Function.Module._load (module.js:417:25)\",\n    \"Module.require (module.js:497:17)\",\n    \"require (internal/module.js:20:19)\",\n    \"Object.<anonymous> (/var/task/node_modules/http-signature/lib/utils.js:4:13)\",\n    \"Module._compile (module.js:570:32)\",\n    \"Object.Module._extensions..js (module.js:579:10)\",\n    \"Module.load (module.js:487:32)\",\n    \"tryModuleLoad (module.js:446:12)\",\n    \"Function.Module._load (module.js:438:3)\",\n    \"Module.require (module.js:497:17)\",\n    \"require (internal/module.js:20:19)\",\n    \"Object.<anonymous> (/var/task/node_modules/http-signature/lib/parser.js:5:13)\",\n    \"Module._compile (module.js:570:32)\",\n    \"Object.Module._extensions..js (module.js:579:10)\",\n    \"Module.load (module.js:487:32)\"\n  ]\n}\n\nHopefully I've included enough info to make sense appologies if not, this is the first time I've tried accessing anything other than from S3", 
            "subreddit": "aws", 
            "title": "Issue setting up Lambda with API gateway", 
            "url": "https://www.reddit.com/r/aws/comments/6zfoj8/issue_setting_up_lambda_with_api_gateway/"
        }, 
        {
            "author": "shipwrecked__", 
            "created_utc": 1505137956.0, 
            "domain": "self.aws", 
            "id": "6zfimy", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zfimy/restoring_from_glacier_to_ec2/", 
            "score": 2, 
            "selftext": "I have a question hoping someone can help me with. One of our guys we work with uploaded our veeam backups into Glacier using fastglacier. Unfortunately, now comes a time where we need to actually restore these. What is the best way to do this? Can we just launch an EC2 instance with veeam and fastglacier to restore to an additional volume? Will this restore be free as they are in the same AWS region? Is there another way or best practice to do this kind of restore? We do not have any S3 buckets, or anything else, just a vault within Glacier at the moment.\n\nThe business does not want to download the files from FastGlacier to our on-prem Veeam server due to the cost. The guy who set up this solution believes downloading the files via the FastGlacier client on the EC2 server will not incur any costs.\n\nThanks in advance! \n\n\nEDIT: I think I found the answer...\nWe charge less where our costs are less. Some prices vary across Amazon Glacier Regions and are based on the location of your vault. There is no Data Transfer charge for data transferred between Amazon EC2 and Amazon Glacier within the same Region. Data transferred between Amazon EC2 and Amazon Glacier across all other Regions (e.g. between the Amazon EC2 Northern California and Amazon Glacier US East North Virginia Regions) will be charged at Internet Data Transfer rates on both sides of the transfer.\n\nTLDR: Looks like we CAN use the Glacier client to download the backups for *free on to a VM we have in EC2 as long as it is in the same region (it will be). We will have to pay for the VM we set up and use, plus the EBS used to house the backup files.", 
            "subreddit": "aws", 
            "title": "Restoring from Glacier to EC2?", 
            "url": "https://www.reddit.com/r/aws/comments/6zfimy/restoring_from_glacier_to_ec2/"
        }, 
        {
            "author": "Lulizarti", 
            "created_utc": 1505136170.0, 
            "domain": "self.aws", 
            "id": "6zfcyc", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 29, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zfcyc/unreasonable_amount_of_failed_02_status_checks_ec2/", 
            "score": 7, 
            "selftext": "Our company has had 10 instances completely fail 0/2 status checks in the past month in us-east-1 AZ B C D. We enabled Auto-healing to see if it would actually help, and shockingly (/s), it didn't help. Once instances reach 0/2 you can't even stop them. So auto-healing sits in a stop loop never able to full do it's job. \n\nWhat can we do? This feels a little out of the ordinary on failures. The amount of instances ,10ish out of 200+, in the past 3 weeks that had to be reprovisioned is getting insane. We recently migrated to VPC from EC2 Classic. We went 2 months without 1 failed instance in EC2 Classic. 3 weeks since migration, the 10 mentions above.\n\nIf we didn't use OpsWorks our client's websites would be done for hours instead of 30-60m depending on how long it takes our team to get to a computer to relaunch a stack. Amazon keeps telling us we need to use LB and auto-scaling, but due to the nature of what we host that isn't feasible without a MAJOR overhaul.", 
            "subreddit": "aws", 
            "title": "Unreasonable Amount of Failed 0/2 Status Checks EC2?", 
            "url": "https://www.reddit.com/r/aws/comments/6zfcyc/unreasonable_amount_of_failed_02_status_checks_ec2/"
        }, 
        {
            "author": "FixingNix", 
            "created_utc": 1505130018.0, 
            "domain": "self.aws", 
            "id": "6zetr2", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 20, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zetr2/reinvent_question/", 
            "score": 11, 
            "selftext": "I have my registration and travel in place for re:Invent but I can't figure out how to register for the sessions I want to attend. Other conferences I've been too you can make a schedule and register for a guaranteed seat. This one, I can just hit the 'favorites' button but can't register. What am I missing?\n\nThanks!", 
            "subreddit": "aws", 
            "title": "Re:Invent question", 
            "url": "https://www.reddit.com/r/aws/comments/6zetr2/reinvent_question/"
        }, 
        {
            "author": "sterlingarcher79", 
            "created_utc": 1505127964.0, 
            "domain": "self.aws", 
            "id": "6zeojs", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zeojs/whats_the_best_way_to_learn_cli/", 
            "score": 7, 
            "selftext": "Be gentle. I'm currently working with AWS, using the GUI for my daily needs but I do believe that migrating my operations knowledge to CLI could make me more productive and even open my mind to new opportunities. I have a background in IT, but I'm not a programmer. I have basic skills in this field but would like to enhance them when it comes to CLI. What would be a good starting point (resources)?", 
            "subreddit": "aws", 
            "title": "What's the best way to learn CLI?", 
            "url": "https://www.reddit.com/r/aws/comments/6zeojs/whats_the_best_way_to_learn_cli/"
        }, 
        {
            "author": "foshiee", 
            "created_utc": 1505122515.0, 
            "domain": "self.aws", 
            "id": "6zecei", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zecei/using_ec2_ssm_with_managed_instances/", 
            "score": 5, 
            "selftext": "Greetings AWS subreddit,\n\nI am evaluating AWS EC2 Simple Systems Manager Patch Management for Windows Update on our on-prem Windows Server VMs. \n\nAt the moment my company just uses GPO to manage Windows Updates on these machines, which doesn't allow one to automatically approve/deny patches based on set criteria, or schedule maintenance windows. SSM has a one up on WSUS in the fact that it supports maintenance windows. \n\nBut apart from that, what other benefits does using SSM have over WSUS? I haven't yet found out if it is possible to patch other Microsoft applications with SSM (such as SQL and Exchange) or if you can patch third-party applications using it. Does anybody know if this is feasible/possible, perhaps through custom Documents or something? I know you an install .msi applications with one of the already existing AWS Documents. \n\nI guess my question is this:\n\nWhich ways, if any, can you think of that SSM is better at patching on-prem Windows Servers than WSUS, can I use it to update other Microsoft and third-party applications, how easy is it to check compliance and which patches are missing, and are there any other useful, awesome things that SSM can allow me to do on Managed Instances?\n\nCheers,\nFoshiee", 
            "subreddit": "aws", 
            "title": "Using EC2 SSM with Managed Instances", 
            "url": "https://www.reddit.com/r/aws/comments/6zecei/using_ec2_ssm_with_managed_instances/"
        }, 
        {
            "author": "behrangsa", 
            "created_utc": 1505118431.0, 
            "domain": "self.aws", 
            "id": "6ze3vc", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ze3vc/looking_for_a_way_to_limit_the_incoming_bandwidth/", 
            "score": 15, 
            "selftext": "Hi,\n\nI have an app on an EC2 instance that continuously polls and fetches data from a server in our on-prem data center over a Direct Connect connection.\n\nI am looking for a way to make sure this app is not getting more than, say, 1MB/s of incoming data bandwidth to make sure it does not saturate our Direct Connect connection. \n\nI can implement this functionality in the app, but are there any other proven alternatives available that do not require modifying the app?\n\nOne possible option could be to use [trickle](https://linux.die.net/man/1/trickle). Are there any other options that you can recommend?\n\nThanks.", 
            "subreddit": "aws", 
            "title": "Looking for a way to limit the incoming bandwidth of an EC2 instance. Any recommendations?", 
            "url": "https://www.reddit.com/r/aws/comments/6ze3vc/looking_for_a_way_to_limit_the_incoming_bandwidth/"
        }, 
        {
            "author": "tmt_game", 
            "created_utc": 1505118347.0, 
            "domain": "self.aws", 
            "id": "6ze3pt", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ze3pt/is_there_any_downside_to_buy_a_noupfront_1_year/", 
            "score": 2, 
            "selftext": "I am basically comparing a All up-front RI for 1 year vs no-upfront RI for the same duration. \n\nUsing t2.medium as an example, All upfront 's effective rate is 0.031 whereas no upfront is 0.034. \n\nNo upfront is actually quite an attractive option because I don't have a large cash outlay at the beginning and the hourly rate is not that hugely different. I am tempted to go with no upfront.\n\nIs my reasoning/understanding sound? Is there any catch in my consideration? \n\n\nI always have a fixed number of ec2 instances running because I am using ec2 instance to build ecs clusters.", 
            "subreddit": "aws", 
            "title": "Is there any downside to buy a no-upfront 1 year reserved instance?", 
            "url": "https://www.reddit.com/r/aws/comments/6ze3pt/is_there_any_downside_to_buy_a_noupfront_1_year/"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1505097409.0, 
            "domain": "self.aws", 
            "id": "6zconx", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zconx/why_cant_i_reuse_the_same_rdp_file_to_connect_to/", 
            "score": 3, 
            "selftext": "Is there something I can do to allow this, so I don't have to download a new RDP file every time?  I don't seem to have to do that with Azure VM's.", 
            "subreddit": "aws", 
            "title": "Why can't I reuse the same RDP file to connect to my Windows EC2 instances after restart?", 
            "url": "https://www.reddit.com/r/aws/comments/6zconx/why_cant_i_reuse_the_same_rdp_file_to_connect_to/"
        }, 
        {
            "author": "sipsaap", 
            "created_utc": 1505066516.0, 
            "domain": "self.aws", 
            "id": "6z9rlj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6z9rlj/codedeploy_deployment_configuration_comparison/", 
            "score": 1, 
            "selftext": "I've started using AWS CodeDeploy and was looking at the 3 deployment configurations ( http://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html )\n\nPersonally, I would probably go with the 'one-at-a-time' approach, that fails if any deployments should fail, but I'm sure there are plenty of reasons to go with the other two approaches.\n\nCan anyone explain the different situations, where each strategy might be the preferred choice? When and why would you choose one deployment configuration over another?", 
            "subreddit": "aws", 
            "title": "CodeDeploy Deployment Configuration Comparison", 
            "url": "https://www.reddit.com/r/aws/comments/6z9rlj/codedeploy_deployment_configuration_comparison/"
        }, 
        {
            "author": "Guchelkaben", 
            "created_utc": 1505060756.0, 
            "domain": "self.aws", 
            "id": "6z96ks", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6z96ks/api_call_for_services/", 
            "score": 2, 
            "selftext": "Hi guys,\n\nI will program a tool which illustrates all my services with the real time traffic. Is there an API to fetch this data? I am looking for 2 hours now and I haven't found anything about this topic.\n\nFor instance:\n\nGet call to get all my running instances, or get all packages which arrived to an endpoint. Is there an API for this?\n\nMany thanks", 
            "subreddit": "aws", 
            "title": "API call for services", 
            "url": "https://www.reddit.com/r/aws/comments/6z96ks/api_call_for_services/"
        }, 
        {
            "author": "nikhilb_it", 
            "created_utc": 1505059492.0, 
            "domain": "bluepiit.com", 
            "id": "6z91xt", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6z91xt/how_to_automate_ami_backups_and_cleanups_using/", 
            "score": 11, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "How to Automate AMI Backups and Cleanups, using AWS Lambda (Serverless), with EC2 Tags", 
            "url": "https://www.bluepiit.com/blog/how-to-automate-ami-backups-cleanups-using-aws-lambda-serverless-with-ec2-tags/"
        }, 
        {
            "author": "speckz", 
            "created_utc": 1505048238.0, 
            "domain": "read.acloud.guru", 
            "id": "6z836w", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "article", 
            "link_flair_text": "article", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6z836w/the_secret_sauce_behind_amazon_route53/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "The secret sauce behind Amazon Route53", 
            "url": "https://read.acloud.guru/the-secret-sauce-behind-amazon-route53-dae2573293c6"
        }, 
        {
            "author": "amitm02", 
            "created_utc": 1505047951.0, 
            "domain": "self.aws", 
            "id": "6z82jb", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6z82jb/best_practice_to_store_users_plan_and_control/", 
            "score": 1, 
            "selftext": "Assume I have a web app application and I use aws cognito users-pool to manage my users. Also assume some of the users are just \"Guests\", some are in a \"Regular\" paid plan and some are under \"Premium\" paid plan.\n\nWhere is the best place to store the users plan information? Is it better to store it as a Cognito user attribute or in some key:value DB (e.g Dynamodb)?\n\nHow should I control what a user can do according to his plan? Should i check the user ID against his \"plan type\" value in Cognito user pool/DB for each http request he makes to the server? Is there a cheaper (resource wise) way to accomplish this?\n\nThanks", 
            "subreddit": "aws", 
            "title": "Best practice to store users \u201cplan\u201d and control their permission in AWS Cognito", 
            "url": "https://www.reddit.com/r/aws/comments/6z82jb/best_practice_to_store_users_plan_and_control/"
        }, 
        {
            "author": "anonwipq", 
            "created_utc": 1505042209.0, 
            "domain": "businessinsider.in", 
            "id": "6z7pts", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 75, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6z7pts/a_certificate_in_amazons_aws_cloud_technology_can/", 
            "score": 106, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "A certificate in Amazon's AWS cloud technology can boost your salary by 26%", 
            "url": "http://www.businessinsider.in/A-certificate-in-Amazons-AWS-cloud-technology-can-boost-your-salary-by-26/articleshow/60439808.cms?utm_source=social_Reddit&utm_medium=social_sharing&utm_campaign=Click_through_social_share"
        }, 
        {
            "author": "slipdexic", 
            "created_utc": 1505041264.0, 
            "domain": "self.aws", 
            "id": "6z7nz9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6z7nz9/protecting_aws_cli_credentials_with_mfa_question/", 
            "score": 4, 
            "selftext": "I'm looking way to use AWS CLI from either Windows or MacBook . I do not want to store the keys locally but  instead request a set of temporary session credentials , assuming the relevant role that would be assigned.\n\nMy idea is to run an app enter some credentials and MFA , that then calls something like GetSessionTokenRole and sets up the CLI for use.\nThe creds can then expire after a few hours .\n\nI'm sure there must already be a solution out there before I go off and re invent the wheel.\n", 
            "subreddit": "aws", 
            "title": "Protecting AWS CLI credentials with MFA question.", 
            "url": "https://www.reddit.com/r/aws/comments/6z7nz9/protecting_aws_cli_credentials_with_mfa_question/"
        }, 
        {
            "author": "shesnothing", 
            "created_utc": 1505011164.0, 
            "domain": "self.aws", 
            "id": "6z5wt2", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 25, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6z5wt2/can_someone_explain_to_me_how_cloudfront_works/", 
            "score": 3, 
            "selftext": "Can someone explain to me how CloudFront works? Everytime I look for jobs on my iPhone or Mac on Indeed.com I get a \"________\".cloudfront.net cache with random numbers and letters? I'm dumb.\n\nSometimes I think I have a virus on both my Apple products because of the CloudFront cache but then again I'm dumb AF. \n\nThanks", 
            "subreddit": "aws", 
            "title": "Can someone explain to me how CloudFront works? Everytime I look for jobs on my iPhone or Mac on Indeed.com I get a \"________\".cloudfront.net cache with random numbers and letters? I'm dumb.", 
            "url": "https://www.reddit.com/r/aws/comments/6z5wt2/can_someone_explain_to_me_how_cloudfront_works/"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1504983413.0, 
            "domain": "self.aws", 
            "id": "6z3hog", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6z3hog/is_sni_that_difficult_to_integrate_with/", 
            "score": 7, 
            "selftext": "I'm attempting to work with a vendor, FastSpring, and so far I have been waiting for them for about a year now to implement SNI on their end to be able to call API Gateway when an order comes through via their Webhook.  Every time I email them they said they're working on it, or they're testing it, or something.  Is it really THAT hard to do??", 
            "subreddit": "aws", 
            "title": "Is SNI that difficult to integrate with?", 
            "url": "https://www.reddit.com/r/aws/comments/6z3hog/is_sni_that_difficult_to_integrate_with/"
        }, 
        {
            "author": "Wallblacksheep", 
            "created_utc": 1504980716.0, 
            "domain": "self.aws", 
            "id": "6z388v", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6z388v/getting_instance_ids_via_aws_cli/", 
            "score": 15, 
            "selftext": "Is there a better way to retrieve all ec2 instance id's via the cli? I have been using:\n\n```\naws ec2 describe-instances\n```\n\nbut that prints the entire object.", 
            "subreddit": "aws", 
            "title": "getting instance ids via aws cli", 
            "url": "https://www.reddit.com/r/aws/comments/6z388v/getting_instance_ids_via_aws_cli/"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1504935452.0, 
            "domain": "self.aws", 
            "id": "6z03h1", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 15, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6z03h1/cant_join_ec2_windows_instance_to_active/", 
            "score": 0, 
            "selftext": "I created two EC2 Windows instances.  I made one of them the Active Directory Primary Domain Controller.  All seems to have went fine there.  The domain is \"test.local\".  However, I am unable to join the \"test.local\" domain from the other EC2 instance.  It tells me \"An Active Directory Domain Controller (AD DC) for the domain test.local could not be contacted.\n\nThey both appear to be in the same VPC.  Is there something else I'm missing that needs to be done to enable other instances in the same VPC to join the domain of the primary domain controller?\n\nUpdate:  It seems I can't even ping test.local (or the IP address of the DC) from machine 2, but I can ping test.local from the domain controller.  so maybe I'm missing something with DNS??", 
            "subreddit": "aws", 
            "title": "Can't join EC2 Windows instance to Active Directory Domain (another EC2 Windows instance)", 
            "url": "https://www.reddit.com/r/aws/comments/6z03h1/cant_join_ec2_windows_instance_to_active/"
        }, 
        {
            "author": "DB_CONNECTION_ERROR", 
            "created_utc": 1504927613.0, 
            "domain": "self.aws", 
            "id": "6yzkm2", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yzkm2/resources_for_somebody_very_new/", 
            "score": 11, 
            "selftext": "TL;DR  Work for a small/medium company that wants to make big leap to AWS - I'm a mediocre developer, not an IT person, but need to learn how to create an AWS based infrastructure (VPC,VPN,EC2,etc) as fast as possible.  \n\nLong version only slightly longer - so I\"m a software dev, not typically an IT guy, but it has kind of fell to me (and I want to learn) how to property architect, design, implement, and secure an AWS based infrastructure that will eventually handle a couple of load balanced web servers, a SQL Server, a few REDIS boxes, and developer machines.  \n\nIt's not to say I can't figure this out on my own, but it's outside of my comfort zone, and I'd really like to know I'm doing it correctly while getting it done as quickly as possible.  \n\nAny suggestions on resources or hands-on learning that will get me there quick?\n\nAnd no, so far getting paid AWS architecture training has been a no-go.  ", 
            "subreddit": "aws", 
            "title": "Resources for somebody very new?", 
            "url": "https://www.reddit.com/r/aws/comments/6yzkm2/resources_for_somebody_very_new/"
        }, 
        {
            "author": "pleegor", 
            "created_utc": 1504915714.0, 
            "domain": "self.aws", 
            "id": "6yymqy", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yymqy/managing_security_groups/", 
            "score": 2, 
            "selftext": "Hi everyone!\n\nI am looking for tool which will allow me to manage security groups (not from the AWS Console); something similar to https://github.com/coinbase/demeter with integration for source control. How do you manage those groups and make sure you know what/when was changed? Thanks!", 
            "subreddit": "aws", 
            "title": "Managing Security Groups", 
            "url": "https://www.reddit.com/r/aws/comments/6yymqy/managing_security_groups/"
        }, 
        {
            "author": "wetpaste", 
            "created_utc": 1504912136.0, 
            "domain": "self.aws", 
            "id": "6yybcp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yybcp/best_practice_for_the_following_scenario_iam/", 
            "score": 2, 
            "selftext": "I am trying to figure out the \"correct\" way to accomplish this task.\n\nI need to create an IAM user that can do the following:\n\n* create unlimited S3 Buckets\n* create unlimited IAM users and generate secret key and access key\n* attach a policy to the bucket\n* Cannot access any other S3 buckets in the account, only the ones it creates.\n* cannot manage any other IAM users in the account.\n\nIs there a clean way to do this? Should I just be making a new account with it's own ownership and all that? I would like to avoid that because I would like to be able to view all resources and billing globally, and have the option of giving it control over other resources in the future (deploy and manage EC2 instances, for example)\n\nI think I need to be an admin to create users and attach policies, is there a way around this, or to make sure those resources isolated from the global resources the main account has access to?\n\nI'm not sure if I'm asking the right questions here.\n\n\nEDIT: I'm looking at AWS organizations and I am thinking that might be the easiest way to do this kind of thing. My only worry is that I'm not sure that will allow me to merge resources from two accounts later. Say I want to give it access to a different set of buckets later? https://aws.amazon.com/blogs/aws/category/aws-organizations/", 
            "subreddit": "aws", 
            "title": "Best Practice for the following scenario? IAM limited admin?", 
            "url": "https://www.reddit.com/r/aws/comments/6yybcp/best_practice_for_the_following_scenario_iam/"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1504910808.0, 
            "domain": "self.aws", 
            "id": "6yy6sp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yy6sp/building_windows_test_environment_with_on_prem/", 
            "score": 1, 
            "selftext": "I will be building out a test lab utilizing Windows based EC2 instances.  The lab will contain at minimal Active Directory, SQL Server and SharePoint.  I have an MSDN Universal subscription so I will be bringing my own licenses.  The important thing to note here is I will not be using any AWS managed services, like RDS, it will essentially be mimicking an on premise installation.\n\n1) What is the best strategy for reducing costs when not in use?  Do I get charged for my instances that are not currently running?\n\n2) What is the best strategy for making snapshots of either the complete environment (Active Directory, SQL Server, and SharePoint, each on it's own server) or any one or combination of each instance at a given point in time and then readily be able to hydrate said snapshot?\n\n3) Probably somewhat related to the above, what is the best strategy for starting completely over from the base/clean install of each instance so I don't have to manually recreate/install/configure each one if needed?\n\n4) Again, probably somewhat related to the above, what is the best strategy for making the snapshots of each service be easily portable to different EC2 Instance types so I can test out on different hardware configurations?\n\n5) Are there any networking utilities or services native to AWS that will allow me to simulate latency between each server?  \n\nAny help on the above would be greatly appreciated.  \n\nThanks!", 
            "subreddit": "aws", 
            "title": "Building Windows test environment with \"on prem\" Active Directory. Several questions.", 
            "url": "https://www.reddit.com/r/aws/comments/6yy6sp/building_windows_test_environment_with_on_prem/"
        }, 
        {
            "author": "doublemazaa", 
            "created_utc": 1504892514.0, 
            "domain": "self.aws", 
            "id": "6ywblo", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ywblo/i_started_getting_charged_for_s3_puts_from_s3/", 
            "score": 2, 
            "selftext": "I don't use my personal AWS account much. The bill is always around $0.60.\n\nOver the last month, without any changes, my bill jumped to about $1.20.\n\nI tracked the increase to a jump in requests to a bucket that had logging turned on. It looks like they started charging for PUTs from logging. The logging PUTs automatically kicked me over the free tier.\n\nDoes anyone know if this is the correct behavior? ", 
            "subreddit": "aws", 
            "title": "I started getting charged for S3 PUTs from S3 logging service", 
            "url": "https://www.reddit.com/r/aws/comments/6ywblo/i_started_getting_charged_for_s3_puts_from_s3/"
        }, 
        {
            "author": "Dinaek", 
            "created_utc": 1504887777.0, 
            "domain": "self.aws", 
            "id": "6yvtcj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yvtcj/rds_ms_sql_server_is_now_hipaa_compliant/", 
            "score": 21, 
            "selftext": "I don't see any announcements, but reviewing the HIPAA compliant services list, SQL Server is now listed as a compliant engine for RDS!\n\nhttps://aws.amazon.com/compliance/services-in-scope/", 
            "subreddit": "aws", 
            "title": "RDS MS SQL Server is now HIPAA Compliant", 
            "url": "https://www.reddit.com/r/aws/comments/6yvtcj/rds_ms_sql_server_is_now_hipaa_compliant/"
        }, 
        {
            "author": "awsgeek", 
            "created_utc": 1504886498.0, 
            "domain": "i.redd.it", 
            "id": "6yvok7", 
            "is_reddit_media_domain": true, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yvok7/a_visual_summary_of_the_latest_addn_to_the_aws/", 
            "score": 123, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "A visual summary of the latest add'n to the AWS ELB family, the Network Load Balancer. Static IPs, super scalability & source IP visibility!", 
            "url": "https://i.redd.it/csq9nw4gmokz.jpg"
        }, 
        {
            "author": "matizzy", 
            "created_utc": 1504881462.0, 
            "domain": "self.aws", 
            "id": "6yv5lj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yv5lj/rds_max_storage_problems/", 
            "score": 3, 
            "selftext": "Hi, first time posting here. \n\nI've run into an issue where our Postgres DB instance will hit the max storage of 6TB in about a month. \n\nI'm not sure what steps to take to resolve this. We can potentially send off a snapshot to cold storage and wipe the DB, but would like to avoid this. \n\nIs 6TB the absolute limit or can Amazon increase this limit with a support request? \n\nShould we perhaps switch to using SQL server which has a 16TB limit on AWS? ", 
            "subreddit": "aws", 
            "title": "RDS Max Storage Problems", 
            "url": "https://www.reddit.com/r/aws/comments/6yv5lj/rds_max_storage_problems/"
        }, 
        {
            "author": "peimurphy", 
            "created_utc": 1504875534.0, 
            "domain": "self.aws", 
            "id": "6yulcp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yulcp/elasticsearch_vpc_support/", 
            "score": 1, 
            "selftext": "With all the new features & updates coming out from AWS these days, why hasn't this been a priority. I can't believe the number of  services that don't directly connect via an endpoint or or connect to a subnet. Access control via a proxy server is just not a real good solution and updates for Access Control via IP take 15 - 20 min to propagate.\n\nAnyone with any ideas when we might see this ?\n\nJim", 
            "subreddit": "aws", 
            "title": "Elasticsearch VPC Support", 
            "url": "https://www.reddit.com/r/aws/comments/6yulcp/elasticsearch_vpc_support/"
        }, 
        {
            "author": "iamdzyg", 
            "created_utc": 1504873867.0, 
            "domain": "self.aws", 
            "id": "6yugdg", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yugdg/pfsense_on_virtualbox_on_ec2/", 
            "score": 1, 
            "selftext": "Have anyone tried this? \n\nI managed to install virtualbox on ubuntu 16.04 (ubuntu is my aws EC2 instance) and installed pfsense CE version on virtualbox (using FreeBSD 32bit).\n\nThe only issue i have is the WAN of pfsense not able to connect to the internet via ubtuntu eth0 (bridge) using DCHP or static IP within the same subnet of my VPC\n\nAssume that i do not intent to create another instance of pfsense and i need pfsense on the ubtuntu instance.\n\nMy purpose is to use pfsense VPN to build a nested VPN connection.", 
            "subreddit": "aws", 
            "title": "pfsense on virtualbox on ec2", 
            "url": "https://www.reddit.com/r/aws/comments/6yugdg/pfsense_on_virtualbox_on_ec2/"
        }, 
        {
            "author": "Mark5n", 
            "created_utc": 1504871493.0, 
            "domain": "self.aws", 
            "id": "6yu9yc", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yu9yc/advice_on_a_personal_project_data_lake/", 
            "score": 1, 
            "selftext": "Hi, I'm just about to dip my toes into AWS and want to create a small setup to get a feel for things. Ideally I want to try:\n\n * Quick sight - visualisation\n * Hadoop - data (I'll have small datasets but they're samples of much larger sets)\n * R - analysis\n\nIs there a package that ties all this together? Any recommendations? ", 
            "subreddit": "aws", 
            "title": "Advice on a personal project: data lake + visualisation", 
            "url": "https://www.reddit.com/r/aws/comments/6yu9yc/advice_on_a_personal_project_data_lake/"
        }, 
        {
            "author": "schoenhauser_allee", 
            "created_utc": 1504855925.0, 
            "domain": "self.aws", 
            "id": "6ytbyb", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ytbyb/security_group_question_inbound_traffic_rules/", 
            "score": 1, 
            "selftext": "Sorry if it's a dull question - I just want to know if there is anything wrong with the way I have my security groups set up.\n\nI have a default VPC with IPv4 CIDR of 172.31.0.0/16, and I want to create a security group where inbound SSH and MySQL traffic is only allowed from instances from the aforementioned VPC. So, I created a security group with inbound rules for SSH and MySQL with the source defined as 172.31.0.0/16.\n\nIs there anything wrong security-wise with the way I set it up, or is there another way to reference VPCs?", 
            "subreddit": "aws", 
            "title": "Security group question - inbound traffic rules", 
            "url": "https://www.reddit.com/r/aws/comments/6ytbyb/security_group_question_inbound_traffic_rules/"
        }, 
        {
            "author": "mojorojo2", 
            "created_utc": 1504847402.0, 
            "domain": "self.aws", 
            "id": "6ysr4m", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 19, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ysr4m/what_is_the_use_case_for_each_of_the_alb_and_nlb/", 
            "score": 4, 
            "selftext": "My question is basically, what does it mean when they say, request level and connection level. why do we need these listeners on different protocols, when mostly it is serving web content on all HTTP or HTTPS. Why does NLB have no secure connection options, how does one setup HTTPS here? I am very confused.", 
            "subreddit": "aws", 
            "title": "What is the use case for each of the ALB and NLB?", 
            "url": "https://www.reddit.com/r/aws/comments/6ysr4m/what_is_the_use_case_for_each_of_the_alb_and_nlb/"
        }, 
        {
            "author": "covertequation", 
            "created_utc": 1504845840.0, 
            "domain": "self.aws", 
            "id": "6ysmww", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ysmww/ecs_placement_strategy_vs_new_cluster/", 
            "score": 2, 
            "selftext": "I am trying to determine which implementation is better for my use case:\n\nI have ecs containers which have different resource requirements (memory and cpu). In example, one container uses 2 gb of ram, and another 64 gb of ram. For cost savings, I would like to use as few of the bigger ec2 instances as possible. It seems like I could make multiple instance types on the same cluster, and define a placement strategy, or I could just make a new cluster. What's the difference from a management standpoint? Similarly, what if different containers have different security groups needed; it seems like I could use multiple ASG's on a single cluster with placement strategies, or use multiple clusters.", 
            "subreddit": "aws", 
            "title": "ECS Placement Strategy vs new Cluster", 
            "url": "https://www.reddit.com/r/aws/comments/6ysmww/ecs_placement_strategy_vs_new_cluster/"
        }, 
        {
            "author": "behrangsa", 
            "created_utc": 1504839614.0, 
            "domain": "self.aws", 
            "id": "6ys4wy", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "resource", 
            "link_flair_text": "technical resource", 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ys4wy/looking_for_a_sample_cognito_app_with_s3_for/", 
            "score": 1, 
            "selftext": "Basically a very simple HTML page with a link that redirects the user to authenticate with Twitter and when Twitter sends the user back it displays the user details by invoking a Lambda function. \n\nThe user details can be stored in Dynamo or RDS (or anywhere else). \n\nI'm mainly interested in the Cognito related steps. ", 
            "subreddit": "aws", 
            "title": "Looking for a sample Cognito app with S3 for static hosting and Lambda as backend. Any recommendations?", 
            "url": "https://www.reddit.com/r/aws/comments/6ys4wy/looking_for_a_sample_cognito_app_with_s3_for/"
        }, 
        {
            "author": "kgalb2", 
            "created_utc": 1504837144.0, 
            "domain": "self.aws", 
            "id": "6yrxgl", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 16, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yrxgl/what_are_some_s3_lessons_you_have_learned/", 
            "score": 7, 
            "selftext": "I started writing a blog post about some lessons I have learned about S3 (often times the hard way). I was curious if others here of /r/aws have some interesting lessons they have learned about S3. \n\nHere are some I have learned:\n\n* For highly distributed frequent access. Have a good random key prefix for optimal partitioning.\n* Listing operations are generally frowned upon for a lot of keys. It is fine for a few thousands keys.\n* You can extend S3 to do a lot of different things, but that doesn't mean you should. Don't recreate the wheel if you don't have to.\n\nHas anybody else ran into these before?\n\n", 
            "subreddit": "aws", 
            "title": "What are some S3 lessons you have learned?", 
            "url": "https://www.reddit.com/r/aws/comments/6yrxgl/what_are_some_s3_lessons_you_have_learned/"
        }, 
        {
            "author": "tedder42", 
            "created_utc": 1504830325.0, 
            "domain": "self.aws", 
            "id": "6yrb6g", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yrb6g/graphical_interface_to_cloudwatch_logs_kibana_for/", 
            "score": 2, 
            "selftext": "Does anyone know of a decent search/display UI for Cloudwatch Logs? I know of [awslogs](https://github.com/jorgebastida/awslogs) for the commandline, but I want something like Kibana without the redundant architecture of the 'EL' components of ELK.\n\nAWS Elasticsearch doesn't support VPCs which is a dealbreaker, and building my own ELK stack, which I've done in versions 1, 2, and 5, is so redundant when I'm using cwlogs as a primary store.", 
            "subreddit": "aws", 
            "title": "graphical interface to cloudwatch logs? 'kibana for cwlogs'?", 
            "url": "https://www.reddit.com/r/aws/comments/6yrb6g/graphical_interface_to_cloudwatch_logs_kibana_for/"
        }, 
        {
            "author": "DigitalPlumberNZ", 
            "created_utc": 1504829870.0, 
            "domain": "self.aws", 
            "id": "6yr9lf", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yr9lf/loading_flat_files_into_rds_sql_server/", 
            "score": 2, 
            "selftext": "Hi\n\nWe're looking to migrate an existing in-house workload into AWS, using RDS to replace the SQL Server component. However, part of the workload involves daily ingestion of flat files produced by a number of other systems. I'm struggling to find any guidance on how to handle this against RDS SQL Server. Lots of stuff on MySQL's LOAD DATA command, pretty much zero on the SQL Server equivalent.\n\nIs Data Pipeline the way to go? \n\nOr is it better to utilise the EC2 instance that'll make up the other part of the deployment and have it load the files using bcp or another SQL Server tool? I'm not a DB guy, so I don't know, or have to know, precisely how that would be achieved.\n\nCheers", 
            "subreddit": "aws", 
            "title": "Loading flat files into RDS SQL Server", 
            "url": "https://www.reddit.com/r/aws/comments/6yr9lf/loading_flat_files_into_rds_sql_server/"
        }, 
        {
            "author": "jeffbarr", 
            "created_utc": 1504824855.0, 
            "domain": "aws.amazon.com", 
            "id": "6yqsqy", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 55, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yqsqy/network_load_balancer_effortless_scaling_to/", 
            "score": 95, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Network Load Balancer (Effortless Scaling to Millions of RPS)", 
            "url": "https://aws.amazon.com/blogs/aws/new-network-load-balancer-effortless-scaling-to-millions-of-requests-per-second/"
        }, 
        {
            "author": "MattW224", 
            "created_utc": 1504817835.0, 
            "domain": "self.aws", 
            "id": "6yq2r9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yq2r9/aws_sam_vs_serverless_framework/", 
            "score": 3, 
            "selftext": "Curious to poll the /r/aws community. What are you using for your serverless projects?", 
            "subreddit": "aws", 
            "title": "AWS SAM vs. Serverless Framework.", 
            "url": "https://www.reddit.com/r/aws/comments/6yq2r9/aws_sam_vs_serverless_framework/"
        }, 
        {
            "author": "schubes24", 
            "created_utc": 1504813342.0, 
            "domain": "self.aws", 
            "id": "6ypl2d", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ypl2d/rdp_access_to_server_options/", 
            "score": 2, 
            "selftext": "Are there options to allow RDP access to a server besides by allowing certain IP addresses via security groups?  I have 2 app servers not on my network that an oncall group needs to be able to access from outside my network.  Rather than managing their home IP addresses, I'm wondering if there is a different option.  Any help is appreciated.", 
            "subreddit": "aws", 
            "title": "RDP Access to server options", 
            "url": "https://www.reddit.com/r/aws/comments/6ypl2d/rdp_access_to_server_options/"
        }, 
        {
            "author": "sn10therealbatman", 
            "created_utc": 1504807881.0, 
            "domain": "self.aws", 
            "id": "6yozo3", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yozo3/can_i_run_a_facebook_clone_with_1000_user_for_a/", 
            "score": 0, 
            "selftext": "Just a hypothetical question I had while signing up for AWS just now. I am confused by the metrics (no prior experience) so I am trying to get an idea how capable the Free Tier is. Can it run a fb clone or a reddit or a twitter with 1000 users? If not why?\n[X-Post on r/cloudcomputing] (https://www.reddit.com/r/cloudcomputing/comments/6yowwb/can_run_a_facebook_clone_with_1000_user_for_a/)", 
            "subreddit": "aws", 
            "title": "Can I run a facebook clone with 1000 user for a month on AWS Free Tier?", 
            "url": "https://www.reddit.com/r/aws/comments/6yozo3/can_i_run_a_facebook_clone_with_1000_user_for_a/"
        }, 
        {
            "author": "it_happened_here", 
            "created_utc": 1504806168.0, 
            "domain": "self.aws", 
            "id": "6yosvw", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yosvw/amazon_api_gateway_any_way_to_assign_an_api_key/", 
            "score": 7, 
            "selftext": "I've created my API and I've got a Usage Plan set up with API Keys attached to a Stage. I'd like to set an individual Key to work with an individual endpoint instead of ALL endpoints within a Stage. Any way to do this?", 
            "subreddit": "aws", 
            "title": "Amazon API Gateway: Any way to assign an API Key to a specific endpoint?", 
            "url": "https://www.reddit.com/r/aws/comments/6yosvw/amazon_api_gateway_any_way_to_assign_an_api_key/"
        }, 
        {
            "author": "fsmith22", 
            "created_utc": 1504800258.0, 
            "domain": "self.aws", 
            "id": "6yo5of", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yo5of/integration_of_multisite_to_site_vpn/", 
            "score": 1, 
            "selftext": "Currently working on an aws migration where we have an existing fully meshed multi-site environment. Site to site vpn tunnels exist for each site at every site. Anyone tackle this type of architecture? Assuming BGP is the best answer but not sure how to implement in aws.  Do I have to build a vpg for each site?", 
            "subreddit": "aws", 
            "title": "Integration of multi-site to site vpn", 
            "url": "https://www.reddit.com/r/aws/comments/6yo5of/integration_of_multisite_to_site_vpn/"
        }, 
        {
            "author": "xxst1tch3sxx", 
            "created_utc": 1504798598.0, 
            "domain": "self.aws", 
            "id": "6ynz2v", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ynz2v/macie_for_s3_buckets/", 
            "score": 5, 
            "selftext": "Anyone implemented Macie? Any issues with it actually reporting back info?\n\nI've gotten a total of maybe 3 alerts from my test bucket containing info that should surely be firing off alerts left and right. ", 
            "subreddit": "aws", 
            "title": "Macie for S3 buckets", 
            "url": "https://www.reddit.com/r/aws/comments/6ynz2v/macie_for_s3_buckets/"
        }, 
        {
            "author": "crapspakkle", 
            "created_utc": 1504796139.0, 
            "domain": "self.aws", 
            "id": "6ynpia", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 14, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ynpia/how_do_you_rotate_your_access_keys/", 
            "score": 14, 
            "selftext": "I have looked for a Lambda function that can do this but have not had much success.  How are you guys keeping your IAM access keys rotated seamlessly?", 
            "subreddit": "aws", 
            "title": "How do you rotate your access keys?", 
            "url": "https://www.reddit.com/r/aws/comments/6ynpia/how_do_you_rotate_your_access_keys/"
        }, 
        {
            "author": "silviadoomra", 
            "created_utc": 1504792902.0, 
            "domain": "aws.amazon.com", 
            "id": "6yndst", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yndst/database_migration_gaining_momentum/", 
            "score": 6, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Database Migration Gaining Momentum", 
            "url": "https://aws.amazon.com/blogs/database/database-migration-gaining-momentum/"
        }, 
        {
            "author": "kiwifellows", 
            "created_utc": 1504785056.0, 
            "domain": "github.com", 
            "id": "6ymp7p", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ymp7p/v01_beta_just_released_with_improvements_eg_multi/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "V0.1 \"beta\" just released with improvements e.g. Multi Region API Calls via AWS SDK, JMESPath expressions etc...", 
            "url": "https://github.com/teemops/phpawsapi/"
        }, 
        {
            "author": "hydracone", 
            "created_utc": 1504779819.0, 
            "domain": "self.aws", 
            "id": "6ymc1y", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ymc1y/lowest_price_on_the_monthly_bill/", 
            "score": 1, 
            "selftext": "Hello /r/aws, \n\nI just wanted to know if there is a minimum price that you guys charge for each service at the end of the month. As an example, I'm planning to use the AWS API Gateway for one of my applications but I don't forsee any more than a 1000 calls per month. So in this case according to the pricing section (for Northern Virginia), my monthly charge should be : \n\n(1,000 calls / 1,000,000 calls) * $3.50 = $0.00035\n\nWhich is quite a small amount. \n\nAnother example would be my S3 usage. For my needs, 100 MB per month is more than sufficient. So in that case, the pricing looks like: \n\n(100 MB / 1000 MB) * $0.023 = $0.0023 \n\nAgain, not a very significant amount. So, am I going to be charged the exact amount in accordance with the specified pricing, or will it be rounded off to a larger value (let's say to 2 decimal places --> $0.01)?", 
            "subreddit": "aws", 
            "title": "Lowest price on the monthly bill", 
            "url": "https://www.reddit.com/r/aws/comments/6ymc1y/lowest_price_on_the_monthly_bill/"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1504759211.0, 
            "domain": "self.aws", 
            "id": "6yl1tu", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yl1tu/so_many_public_amis/", 
            "score": 0, 
            "selftext": "with so many public AMIs out there, i wonder how many of these were not intended to be public.", 
            "subreddit": "aws", 
            "title": "so many public AMIs", 
            "url": "https://www.reddit.com/r/aws/comments/6yl1tu/so_many_public_amis/"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1504755791.0, 
            "domain": "self.aws", 
            "id": "6yks6t", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 15, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yks6t/the_portknock_protocol_and_aws_security_groups/", 
            "score": 0, 
            "selftext": "i have done a port-knock protocol before on a traditional server.  this server was in a DMZ that allowed anything in.  would i need to run an instance the same way by giving it a \"wide open\" security group?  it would be nice if AWS added a port-knock feature to security groups.  i've head that some routers have added it.  it could be a simple rule that can be added with a series of ports to listen for.", 
            "subreddit": "aws", 
            "title": "The port-knock protocol and AWS Security Groups", 
            "url": "https://www.reddit.com/r/aws/comments/6yks6t/the_portknock_protocol_and_aws_security_groups/"
        }, 
        {
            "author": "AbhimanyuGrover", 
            "created_utc": 1504755566.0, 
            "domain": "self.aws", 
            "id": "6ykrir", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ykrir/how_do_you_automatically_rotate_or_archive_or/", 
            "score": 9, 
            "selftext": "Custom scripts or any tool?", 
            "subreddit": "aws", 
            "title": "How do you automatically rotate (or archive or delete) snapshots?", 
            "url": "https://www.reddit.com/r/aws/comments/6ykrir/how_do_you_automatically_rotate_or_archive_or/"
        }, 
        {
            "author": "softwareguy74", 
            "created_utc": 1504747876.0, 
            "domain": "self.aws", 
            "id": "6yk2qu", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yk2qu/how_does_workdocs_now_compare_with_google_docs/", 
            "score": 18, 
            "selftext": "I'm sure this has been asked a million times but wanted to get some feedback from this sub.\n\nI have been so far all in on Google Docs among with Gmail, but I've been getting more and more interested in WorkDocs as we try and migrate completely to AWS.\n\nI'm curious both from an end user perspective and an API perspective.  It looks like they just released a new SDK that provides quite a bit of functionality.", 
            "subreddit": "aws", 
            "title": "How does WorkDocs now compare with Google Docs?", 
            "url": "https://www.reddit.com/r/aws/comments/6yk2qu/how_does_workdocs_now_compare_with_google_docs/"
        }, 
        {
            "author": "LittleJoeyHodges", 
            "created_utc": 1504738170.0, 
            "domain": "self.aws", 
            "id": "6yj5l5", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yj5l5/rds_backups/", 
            "score": 13, 
            "selftext": "RDS makes automatic backups (i.e. snapshots) during a user-specified window on a regular interval. According to [the documentation](http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html), these automatic snapshots are deleted if the DB instance is deleted. This seems like a poor design, because surely one of the most likely scenarios in which you need a backup is inadvertent deletion of a DB instance.\n\nWhat strategies (if any) are other people using to regularly backup RDS instances? Manual snapshots? SQL dumps? Or do you rely on automatic snapshots exclusively?", 
            "subreddit": "aws", 
            "title": "RDS + backups", 
            "url": "https://www.reddit.com/r/aws/comments/6yj5l5/rds_backups/"
        }, 
        {
            "author": "noobcser", 
            "created_utc": 1504734151.0, 
            "domain": "self.aws", 
            "id": "6yir1c", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yir1c/unable_to_resize_ec2_ebs/", 
            "score": 12, 
            "selftext": "I have an EC2 that has 8GB space and running out, so through the web console I increased it to 16 GB - but it's not allocated to the partition. \n\nTried to follow the guide in: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-expand-volume.html#console-modify\n\nBut I got:\n\n    FAILED: unable to determine partition type\n\nHere are some info:\n\n    $ lsblk\n    NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT\n    xvda    202:0    0  16G  0 disk\n    \u2514\u2500xvda1 202:1    0   8G  0 part /\n\nand\n\n    $ df\n    Filesystem     1K-blocks    Used Available Use% Mounted on\n    devtmpfs         2015072      56   2015016   1% /dev\n    tmpfs            2024004       0   2024004   0% /dev/shm\n    /dev/xvda1       8123812 6163776   1859788  77% /\n\ntrying to grow:\n\n    $ growpart /dev/xvda1 1\n    FAILED: unable to determine partition type\n\nWhat am I missing?", 
            "subreddit": "aws", 
            "title": "Unable to resize EC2 EBS", 
            "url": "https://www.reddit.com/r/aws/comments/6yir1c/unable_to_resize_ec2_ebs/"
        }, 
        {
            "author": "J0e_EE", 
            "created_utc": 1504731086.0, 
            "domain": "self.aws", 
            "id": "6yifiw", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yifiw/help_with_authentication_for_workdocs/", 
            "score": 6, 
            "selftext": "Here is my C# code:\n\nAmazon.WorkDocs.AmazonWorkDocsConfig conf = new Amazon.WorkDocs.AmazonWorkDocsConfig();\nconf.ServiceURL = \"https://workdocs.us-west-2.amazonaws.com\";\n\nAmazon.WorkDocs.AmazonWorkDocsClient oAWSClient = new Amazon.WorkDocs.AmazonWorkDocsClient(\"VALID_ACCESS_KEY\", \"VALID_SECRET_KEY\", conf);\n\nAmazon.WorkDocs.Model.DescribeRootFoldersRequest folderReq = new Amazon.WorkDocs.Model.DescribeRootFoldersRequest();\n\nAmazon.WorkDocs.Model.DescribeRootFoldersResponse folderResp = oAWSClient.DescribeRootFolders(folderReq);\n\nIt looks like I am missing an authentication token but I have no idea how to request this - there is no sample C# code on the AWS website.\n\nCan you please help?  I am getting the following error on the last line:\n\nValue at 'authenticationToken' failed to satify contraint:  Member must not be null", 
            "subreddit": "aws", 
            "title": "Help with Authentication for WorkDocs", 
            "url": "https://www.reddit.com/r/aws/comments/6yifiw/help_with_authentication_for_workdocs/"
        }, 
        {
            "author": "jearkrishna", 
            "created_utc": 1504726185.0, 
            "domain": "self.aws", 
            "id": "6yhwhn", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yhwhn/jfrog_artifactory_integration_with_aws_code/", 
            "score": 5, 
            "selftext": "Is there any way to integration artifactory to was code pipeline ? Would like to avoid keep polling artifactory for changes. \nHow to start aws code pipeline as soon as new artifact pushed into artifactory ?\nThanks", 
            "subreddit": "aws", 
            "title": "JFrog artifactory integration with aws code pipeline", 
            "url": "https://www.reddit.com/r/aws/comments/6yhwhn/jfrog_artifactory_integration_with_aws_code/"
        }, 
        {
            "author": "linux_n00by", 
            "created_utc": 1504725699.0, 
            "domain": "self.aws", 
            "id": "6yhuh1", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yhuh1/help_with_ec2_and_s3/", 
            "score": 3, 
            "selftext": "hi guys,\n\nso i wanted to implement multiple ec2 instance with apache installed and was wondering if i can just mount a S3 bucket that contains the web application on all ec2 instances?\n\nwill there any issue with accessing it like degradation of read/write speed?", 
            "subreddit": "aws", 
            "title": "help with EC2 and S3", 
            "url": "https://www.reddit.com/r/aws/comments/6yhuh1/help_with_ec2_and_s3/"
        }, 
        {
            "author": "redditsterr", 
            "created_utc": 1504722548.0, 
            "domain": "self.aws", 
            "id": "6yhhwc", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yhhwc/npm_nodejs_package_nodexlsx_in_lambda/", 
            "score": 4, 
            "selftext": "Hi guys,\n            For a requirement in NodeJS , spreadsheet needs to be read and manipulated .  Came across node-xlsx\nhttps://www.npmjs.com/package/node-xlsx\n\nWas wondering if node-xlsx package can be used in Lambda serverless architecture ? \n\nWhere can the package be downloaded so that Lambda can access and use it , each time it is invoked?\n\nThanks", 
            "subreddit": "aws", 
            "title": "npm Node.JS package node-xlsx in Lambda", 
            "url": "https://www.reddit.com/r/aws/comments/6yhhwc/npm_nodejs_package_nodexlsx_in_lambda/"
        }, 
        {
            "author": "Feed_Bag", 
            "created_utc": 1504721996.0, 
            "domain": "self.aws", 
            "id": "6yhftj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 10, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yhftj/hosted_datacenter_replication_solution_with_aws/", 
            "score": 5, 
            "selftext": "My company has a small datacenter where we host assorted types of servers for some of our customer.  It is running on XenServer infrastructure, and we have both Windows and Linux VMs in there.\n\nI am assisting management with trying to come up with a VM replication solution that would push our Xen environment to AWS, keep it replicated, and allow for quick disaster recovery in the event out datacenter has an issue.  I am reviewing the AWS Disaster Recovery whitepaper at this time, but I'm not sure the solutions in there would fit what I am looking to do.\n\nThe Warm Standby and Multi-site solutions they talk about are probably my best options, but I cannot determine what replication tool they are using.  Would VM Import/Export be the best option here?  Or is there a different replication tool available for VMs that I am not thinking of?", 
            "subreddit": "aws", 
            "title": "Hosted datacenter replication solution with AWS?", 
            "url": "https://www.reddit.com/r/aws/comments/6yhftj/hosted_datacenter_replication_solution_with_aws/"
        }, 
        {
            "author": "chrzanowski", 
            "created_utc": 1504719769.0, 
            "domain": "self.aws", 
            "id": "6yh6wb", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yh6wb/codepipeline_codebuild_lambda/", 
            "score": 24, 
            "selftext": "Currently I have setup my AWS CodePipeline to fetch GitHub project on each commit, handle it with CodeBuild which is saving output on S3.\n\nHow can I make it to deploy this artifact to the AWS Lambda?", 
            "subreddit": "aws", 
            "title": "CodePipeline + CodeBuild > Lambda", 
            "url": "https://www.reddit.com/r/aws/comments/6yh6wb/codepipeline_codebuild_lambda/"
        }, 
        {
            "author": "jonzie777", 
            "created_utc": 1504714836.0, 
            "domain": "self.aws", 
            "id": "6ygn77", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ygn77/aws_image_import/", 
            "score": 9, 
            "selftext": "Hey all, i had to import a customized RHEL7 image for my company and create an AMI out of it, i was able to get all that completed without issue however i am curious as to how when i deploy that AMI now from my AMI's if there are any aws tools that need to be installed on it so that during deployment it can be customized? hopefully that makes sense ", 
            "subreddit": "aws", 
            "title": "AWS Image Import", 
            "url": "https://www.reddit.com/r/aws/comments/6ygn77/aws_image_import/"
        }, 
        {
            "author": "edyang73", 
            "created_utc": 1504711713.0, 
            "domain": "itproportal.com", 
            "id": "6ygb3d", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ygb3d/7_hidden_aws_costs_that_could_be_killing_your/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "7 hidden AWS costs that could be killing your budget", 
            "url": "http://www.itproportal.com/features/7-hidden-aws-costs-that-could-be-killing-your-budget/"
        }, 
        {
            "author": "Sorkiin", 
            "created_utc": 1504705140.0, 
            "domain": "self.aws", 
            "id": "6yfo6c", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yfo6c/question_route53_custom_domain_name_prefix/", 
            "score": 3, 
            "selftext": "If I have a website that is called 'website.com' that is pointed towards an s3, and I want to point the url 'app.website.com' to a separate s3 bucket, how do I set that up in route53? Do I need to create another hosted zone? Can I just create an alias record in the current hosted zone to point to the other s3 bucket with the record set name to 'app.website.com'?\n\nThanks!", 
            "subreddit": "aws", 
            "title": "[Question] Route53 Custom Domain Name Prefix", 
            "url": "https://www.reddit.com/r/aws/comments/6yfo6c/question_route53_custom_domain_name_prefix/"
        }, 
        {
            "author": "destroy--everything", 
            "created_utc": 1504667355.0, 
            "domain": "self.aws", 
            "id": "6yd17g", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yd17g/rant_modal_dialogue_boxes_showing_up_in/", 
            "score": 15, 
            "selftext": "Have others also started noticing over the last few weeks the new 'feature' that has been introduced which throws up a modal dialogue box that takes focus from whatever it is you are doing?\n\nA colleague was just doing a presentation and the console.aws app took over the presentation. \n\nLast night I was enjoying a cold beer while watching the Socceroos strip the paint from Thailands goalposts and then the AWS webapp popped up over the top of my foxtel player which was in full screen mode... I was already furious with the Socceroos performance but this popup was one too many examples of a poor performance and now my macbook is more shattered than the Socceroos world cup chances.\n\nSo anyone at AWS reading this can you:\n\n* get rid of the popup\n* get me a new laptop\n\n\nCheers", 
            "subreddit": "aws", 
            "title": "[Rant] Modal dialogue boxes showing up in console.aws.com", 
            "url": "https://www.reddit.com/r/aws/comments/6yd17g/rant_modal_dialogue_boxes_showing_up_in/"
        }, 
        {
            "author": "slipdexic", 
            "created_utc": 1504663937.0, 
            "domain": "self.aws", 
            "id": "6ycqb9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ycqb9/aws_workspace_london/", 
            "score": 8, 
            "selftext": "Hi \nI was wondering if anyone knows when AWS workspace will be coming to London region !", 
            "subreddit": "aws", 
            "title": "AWS Workspace london", 
            "url": "https://www.reddit.com/r/aws/comments/6ycqb9/aws_workspace_london/"
        }, 
        {
            "author": "2016pantherswin", 
            "created_utc": 1504660910.0, 
            "domain": "self.aws", 
            "id": "6ycggo", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ycggo/question_about_costs_associated_with_multiple_ec2/", 
            "score": 9, 
            "selftext": "If i were to create many EC2 instances, but only use each for $5/mo - would my costs be only for the actual time used + storage fee's? ", 
            "subreddit": "aws", 
            "title": "Question about cost's associated with multiple EC2 Instances", 
            "url": "https://www.reddit.com/r/aws/comments/6ycggo/question_about_costs_associated_with_multiple_ec2/"
        }, 
        {
            "author": "need_for_web_speed", 
            "created_utc": 1504656365.0, 
            "domain": "self.aws", 
            "id": "6yc1bx", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yc1bx/loopback_addresses_and_data_transfer_rates_one/", 
            "score": 1, 
            "selftext": "I have one instance on AWS; a reverse proxy onto itself for caching purposes (varnish), pointing towards a web server on the same box. Has anyone experienced high data transfer rates when the proxy is a loopback address [127.0.0.1]? This is all in one instance. Appreciate any input!", 
            "subreddit": "aws", 
            "title": "Loopback addresses and data transfer rates [one instance]?", 
            "url": "https://www.reddit.com/r/aws/comments/6yc1bx/loopback_addresses_and_data_transfer_rates_one/"
        }, 
        {
            "author": "gemgr0", 
            "created_utc": 1504652579.0, 
            "domain": "aws.amazon.com", 
            "id": "6ybood", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ybood/ec2_instances_now_provide_a_maximum_bandwidth_of/", 
            "score": 15, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "EC2 instances now provide a maximum bandwidth of 25 Gbps", 
            "url": "https://aws.amazon.com/about-aws/whats-new/2017/09/announcing-improved-networking-performance-for-amazon-ec2-instances/?sc_channel=sm&sc_campaign=Launch&sc_publisher=FACEBOOK&sc_country=Global&sc_geo=GLOBAL&sc_outcome=awareness&trk=_FACEBOOK&sc_content=EC2_37814e26_25Gbps_Bandwith_on_Ec2_Instances&sc_category=Amazon_EC2&linkId=41856892"
        }, 
        {
            "author": "Linux512", 
            "created_utc": 1504648633.0, 
            "domain": "self.aws", 
            "id": "6ybar6", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 26, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6ybar6/aws_lightsail_vs_digital_ocean_5_a_month_vps/", 
            "score": 35, 
            "selftext": "I want to run a $5 a month VPS on either AWS or Digital Ocean. Which one of these will give me the most bang for the buck and what use cases would benefit using AWS Lightsail vs Digital Ocean vice versa? I will use about 800-900GB per month.", 
            "subreddit": "aws", 
            "title": "AWS Lightsail vs Digital Ocean $5 a month VPS", 
            "url": "https://www.reddit.com/r/aws/comments/6ybar6/aws_lightsail_vs_digital_ocean_5_a_month_vps/"
        }, 
        {
            "author": "Iaskdumbshit2", 
            "created_utc": 1504644474.0, 
            "domain": "self.aws", 
            "id": "6yavfu", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 9, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yavfu/what_kind_of_ec2_and_rds_combination_should_i_be/", 
            "score": 1, 
            "selftext": "Is there a guide or a list of recommendations that available on this subject? I am looking for a combo that could support anywhere from 5,000-15,000 simulations connections. ", 
            "subreddit": "aws", 
            "title": "What kind of EC2 and RDS combination should I be looking for to accommodate a large user base?", 
            "url": "https://www.reddit.com/r/aws/comments/6yavfu/what_kind_of_ec2_and_rds_combination_should_i_be/"
        }, 
        {
            "author": "Dying_Daily", 
            "created_utc": 1504636140.0, 
            "domain": "self.aws", 
            "id": "6y9xsh", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y9xsh/recommendations_for_what_to_monitor_with/", 
            "score": 15, 
            "selftext": "Hi all,\n\nDoes anyone know of any good resources/articles/etc. discussing recommendations for what to monitor with CloudWatch? There are certain things that are obvious to me such as cpu, disk, memory, unhealthy instances, etc. but given the \"customability\" of CW to alert on basically anything, I'm wondering if what's being recommended for monitoring (besides the obvious stuff), particularly for auto-scaled web and app-based EC2 instances. Appreciate any advice!\n\nEDIT: Let me add another important piece of information. We already have in place Splunk monitoring that catches a lot of our application-based issues. So I guess another part of the question is, what can/should I do with CloudWatch that I can't do with Splunk or other log-based analysis tools?", 
            "subreddit": "aws", 
            "title": "Recommendations for what to monitor with CloudWatch besides obvious stuff like cpu, disk, and memory?", 
            "url": "https://www.reddit.com/r/aws/comments/6y9xsh/recommendations_for_what_to_monitor_with/"
        }, 
        {
            "author": "silviadoomra", 
            "created_utc": 1504631375.0, 
            "domain": "aws.amazon.com", 
            "id": "6y9ehq", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y9ehq/capturing_data_changes_in_amazon_aurora_using_aws/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Capturing Data Changes in Amazon Aurora Using AWS Lambda", 
            "url": "https://aws.amazon.com/blogs/database/capturing-data-changes-in-amazon-aurora-using-aws-lambda/"
        }, 
        {
            "author": "LE_POOR_MERIT", 
            "created_utc": 1504628483.0, 
            "domain": "self.aws", 
            "id": "6y92kk", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y92kk/help_format_of_post_test_event_when_using_lambda/", 
            "score": 2, 
            "selftext": "I just started this today and I'm wasting too much time on this one, small thing.\n\nI followed the [tutorial](http://docs.aws.amazon.com/lambda/latest/dg/with-on-demand-https-example-configure-event-source_1.html) to create a microservice in Lambda that reads and writes to DynamoDB.  The tutorial ends with a test of the Lambda function using a GET.  This works fine.  It does not provide samples for any of the other operations.\n\nI want to test writing to the DB using POST.  Here is my test event:\n\n\n    {\n        \"httpMethod\": \"POST\",\n        \"TableName\": \"TokenStorage\",\n        \"body\": {\n            \"Item\": {\n                \"Token\": {\n                    \"S\": \"this_is_my_test_token\"\n                },\n                \"Created\": {\n                    \"S\": \"2017-09-05 15:29:41.160993\"\n                }\n            }\n        }\n    }\n\nThe tutorial code is looking for the key \"body\".  However, whenever I test with this event, I receive the error: \n\n    expected string or buffer: TypeError\n    Traceback (most recent call last):\n      File \"/var/task/lambda_function.py\", line 41, in lambda_handler\n        payload = event['queryStringParameters'] if operation == 'GET' else json.loads(event['body'])\n      File \"/usr/lib64/python2.7/json/__init__.py\", line 339, in loads\n        return _default_decoder.decode(s)\n      File \"/usr/lib64/python2.7/json/decoder.py\", line 364, in decode\n        obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n    TypeError: expected string or buffer\n\nObviously, my test event is incorrect, but I cannot find a sample online anywhere.\n\nFor reference, here is the tutorial Lambda code in Python:\n\n    from __future__ import print_function\n\n    import boto3\n    import json\n\n    print('Loading function')\n    dynamo = boto3.client('dynamodb')\n\n\n    def respond(err, res=None):\n    return {\n        'statusCode': '400' if err else '200',\n        'body': err.message if err else json.dumps(res),\n        'headers': {\n            'Content-Type': 'application/json',\n        },\n    }\n\n\n    def lambda_handler(event, context):\n    '''Demonstrates a simple HTTP endpoint using API Gateway. You have full\n    access to the request and response payload, including headers and\n    status code.\n\n    To scan a DynamoDB table, make a GET request with the TableName as a\n    query string parameter. To put, update, or delete an item, make a POST,\n    PUT, or DELETE request respectively, passing in the payload to the\n    DynamoDB API as a JSON body.\n    '''\n    #print(\"Received event: \" + json.dumps(event, indent=2))\n\n    operations = {\n        'DELETE': lambda dynamo, x: dynamo.delete_item(**x),\n        'GET': lambda dynamo, x: dynamo.scan(**x),\n        'POST': lambda dynamo, x: dynamo.put_item(**x),\n        'PUT': lambda dynamo, x: dynamo.update_item(**x),\n    }\n\n    operation = event['httpMethod']\n    if operation in operations:\n        payload = event['queryStringParameters'] if operation == 'GET' else json.loads(event['body'])\n        return respond(None, operations[operation](dynamo, payload))\n    else:\n        return respond(ValueError('Unsupported method \"{}\"'.format(operation)))\n", 
            "subreddit": "aws", 
            "title": "HELP: Format of POST test event when using Lambda function to write to DynamoDB.", 
            "url": "https://www.reddit.com/r/aws/comments/6y92kk/help_format_of_post_test_event_when_using_lambda/"
        }, 
        {
            "author": "reprojected", 
            "created_utc": 1504628068.0, 
            "domain": "self.aws", 
            "id": "6y90wd", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y90wd/report_on_unusedinfrequently_used_workspaces/", 
            "score": 5, 
            "selftext": "How can I run a report/query which returns those Workspaces (with username, not just Workspace name) which have not been accessed in a specific timeframe?  CloudWatch seems useless in this regard, and I don't find any PS snippets to co-opt.  Thoughts?  Thanks!", 
            "subreddit": "aws", 
            "title": "Report on unused/infrequently used Workspaces?", 
            "url": "https://www.reddit.com/r/aws/comments/6y90wd/report_on_unusedinfrequently_used_workspaces/"
        }, 
        {
            "author": "redditsterr", 
            "created_utc": 1504627989.0, 
            "domain": "self.aws", 
            "id": "6y90l7", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y90l7/best_way_to_store_text_entered_in_a_html_form_aws/", 
            "score": 3, 
            "selftext": "\nHey guys ,newbie here with no programming background\nFollowing is the use case :\nFlow diagram -\nhttps://snag.gy/FgfauH.jpg\n\nText will be entered in the TextArea of a static HTML form and the data will be eventfully stored on Amazon S3 bucket. The send button  from static form will trigger Amazon Lambda .\n\nThe text needs to be converted and saved as 2 files :\nFile A. HTML code \nFile B. It can a text format such that originally entered format is retained ( ie line breaks, bold etc).\n\nThe text from File B will be copied into the Facebook Graph API.\n\n\nQuestions :\n1.What is the best way to save such files in the  PHYTHON/ NODE.JS / C#  ? , \n2.What program function /libraries can help achieve this ?\n3.Will Facebook Graph API accept and retain the text formatting from File B?\n\nI was'nt sure which subreddit to post , but since all the logic will be based in Lambda, so I thought would post here\nThank you in advance\n", 
            "subreddit": "aws", 
            "title": "Best way to store text entered in a HTML form - AWS Lambda", 
            "url": "https://www.reddit.com/r/aws/comments/6y90l7/best_way_to_store_text_entered_in_a_html_form_aws/"
        }, 
        {
            "author": "Blahblahcomputer", 
            "created_utc": 1504625525.0, 
            "domain": "linkedin.com", 
            "id": "6y8qhd", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y8qhd/aws_multi_account_strategies_for_large_enterprise/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "AWS Multi Account Strategies for Large Enterprise - Please check it out and provide feedback!", 
            "url": "https://www.linkedin.com/pulse/aws-multi-account-strategies-large-enterprise-eric-moore"
        }, 
        {
            "author": "speckz", 
            "created_utc": 1504619558.0, 
            "domain": "medium.com", 
            "id": "6y83si", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "article", 
            "link_flair_text": "article", 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y83si/i3_instances_and_nvme_booya_or_how_you_can_build/", 
            "score": 21, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "I3 instances and NVMe: booya! Or how you can build FreeBSD from the source in under 11 minutes vs. 12+ hours on a desktop.", 
            "url": "https://medium.com/@julsimon/i3-instances-and-nvme-booya-57fbf452a1c1"
        }, 
        {
            "author": "twyt88", 
            "created_utc": 1504618000.0, 
            "domain": "self.aws", 
            "id": "6y7ydi", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 36, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y7ydi/centralised_logging_services_which_one_would_you/", 
            "score": 30, 
            "selftext": "Primary Requirements: \n* centralising logs for Java, nginx, AWS etc logs\n* must be searchable in real time\n\nWould love to know what you are using or what are your experienced.\n\nThanks", 
            "subreddit": "aws", 
            "title": "Centralised Logging Services .. which one would you prefer?", 
            "url": "https://www.reddit.com/r/aws/comments/6y7ydi/centralised_logging_services_which_one_would_you/"
        }, 
        {
            "author": "rashaza", 
            "created_utc": 1504611727.0, 
            "domain": "self.aws", 
            "id": "6y7f4h", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y7f4h/api_gateway_http_support_not_https/", 
            "score": 2, 
            "selftext": "Hi guys,\n\nWe have a 3rd party that does not support https. Is it possible to do http only (not https) with API Gateway?\n\nIt seems that at the moment the http is a redirect to the https on the default setup, is it even possible to have direct (non-redirect) http on api gateway?\n\nThanks", 
            "subreddit": "aws", 
            "title": "API Gateway http support (not https)", 
            "url": "https://www.reddit.com/r/aws/comments/6y7f4h/api_gateway_http_support_not_https/"
        }, 
        {
            "author": "Naweze", 
            "created_utc": 1504595914.0, 
            "domain": "linkedin.com", 
            "id": "6y6erf", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y6erf/how_i_easily_reduce_aws_storage_costs_by_60/", 
            "score": 0, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "How I easily reduce AWS storage costs by 60%?", 
            "url": "https://www.linkedin.com/pulse/how-i-easily-reduce-aws-storage-costs-60-mihir-shah"
        }, 
        {
            "author": "proudboffin", 
            "created_utc": 1504594745.0, 
            "domain": "logz.io", 
            "id": "6y6c13", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y6c13/logging_serverless_challenges_best_practices/", 
            "score": 1, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Logging serverless - challenges, best practices", 
            "url": "https://logz.io/blog/logging-serverless-architecture/"
        }, 
        {
            "author": "yonatannn", 
            "created_utc": 1504592197.0, 
            "domain": "self.aws", 
            "id": "6y65u9", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y65u9/5_millions_events_per_day_which_aws_services_can/", 
            "score": 8, 
            "selftext": "Howdy. Our Node.JS app receives 5M events per day from some cloud CRM (using an open socket, not api/webhook), we perform some minor logic over each event and save into ElasticSearch. Though we can just code it ourself, I wonder whether some AWS services can decrease the effort? what value can Kineses bring to this table?", 
            "subreddit": "aws", 
            "title": "5 millions events per day, which AWS services can help?", 
            "url": "https://www.reddit.com/r/aws/comments/6y65u9/5_millions_events_per_day_which_aws_services_can/"
        }, 
        {
            "author": "Linux512", 
            "created_utc": 1504586156.0, 
            "domain": "self.aws", 
            "id": "6y5q2e", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y5q2e/using_aws_lightsail_bandwidth_with_ec2_instance/", 
            "score": 7, 
            "selftext": "I want to try to use an AWS EC2 instance to play games on. It is bandwidth intensive and I was wondering if it was possible to use the $5 AWS Lightsail bandwidth with the AWS EC2 instance? From the AWS Lightsail docs: Both data transfer IN to Lightsail instances and data transfer OUT from a Lightsail instance when using the instance\u2019s private IP address are free beyond your data transfer allowance. ", 
            "subreddit": "aws", 
            "title": "Using AWS Lightsail bandwidth with EC2 instance.", 
            "url": "https://www.reddit.com/r/aws/comments/6y5q2e/using_aws_lightsail_bandwidth_with_ec2_instance/"
        }, 
        {
            "author": "turumti", 
            "created_utc": 1504584570.0, 
            "domain": "self.aws", 
            "id": "6y5l8k", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y5l8k/glacier_and_s3_size_question/", 
            "score": 20, 
            "selftext": "If the maximum object size in S3 is 5TB and the maximum size of a Glacier archive is 4TB, what happens when a lifecycle rule tries to move a 5TB file from S3 into Glacier?", 
            "subreddit": "aws", 
            "title": "Glacier and S3 size question", 
            "url": "https://www.reddit.com/r/aws/comments/6y5l8k/glacier_and_s3_size_question/"
        }, 
        {
            "author": "tech_tuna", 
            "created_utc": 1504578356.0, 
            "domain": "self.aws", 
            "id": "6y5100", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 21, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y5100/looking_for_suggestions_on_configuring_federated/", 
            "score": 5, 
            "selftext": "I have multiple AWS accounts and I'd like to manage access to them with an identity provider and something like Duo for 2FA.  \n\nI've inherited a system which is using Active Directory and Duo.  I'm happy with the Duo piece but would prefer to use something else other than AD, I'm a bit bewildered by the options. ", 
            "subreddit": "aws", 
            "title": "Looking for suggestions on configuring federated access to the AWS CLI/API and console", 
            "url": "https://www.reddit.com/r/aws/comments/6y5100/looking_for_suggestions_on_configuring_federated/"
        }, 
        {
            "author": "Yemen4u2", 
            "created_utc": 1504557158.0, 
            "domain": "self.aws", 
            "id": "6y2yxf", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y2yxf/can_you_run_a_hugo_site_from_an_ec2_instance/", 
            "score": 3, 
            "selftext": "I created an EC2 Micro and installed Hugo on it. I tried to start-up the server but when I went to the URL it just gave me a \"This site can\u2019t be reached\" error.\n\nI know that you can host websites on S3 but I want to see if I can get it to work on EC2 so I can dev quickly. Is it possible? Any tips on how I can debug this error?", 
            "subreddit": "aws", 
            "title": "Can you run a Hugo site from an EC2 instance?", 
            "url": "https://www.reddit.com/r/aws/comments/6y2yxf/can_you_run_a_hugo_site_from_an_ec2_instance/"
        }, 
        {
            "author": "heyajinkya", 
            "created_utc": 1504554978.0, 
            "domain": "self.aws", 
            "id": "6y2qff", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y2qff/changing_configuration_of_master_node_in_amazon/", 
            "score": 3, 
            "selftext": "I have a MASTER node in EMR with the following config - 15 GB memory and 80  SSD GB storage.\n\nHow do I increase it to 30 GiB memory and 160 SSD GB storage?\n\n1]   Should i create a new slave instance with desired Master config and then find a way to swap? In this case I have to move all the data?\n\n2]. Or I should clone EMR and then change config of Master?\n\nWhats the best practice for this ? \n\n", 
            "subreddit": "aws", 
            "title": "Changing configuration of Master node in Amazon AWS EMR ?", 
            "url": "https://www.reddit.com/r/aws/comments/6y2qff/changing_configuration_of_master_node_in_amazon/"
        }, 
        {
            "author": "DerpDick90", 
            "created_utc": 1504545318.0, 
            "domain": "self.aws", 
            "id": "6y1o7f", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y1o7f/sending_sms_and_email/", 
            "score": 5, 
            "selftext": "In my app, I need to send SMS messages and Emails to small amounts of users (2 to 5). These messages are invitations for certain functionality in the app and will thus be triggered via another client device. These emails will initially need to be sent without the recipients consent (a cold invitation). How do I accomplish this with SNS/SES?\n\nI was thinking about creating an SNS topic for each user and subscribing the invited emails/phonenumbers to that and then publishing messages to that topic. However, I'm concerned that this may not be how topics were intended to be used since there'd be only a few people subscribed to each and there'd be one for each user (i.e. potentially a lot). I'm also worried about security: giving the client permission to create topics at will. This could be abused.\n\nI don't have any backend server for this; I'm hoping to use only AWS services and I'm pretty new to AWS in general. What would be a good, secure way to accomplish this? Am I thinking about this all wrong? Or is there a way to limit the number of topics an authenticated user can create? Clients are authenticated via Cognito.", 
            "subreddit": "aws", 
            "title": "Sending SMS and Email", 
            "url": "https://www.reddit.com/r/aws/comments/6y1o7f/sending_sms_and_email/"
        }, 
        {
            "author": "vapidness_is_rampant", 
            "created_utc": 1504536339.0, 
            "domain": "self.aws", 
            "id": "6y0pwe", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6y0pwe/login_to_user_pool_with_google/", 
            "score": 7, 
            "selftext": "My app currently uses a Cognito user pool for email and password authentication. It works very well. I want to add google authentication now.\n\nI've added google as an identity provider by following the documentation here \n\nhttp://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pools-social.html.\n\nScreen shot\n\nhttps://imgur.com/nQdZMVe\n\n\nI've authenticated my user with google and get back an auth token from google and an id token. I'm unsure what to do next.\n\nI imagine I somehow give this token to cognito and cognito gives me a cognito id token I can use for authentication with my app.", 
            "subreddit": "aws", 
            "title": "Login to user pool with Google", 
            "url": "https://www.reddit.com/r/aws/comments/6y0pwe/login_to_user_pool_with_google/"
        }, 
        {
            "author": "JonnyBravoII", 
            "created_utc": 1504522999.0, 
            "domain": "self.aws", 
            "id": "6xzolj", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 17, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xzolj/i3_vs_r4_instance_types/", 
            "score": 5, 
            "selftext": "We run a SQL Server database and we're looking to update the instance type it's running on.  Comparing the i3.xlarge vs the r4.xlarge, the memory and CPU appear to be exactly the same.  The only difference is that the i3 is designated as high I/O with optimized storage.  In our databases, we do millions of one-record writes throughout the day.  \n\nMy gut tells me that the i3 would be better for our use case but would be interested in other people's thoughts and experiences.\n\n", 
            "subreddit": "aws", 
            "title": "i3 vs r4 instance types", 
            "url": "https://www.reddit.com/r/aws/comments/6xzolj/i3_vs_r4_instance_types/"
        }, 
        {
            "author": "sivanr", 
            "created_utc": 1504520815.0, 
            "domain": "self.aws", 
            "id": "6xzjxr", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xzjxr/reinvent_promo_code/", 
            "score": 8, 
            "selftext": "Standard registration fee for re:invent 2017 is 1799$. I wonder what I could expect from a promo code? I guess it depends but is there some guesstimation?", 
            "subreddit": "aws", 
            "title": "Re:Invent promo code", 
            "url": "https://www.reddit.com/r/aws/comments/6xzjxr/reinvent_promo_code/"
        }, 
        {
            "author": "titus_andronikus", 
            "created_utc": 1504516538.0, 
            "domain": "self.aws", 
            "id": "6xzark", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 38, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xzark/sysadmin_inherited_aws_small_autoscaling_web_app/", 
            "score": 58, 
            "selftext": "Hi,\n\nI've just got account details for an AWS account which I will be managing.\n\nI've had some experience with AWS but now I can say that experience helps me only in GUI navigation.\n\nWhere should I start in reviewing current setup. \n\nHow do you \"connect the dots\" when / if you get to manage already existing account with no previous persons to ask.", 
            "subreddit": "aws", 
            "title": "Sysadmin inherited AWS small autoscaling web app system, what now?", 
            "url": "https://www.reddit.com/r/aws/comments/6xzark/sysadmin_inherited_aws_small_autoscaling_web_app/"
        }, 
        {
            "author": "SneakyPoopNinja", 
            "created_utc": 1504511794.0, 
            "domain": "self.aws", 
            "id": "6xz06p", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xz06p/dynamodb_and_unity_sdk_only_has_access_to_async/", 
            "score": 0, 
            "selftext": "Is there a reason I only have access to async methods with DynamoDB in Unity? I'm trying to use methods seen in the .NET BatchGetItem(), Query(), and so on. But I can only seem to find the Async versions of these which have like zero documentation on how to use them. \n\nDoes anyone know if there is a reason for this, and if so, maybe some examples on how to properly use these methods? \n\nThanks ahead of time! ", 
            "subreddit": "aws", 
            "title": "DynamoDB and Unity SDK only has access to Async methods?", 
            "url": "https://www.reddit.com/r/aws/comments/6xz06p/dynamodb_and_unity_sdk_only_has_access_to_async/"
        }, 
        {
            "author": "Skaperen", 
            "created_utc": 1504504675.0, 
            "domain": "self.aws", 
            "id": "6xyj9i", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xyj9i/microsoft_windows_instance_as_a_remote_desktop/", 
            "score": 10, 
            "selftext": "i am a solid Linux user.  but i would like to be able to port and test some of my developments over on Microsoft Windows (primarily in python).  for a reason i will not be explaining, i am limited to one laptop.  i could run Windows in a VM.  but for the small amount of usage i will make of it, i wonder if i would be better off running Windows on an instance from a Marketplace AMI and connect to it from a client that does RDP such as Remmina.  your thoughts on this crazy idea?", 
            "subreddit": "aws", 
            "title": "Microsoft Windows instance as a remote desktop", 
            "url": "https://www.reddit.com/r/aws/comments/6xyj9i/microsoft_windows_instance_as_a_remote_desktop/"
        }, 
        {
            "author": "NJ247", 
            "created_utc": 1504456915.0, 
            "domain": "self.aws", 
            "id": "6xu6tp", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xu6tp/error_the_eb_cli_cannot_find_a_platform_for_key/", 
            "score": 9, 
            "selftext": "Hi,\n\nI am getting the an error for the following command:\n\n    eb init MY_APP --region us-east-1 --platform 'Multi-container Docker' --keyname MY_KEY\n\n    ERROR: The EB CLI cannot find a platform for key \"multi-container docker\".\n\nTo provide a bit more context this command is being run in a Gitlab pipeline.  I have the correct AWS creds set as environment variables and tested listing out platforms etc. \n\nLocally the command above works fine but not in this Gitlab runner.  I set the debug flag and the only thing I could see that was different is that on the runner it has in the output:\n\n* Python Version: 2.7.6\n* Botocore version: 1.7.2\n* EBCLI Version: 3.10.6\n\nWhere as locally I have:\n\n* Python Version: 2.7.5\n* Botocore version: 1.5.80\n* EBCLI Version: 3.10.3\n\nThis is the last part of the debug:\n\n    2017-09-03 14:22:45,906 (INFO) eb : Traceback (most recent call last):\n      File \"/usr/local/lib/python2.7/dist-packages/ebcli/core/ebrun.py\", line 45, in run_app\n        app.run()\n      File \"/usr/local/lib/python2.7/dist-packages/cement/core/foundation.py\", line 797, in run\n        return_val = self.controller._dispatch()\n      File \"/usr/local/lib/python2.7/dist-packages/cement/core/controller.py\", line 472, in _dispatch\n        return func()\n      File \"/usr/local/lib/python2.7/dist-packages/cement/core/controller.py\", line 478, in _dispatch\n        return func()\n      File \"/usr/local/lib/python2.7/dist-packages/ebcli/core/abstractcontroller.py\", line 60, in default\n        self.do_command()\n      File \"/usr/local/lib/python2.7/dist-packages/ebcli/controllers/initialize.py\", line 91, in do_command\n        self.solution = self.get_solution_stack()\n      File \"/usr/local/lib/python2.7/dist-packages/ebcli/controllers/initialize.py\", line 273, in get_solution_stack\n        commonops.get_solution_stack(solution_string)\n      File \"/usr/local/lib/python2.7/dist-packages/ebcli/operations/commonops.py\", line 1211, in get_solution_stack\n        solution_string))\n    NotFoundError: The EB CLI cannot find a platform for key \"multi-container docker\".\n\nAnyone come across this before? \n\nThanks.\n\n\n\n\n", 
            "subreddit": "aws", 
            "title": "ERROR: The EB CLI cannot find a platform for key \"multi-container docker\".", 
            "url": "https://www.reddit.com/r/aws/comments/6xu6tp/error_the_eb_cli_cannot_find_a_platform_for_key/"
        }, 
        {
            "author": "plove55", 
            "created_utc": 1504453045.0, 
            "domain": "self.aws", 
            "id": "6xtsu0", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xtsu0/lambda_function_to_modify_rds_size_based_on_time/", 
            "score": 1, 
            "selftext": "Trying to use a larger RDS size during peak hours 7am-5pm M-F.  Then automatically change its to a smaller size outside of those hours.  Using Aurora DB.  I have been trying Lambda functions.  Can't seem to get it to work.  I understand the 5 minutes of downtime.", 
            "subreddit": "aws", 
            "title": "Lambda function to modify RDS size based on time, and day of week.", 
            "url": "https://www.reddit.com/r/aws/comments/6xtsu0/lambda_function_to_modify_rds_size_based_on_time/"
        }, 
        {
            "author": "SweBot", 
            "created_utc": 1504449678.0, 
            "domain": "self.aws", 
            "id": "6xthro", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xthro/migrate_rds_to_vpc/", 
            "score": 18, 
            "selftext": "What's the best way to migrate a postgres RDS classic db to a RDS server in a VPC without any downtime? Is this possible? ", 
            "subreddit": "aws", 
            "title": "Migrate RDS to VPC", 
            "url": "https://www.reddit.com/r/aws/comments/6xthro/migrate_rds_to_vpc/"
        }, 
        {
            "author": "SneakyPoopNinja", 
            "created_utc": 1504434771.0, 
            "domain": "self.aws", 
            "id": "6xsgrk", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "support", 
            "link_flair_text": "support query", 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xsgrk/iterating_through_items_under_a_specific_hash/", 
            "score": 6, 
            "selftext": "I have a Table with the has a string, and a few booleans as the items in the table. \n\nI'm simply trying to iterate through the items under a single hash key and get all of their states. \n\nThe documentation for doing this is nill, and even less so in Unity which seems to be a slightly different story than standard .NET ways of doing things. Anyone have any experience here? ", 
            "subreddit": "aws", 
            "title": "Iterating through items under a specific hash with C# in Unity?", 
            "url": "https://www.reddit.com/r/aws/comments/6xsgrk/iterating_through_items_under_a_specific_hash/"
        }, 
        {
            "author": "jasonstonek", 
            "created_utc": 1504400347.0, 
            "domain": "self.aws", 
            "id": "6xq7sc", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xq7sc/what_happen_when_you_surpass_your_rds_storage/", 
            "score": 2, 
            "selftext": "Does the rds drop inserts? Or does it break completely? Is there way to auto scale this?", 
            "subreddit": "aws", 
            "title": "What happen when you surpass your rds storage limit?", 
            "url": "https://www.reddit.com/r/aws/comments/6xq7sc/what_happen_when_you_surpass_your_rds_storage/"
        }, 
        {
            "author": "beast4545", 
            "created_utc": 1504399374.0, 
            "domain": "self.aws", 
            "id": "6xq4qi", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xq4qi/splitting_a_large_file_in_s3/", 
            "score": 2, 
            "selftext": "Hi,\n\nI m trying to find a solution to a problem that we currently have. We have a CSV file in S3 that contains around 1m lines and I need to read this file and convert it in to a json while I m doing that I need to only read 10000 lines and then create a json and post it to a third party and read the next 10000 and do the same until EOF. My solution that I m looking at is\n*. Trigger a lambda function when s3 gets the 1m raw file. This lambda will read 10000 lines and create a json file for every 10000 and put it to another s3 this will trigger another lambda which will post it to the third party\n* Problem with this is my lambda timeout because its taking more that 5mins to do it.\n* Another way I was thinking was to use AWS step functions. So Lambda get trigged when the s3 receives the 1m row file and then read 10000 lines call the same lambda if the EOF is not reached with the current file pointer. I need to try this.\n\nBut what I m trying to find out is, Is there a better way to do this using other AWS tools like EMR or Kinesis/Firehose etc.\n\nThanks in Advance.", 
            "subreddit": "aws", 
            "title": "Splitting a large file in s3", 
            "url": "https://www.reddit.com/r/aws/comments/6xq4qi/splitting_a_large_file_in_s3/"
        }, 
        {
            "author": "tech_tuna", 
            "created_utc": 1504398012.0, 
            "domain": "self.aws", 
            "id": "6xq0k2", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xq0k2/any_idea_what_this_means_in_the_cloudformation/", 
            "score": 9, 
            "selftext": "http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-ref.html\n\nThe YAML doc states:\n\n    Syntax for the full function name:\n    Ref: logicalName\n\n    Syntax for the short form:\n    !Ref logicalName\n```\n\nI've googled around a bit and do not see the difference between Ref and !Ref.  I'm guessing there is a simple explanation here but the doc isn't helping.  It's not helping me at least.", 
            "subreddit": "aws", 
            "title": "Any idea what this means in the CloudFormation doc for the Ref function?", 
            "url": "https://www.reddit.com/r/aws/comments/6xq0k2/any_idea_what_this_means_in_the_cloudformation/"
        }, 
        {
            "author": "Micocrates", 
            "created_utc": 1504372539.0, 
            "domain": "self.aws", 
            "id": "6xne3m", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xne3m/what_is_the_best_way_to_secure_a_static_website/", 
            "score": 9, 
            "selftext": "I've set up a website with CORS that has the AllowedOrigin to be my website domain. I've set up Route53 and have a custom domain pointed at an S3 Bucket. I've set another S3 Bucket policy to be public getobject and putobject. The CORS policy works, but I am also able to directly go to the object link in the S3 bucket into the browser. \n\nI have tried to Add the Condition statement\n,\n            \"Condition\": {\n                \"StringLike\": {\n                    \"aws:Referer\": \"http://mywebsite.com*\"\n                }\n            }    \n\nTo the end of the bucket policy and the referer/referrer only works in chrome. There does not seem to be a way to add the referrer in Firefox. Ive tried <meta name=\"referer\" content=\"origin\"> in the header and that doesn't work.\n<a href=\"http://mywebsite.com\" referrerpolicy=\"origin\" style=\"display:none\"> doesn't help.\n\nHow could I fix this issue?\n  ", 
            "subreddit": "aws", 
            "title": "What is the best way to secure a static website that allows GET and PUT requests from the site.", 
            "url": "https://www.reddit.com/r/aws/comments/6xne3m/what_is_the_best_way_to_secure_a_static_website/"
        }, 
        {
            "author": "hdgdtegdb", 
            "created_utc": 1504360384.0, 
            "domain": "self.aws", 
            "id": "6xm1lg", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 17, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xm1lg/network_acl_and_security_group_visualisation/", 
            "score": 19, 
            "selftext": "Hi all,\n\nI'd be grateful if you could offer any opinions to my question.\n\nWith an increasingly complex set of rules, it's getting more and more difficult for me to track which ports are blocked and which aren't on each server in my VPC.\n\nOn my VPC, I have several subnets and network ACLs, and many security groups.  Is there a good quality tool available (open source or commercial) that will allow me to visualise (and if possible simulate) traffic being blocked or accepted through the network?\n\nIdeally it would be simple to get started with.  I've found a couple of network simulators that are very complicated (and clearly intended for full-time network engineers, which I'm not).  A nice simple tool that would allow me to display the current state of the network on screen would be perfect.\n\nI would prefer a desktop tool, where I can manually enter/import all of my rules from AWS.  I found an online AWS network visualiser, but it requires access to the AWS account, which I'm not comfortable with.\n\nIf you can offer any suggestions, they would be much appreciated!\n\nMany thanks.\n\nEdit: Spelling", 
            "subreddit": "aws", 
            "title": "Network ACL and Security Group Visualisation", 
            "url": "https://www.reddit.com/r/aws/comments/6xm1lg/network_acl_and_security_group_visualisation/"
        }, 
        {
            "author": "ACPotato", 
            "created_utc": 1504354712.0, 
            "domain": "self.aws", 
            "id": "6xlk5w", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xlk5w/programmatically_running_sysprep_on_new_ec2/", 
            "score": 12, 
            "selftext": "I figured this must be pretty common, but I'm struggling for whatever reason.\n\nI'm launching a new EC2 instance from a PowerShell script.  As soon as it launches, I need to make a few modifications (working fine), then sysprep the image ready for re-deployment.\n\nI'm currently using User Data, passing the PS script between <powershell></powershell>.  All changes work, XML files are modified for sysprep, but actually running ec2config.exe with the -sysprep arg via User Data always ends in an error (I even tried modifiying the sysprep command to include /quiet).\n\nHow do people deal with this.  EC2 Run Command?  Searching around and finding less than I'd have expected for what seems a pretty common task.\n\nThanks for any help!", 
            "subreddit": "aws", 
            "title": "Programmatically running sysprep on new EC2 instance.", 
            "url": "https://www.reddit.com/r/aws/comments/6xlk5w/programmatically_running_sysprep_on_new_ec2/"
        }, 
        {
            "author": "Phosphoester", 
            "created_utc": 1504349073.0, 
            "domain": "self.aws", 
            "id": "6xl5lf", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xl5lf/using_amazon_polly_web_api_tts_for_bot/", 
            "score": 3, 
            "selftext": "Hey.\n\nCurrently I'm using Google's api url (http://translate.google.com/translate_tts?ie=UTF-8&total=1&idx=0&textlen=32&client=tw-ob&q=__TEXT&tl=__LOCALE) for my bot to say whatever I type.\n\nIs the same functionality available with Amazon Polly (which is far superior imho)?", 
            "subreddit": "aws", 
            "title": "Using Amazon Polly web api tts for bot?", 
            "url": "https://www.reddit.com/r/aws/comments/6xl5lf/using_amazon_polly_web_api_tts_for_bot/"
        }, 
        {
            "author": "dzlkxj", 
            "created_utc": 1504348764.0, 
            "domain": "self.aws", 
            "id": "6xl4rx", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 11, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xl4rx/making_an_aws_budget/", 
            "score": 19, 
            "selftext": "In the past, when I had to do a forecast budget for the next year, it was rather easy: discuss with users about their needs, allocate money to projects, buy stuff.\n\nIn the cloud era, things became more complicated. Now users have much more liberty to allocate and discard resources to respond to always moving business requirements. And AWS bills for many small stuff (bandwidth, I/Os, etc.)\n\nLast year, I wrote some code to estimate costs using AWS price CSVs and the architecture I had in mind + some buffer. Then I spent the year fighting to stay in line with the allocated budget.\n\nNow I have to work on next year budget. How are you handling this? Is there a better way to handle this?\n\nNB: I know about the cost explorer forecasting feature, but it is not long term enough, and it doesn't take human behavior into account.", 
            "subreddit": "aws", 
            "title": "Making an AWS budget", 
            "url": "https://www.reddit.com/r/aws/comments/6xl4rx/making_an_aws_budget/"
        }, 
        {
            "author": "omerxman", 
            "created_utc": 1504344066.0, 
            "domain": "self.aws", 
            "id": "6xkucn", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 0, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xkucn/how_i_figured_out_ecs_scaling_in_puzzle/", 
            "score": 1, 
            "selftext": "I've been looking a lot for a solution to ECS scaling-in problem.\nDecided to create it my own and it works great:\nhttps://medium.com/@omerxx/how-to-scale-in-ecs-hosts-2d0906d2ba", 
            "subreddit": "aws", 
            "title": "How I figured out ECS scaling in puzzle", 
            "url": "https://www.reddit.com/r/aws/comments/6xkucn/how_i_figured_out_ecs_scaling_in_puzzle/"
        }, 
        {
            "author": "ECrispy", 
            "created_utc": 1504333041.0, 
            "domain": "self.aws", 
            "id": "6xk6rh", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xk6rh/what_aws_services_can_i_use_to_accomplish_this/", 
            "score": 13, 
            "selftext": "I have a Nodejs app that uses websockets and sessions. I want to automate the build and deployment as follows -\n\n- on any code push, a new version of the app is deployed on 'dev' site\n- dashboard allows promoting this to staging, and then to prod\n- the deployment is via docker\n- app runs behind ALB (sockets so can't use ELB) and uses auto-scaling. This would apply to each stage\n- multiple deployments can be managed/torn down etc from web dashboard\n\nI will provide a build script to generate docker image of the app. And our code is hosted in a private git repo, we can't migrate to AWS hosted git/github etc.\n\nCan AWS help do this? There are a ton of Code* services and its not very clear. e.g. I know this will use ECS to manage containers and auto scaling groups. I read some guides and it seems ECR is harder to use than say Docker Cloud and to do things like building a new container on code change needs writing custom scripts.\n\nWe are a very small startup with no dedicated DevOps (i.e. I do this when I can). If there is an alternate solution that's easier and similar cost please do suggest it.\n", 
            "subreddit": "aws", 
            "title": "What AWS services can I use to accomplish this?", 
            "url": "https://www.reddit.com/r/aws/comments/6xk6rh/what_aws_services_can_i_use_to_accomplish_this/"
        }, 
        {
            "author": "d3adbor3d2", 
            "created_utc": 1504309732.0, 
            "domain": "self.aws", 
            "id": "6xifhc", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 7, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xifhc/hello_world_in_aws/", 
            "score": 2, 
            "selftext": "Very new to aws and I've been going through a few intro videos. Someone on the thread mentioned to go hands-on to learn faster. Is there a small/simple pre-built system/service (template?) that I can grab and look under the hood?\n\nI know it's pretty much point and click with aws but I don't have much sysadmin knowledge. Thanks for the help.", 
            "subreddit": "aws", 
            "title": "Hello world in aws", 
            "url": "https://www.reddit.com/r/aws/comments/6xifhc/hello_world_in_aws/"
        }, 
        {
            "author": "geerlingguy", 
            "created_utc": 1504304516.0, 
            "domain": "dev.acquia.com", 
            "id": "6xhxpg", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": "article", 
            "link_flair_text": "article", 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xhxpg/building_an_open_source_photo_gallery_with_face/", 
            "score": 3, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Building an Open Source Photo Gallery with Face and Object Recognition", 
            "url": "https://dev.acquia.com/blog/building-an-open-source-photo-gallery-with-face-and-object-recognition-part-2/31/08/2017/18666"
        }, 
        {
            "author": "iachievedit", 
            "created_utc": 1504300490.0, 
            "domain": "self.aws", 
            "id": "6xhiyk", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xhiyk/aws_cost_report_for_september_out_of_whack/", 
            "score": 4, 
            "selftext": "Out of Whack is a technical term for something doesn't add up.\n\nLogged in today to check my August bill, and it looked normal, and then noticed that the \"current charges for September\" (which started today) is already nearly 20% of an overall monthly bill.  \n\nHas anyone else noticed their AWS September bill projections/current total to be \"out of whack\"?", 
            "subreddit": "aws", 
            "title": "AWS Cost Report for September Out of Whack", 
            "url": "https://www.reddit.com/r/aws/comments/6xhiyk/aws_cost_report_for_september_out_of_whack/"
        }, 
        {
            "author": "IDN1", 
            "created_utc": 1504290859.0, 
            "domain": "self.aws", 
            "id": "6xgi0q", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 4, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xgi0q/any_way_of_tracking_s3_bucket_downloads_ideally/", 
            "score": 2, 
            "selftext": "I'm giving away sample PDF files which I host on S3.\n\nI'd like to monitor the number of downloads- ideally from my iPhone or iPad.\n\nAny suggestions please?\n\nMany thanks", 
            "subreddit": "aws", 
            "title": "Any way of tracking S3 Bucket downloads- ideally with an iPhone / iPad app?", 
            "url": "https://www.reddit.com/r/aws/comments/6xgi0q/any_way_of_tracking_s3_bucket_downloads_ideally/"
        }, 
        {
            "author": "alaxsxaq", 
            "created_utc": 1504287760.0, 
            "domain": "self.aws", 
            "id": "6xg5oi", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 5, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xg5oi/ec2_os_monitoring_in_cloudwatch/", 
            "score": 6, 
            "selftext": "Is this perl script still the best way to monitor OS memory and disk utilization in Cloudwatch?\n\nhttps://aws.amazon.com/code/8720044071969977", 
            "subreddit": "aws", 
            "title": "EC2 OS Monitoring in Cloudwatch", 
            "url": "https://www.reddit.com/r/aws/comments/6xg5oi/ec2_os_monitoring_in_cloudwatch/"
        }, 
        {
            "author": "adjohn", 
            "created_utc": 1504284782.0, 
            "domain": "read.iopipe.com", 
            "id": "6xfthx", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xfthx/the_hidden_concerns_of_network_resources_in_aws/", 
            "score": 5, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "The hidden concerns of network resources in AWS Lambda", 
            "url": "https://read.iopipe.com/5-things-to-know-about-lambda-the-hidden-concerns-of-network-resources-6f863888f656"
        }, 
        {
            "author": "gunsonstrings", 
            "created_utc": 1504282452.0, 
            "domain": "self.aws", 
            "id": "6xfk4v", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 6, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xfk4v/does_lambda_make_sense_combined_with_beanstalkec2/", 
            "score": 1, 
            "selftext": "For most of my applications, I am using a combination of S3, API Gateway, and Lambda.  There are two exceptions.\n\nDue to a limitation in S3 where resolving a host name requires a bucket with a matching name, I am hosting my frontend code on beanstalk and still calling the backend code from Lambda.   We have thousands of domains pointing to our beanstalk endpoint and around 50,000 hits a day using a handful of micro instances.  Very affordable (almost free tier), no performance issues so far.\n\nDue to the price of Gateway API on an app that will quickly scale up to 15M hits per day, we again swapped in a beanstalk component using two c4.large instances which essentially handles the API call to Lambda.  So far this looks like it will scale and we'll cut our cost on the API Gateway down from around $50 per day to $5 per day.  Lambda is maybe $10 or less.\n\nIn both these cases we swapped out a piece of our serverless infrastructure for servers after the fact, begging the question, should we just do it all on servers at this point?  Or does shipping most of the compute and memory to Lambda still provide some benefit over the EC2 nodes?\n\nEdit: Grammar", 
            "subreddit": "aws", 
            "title": "Does Lambda make sense combined with beanstalk/EC2?", 
            "url": "https://www.reddit.com/r/aws/comments/6xfk4v/does_lambda_make_sense_combined_with_beanstalkec2/"
        }, 
        {
            "author": "xen-m-rph", 
            "created_utc": 1504280798.0, 
            "domain": "self.aws", 
            "id": "6xfdb5", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xfdb5/how_to_keep_the_jupyter_notebooks_running_while_i/", 
            "score": 2, 
            "selftext": "I'm kind of new to working with aws and what I want is to be able to keep the jupyter notebooks running even if I close the local terminal on my laptop. right now when I close the terminal on my laptop, it kills the jupyter running on my ec2 instance as well, can someone help me out on how to figure this out ?", 
            "subreddit": "aws", 
            "title": "How to keep the jupyter notebooks running while I close my local terminal on aws ec2 instance", 
            "url": "https://www.reddit.com/r/aws/comments/6xfdb5/how_to_keep_the_jupyter_notebooks_running_while_i/"
        }, 
        {
            "author": "ffxsam", 
            "created_utc": 1504280160.0, 
            "domain": "self.aws", 
            "id": "6xfaul", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 1, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xfaul/how_to_make_a_cloudwatch_alarm_for_lambda/", 
            "score": 2, 
            "selftext": "I can't quite wrap my head around CloudWatch alarms. I get most of it, but what trips me up is specifying a period of time, e.g. \"This alarm will trigger when the blue line goes up to or above the red line for a duration of 1 minute.\"\n\nErrors are instantaneous, they don't continue over a duration of time, so I don't understand how to set this up. I just want a simple \"if error occurred, email me.\"", 
            "subreddit": "aws", 
            "title": "How to make a CloudWatch alarm for Lambda invocation error notification?", 
            "url": "https://www.reddit.com/r/aws/comments/6xfaul/how_to_make_a_cloudwatch_alarm_for_lambda/"
        }, 
        {
            "author": "stjohns1", 
            "created_utc": 1504278117.0, 
            "domain": "aws.amazon.com", 
            "id": "6xf2uz", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 25, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xf2uz/aws_now_allows_custom_names_for_security_group/", 
            "score": 85, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "AWS now allows custom names for security group rules", 
            "url": "https://aws.amazon.com/blogs/aws/new-descriptions-for-security-group-rules/"
        }, 
        {
            "author": "paleredline", 
            "created_utc": 1504276111.0, 
            "domain": "self.aws", 
            "id": "6xevgm", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xevgm/patching_instances_behind_an_elb/", 
            "score": 0, 
            "selftext": "I have a client that has two instances sitting behind an ELB. I have been working in AWS SSM to automate patching of the linux instances. Do i need to remove these instances from the ELB in order to patch them? I can't think of a reason why I would. ", 
            "subreddit": "aws", 
            "title": "Patching instances behind an ELB", 
            "url": "https://www.reddit.com/r/aws/comments/6xevgm/patching_instances_behind_an_elb/"
        }, 
        {
            "author": "LE_POOR_MERIT", 
            "created_utc": 1504273597.0, 
            "domain": "self.aws", 
            "id": "6xemdi", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 3, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xemdi/aws_api_gateway_how_can_i_store_an_endpoint/", 
            "score": 1, 
            "selftext": "Can you guys give me an idea if this is possible and what services I should be looking at?\n\nBackground:\n\nMy company has a mature API.  I am using AWS API Gateway to create a proxy that allows for some additional \"in-between\" processing for selected endpoints to solve some client issues.\n\nHere's how I imagine it working:\n\n1. START call to AWS API Gateway (AAG) endpoint\n2. This proxy endpoint then reaches out to our actual API endpoint (this works fine so far)\n3. The response passes back through AAG, grab one part of the response and store it somewhere in AWS!\n4. END\n\nNow, subsequent authorized calls by this client will be able to access, read, and use the stored variable from the initial call.\n\nSo the key requirements are to be able to write from AAG into some Amazon service that will store a variable.  And then be able to have AAG read that stored variable.\n\nI was initially thinking that Stage Variables were the way to go, but now I'm thinking that Lambda might be needed.\n\nThank you for ANY help or hints!\n", 
            "subreddit": "aws", 
            "title": "AWS API Gateway - How can I store an endpoint response in AWS?", 
            "url": "https://www.reddit.com/r/aws/comments/6xemdi/aws_api_gateway_how_can_i_store_an_endpoint/"
        }, 
        {
            "author": "JohnFGalt", 
            "created_utc": 1504244437.0, 
            "domain": "self.aws", 
            "id": "6xcm06", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 13, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xcm06/route_53_backup_tools/", 
            "score": 16, 
            "selftext": "For those who use Route 53 for DNS, do you back up your zone records, and if so, what do you use to do it? I gave [Route53-Transfer](https://github.com/RisingOak/route53-transfer) a try, but it keeps choking on private zones for me for whatever reason. Do you use publicly available tools? Private scripts? Nothing at all?\n\nI ask because we have a couple services that automatically create/delete DNS records and more than one person who modifies records. Between those two facts, I feel sure I'm gonna wake up to missing zones one day, and I'd like to be able to backup/restore.", 
            "subreddit": "aws", 
            "title": "Route 53 Backup Tools", 
            "url": "https://www.reddit.com/r/aws/comments/6xcm06/route_53_backup_tools/"
        }, 
        {
            "author": "meeskait", 
            "created_utc": 1504241859.0, 
            "domain": "self.aws", 
            "id": "6xcf38", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 2, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xcf38/security_specialty_cert_no_longer_available/", 
            "score": 1, 
            "selftext": "I noticed the security speciality cert is no longer listed on the AWS certifications page. Anyone know what's going on?", 
            "subreddit": "aws", 
            "title": "Security specialty cert no longer available?", 
            "url": "https://www.reddit.com/r/aws/comments/6xcf38/security_specialty_cert_no_longer_available/"
        }, 
        {
            "author": "velu007", 
            "created_utc": 1504229467.0, 
            "domain": "self.aws", 
            "id": "6xbdka", 
            "is_reddit_media_domain": false, 
            "is_self": true, 
            "is_video": false, 
            "link_flair_css_class": "support", 
            "link_flair_text": "support query", 
            "media": null, 
            "num_comments": 8, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6xbdka/can_anyone_advise_what_would_be_the_best_way_to/", 
            "score": 0, 
            "selftext": "So far these are the only solutions I have found- 1. [dynamo + redis] (https://www.reddit.com/r/learnprogramming/comments/3uguni/nosql_dynamodb_auto_increment_key/cxfe3hf/)\n2. [Atomic counters] (http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html#WorkingWithItems.AtomicCounters)\n", 
            "subreddit": "aws", 
            "title": "Can anyone advise what would be the best way to generate auto-incremented IDs in DynamoDB ? I have UUIDs. I want to map each of them to a auto incremented ID (like integer counter) ? How to achieve that ?", 
            "url": "https://www.reddit.com/r/aws/comments/6xbdka/can_anyone_advise_what_would_be_the_best_way_to/"
        }
    ], 
    "subreddit_creation_utc": 1201338576.0, 
    "subscribers": 22006, 
    "title": "Amazon Web Services (AWS): S3, EC2, SQS, RDS, DynamoDB, IAM, CloudFormation, Route 53, VPC and more", 
    "title_word_count_occurrences": {
        " r ": 1, 
        ".net": 3, 
        "alexa": 2, 
        "amazon": 25, 
        "apache": 2, 
        "aws": 148, 
        "big data": 1, 
        "c#": 1, 
        "data science": 1, 
        "deep learning": 1, 
        "docker": 4, 
        "facebook": 1, 
        "github": 1, 
        "gnu": 1, 
        "google": 3, 
        "html": 1, 
        "iphone": 2, 
        "java": 2, 
        "javascript": 1, 
        "linux": 3, 
        "machine learning": 1, 
        "microsoft": 1, 
        "mongodb": 1, 
        "oracle": 1, 
        "php": 2, 
        "python": 4, 
        "scala": 1, 
        "shell": 3, 
        "sql": 8, 
        "tex": 1, 
        "windows": 7
    }, 
    "top_score_submissions": [
        {
            "author": "jeffbarr", 
            "created_utc": 1505755312.0, 
            "domain": "aws.amazon.com", 
            "id": "70wi9e", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 49, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/70wi9e/persecond_billing_for_ec2_instances_and_ebs/", 
            "score": 197, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Per-Second Billing for EC2 Instances and EBS Volumes", 
            "url": "https://aws.amazon.com/blogs/aws/new-per-second-billing-for-ec2-instances-and-ebs-volumes/"
        }, 
        {
            "author": "awsgeek", 
            "created_utc": 1504886498.0, 
            "domain": "i.redd.it", 
            "id": "6yvok7", 
            "is_reddit_media_domain": true, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 12, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6yvok7/a_visual_summary_of_the_latest_addn_to_the_aws/", 
            "score": 123, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "A visual summary of the latest add'n to the AWS ELB family, the Network Load Balancer. Static IPs, super scalability & source IP visibility!", 
            "url": "https://i.redd.it/csq9nw4gmokz.jpg"
        }, 
        {
            "author": "awsgeek", 
            "created_utc": 1505306435.0, 
            "domain": "i.redd.it", 
            "id": "6zu9if", 
            "is_reddit_media_domain": true, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 20, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6zu9if/keeping_pace_with_aws_can_be_excitingchallenging/", 
            "score": 117, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "Keeping pace with AWS can be exciting/challenging, made time this week to experiment with the AWS Web Application Firewall", 
            "url": "https://i.redd.it/3bs4s33dbnlz.jpg"
        }, 
        {
            "author": "Naweze", 
            "created_utc": 1505825547.0, 
            "domain": "techcrunch.com", 
            "id": "712r5w", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 15, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/712r5w/aws_announces_persecond_billing_for_ec2_instances/", 
            "score": 107, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "AWS announces per-second billing for EC2 instances", 
            "url": "https://techcrunch.com/2017/09/18/aws-announces-per-second-billing-for-ec2-instances/"
        }, 
        {
            "author": "anonwipq", 
            "created_utc": 1505042209.0, 
            "domain": "businessinsider.in", 
            "id": "6z7pts", 
            "is_reddit_media_domain": false, 
            "is_self": false, 
            "is_video": false, 
            "link_flair_css_class": null, 
            "link_flair_text": null, 
            "media": null, 
            "num_comments": 75, 
            "num_crossposts": 0, 
            "permalink": "/r/aws/comments/6z7pts/a_certificate_in_amazons_aws_cloud_technology_can/", 
            "score": 106, 
            "selftext": "", 
            "subreddit": "aws", 
            "title": "A certificate in Amazon's AWS cloud technology can boost your salary by 26%", 
            "url": "http://www.businessinsider.in/A-certificate-in-Amazons-AWS-cloud-technology-can-boost-your-salary-by-26/articleshow/60439808.cms?utm_source=social_Reddit&utm_medium=social_sharing&utm_campaign=Click_through_social_share"
        }
    ], 
    "total_submissions": 423, 
    "utc_of_data_collection_completion": "2017-10-16 18:49:47", 
    "utc_of_data_collection_start": "2017-10-16 18:49:44"
}